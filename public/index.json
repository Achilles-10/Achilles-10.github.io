[{"content":"[paper]\n1. Introduction 利用基于残差的特征能够突出细微的伪造痕迹并且抑制无关的图像内容。下图展示了从图像中提取伪造痕迹的理想流程，在原始图像中减去图像内容得到篡改痕迹。本文将通过这种方法提取的残差称为“引导残差”。\n残差特征能够提高对高质量图像的检测性能，但对低质量图像的提升帮助甚微，因为低质量图像存在的压缩和resize等操作会对伪造痕迹产生干扰，故还需要RGB的空域信息来提供更多的信息。本文主要贡献如下：\n提出了细粒度的伪造痕迹提取器MTE(Manipulation Trace Extractor)来提取引导残差，克服了基于预测残差可能存在的偏差问题； 设计了有效的注意力融合机制AFM(Attention Fusion Mechanism)来进行特征融合，自适应地分配双流网络的空间特征和特征权重。同时，还利用通道注意力模块来建立伪造痕迹之间的依赖关系。 提出了双流模型AdapGRnet(Adaptive Fusion Based Guided Residuals Network)，通过将MTE和AFM与Backbone结合，在现实场景下进行伪造检测。AdapGRnet能够学习空域和残差域特征，同时检测高质量和低质量的伪造图像。在四个数据集上达到了SOTA的准确率和鲁棒性。 2. Method 2.1 Overview 补充性分析：\n通常情况下，空域信息既包含有适用于伪造检测任务的伪造痕迹，也包含适用于分类和识别任务的图像内容信息。残差特征可以抑制图像内容信息，但同时也可能造成伪造痕迹的部分丢失，特别是当图像质量低时。\n因此，利用空域信息和残差特征的互补性来进行伪造检测。\n双流网络架构：\n通过双流相互增强的方式学习空域和残差域特征，下图为双流模型的框架图。首先用MTE提取RGB图像的引导残差，然后将RGB图像和引导残差输入到主干网络(ResNet-18移除全连接层)中进行特征学习。最后通过AFM融合双流学习到的空域和残差特征。\n2.2 Manipulation Trace Extractor 引导滤波器是一个边缘保留平滑算子，它保留图像内容并过滤到平坦区域的篡改痕迹。篡改痕迹可通过$R_{gr}=|p-q|$得到，其中$p$为输入图像，$q$为滤波器输出，如下图所示。\n下图展示了高质量人脸和低质量人脸通过高通滤波器和MTE得到的残差结果。第五行是用噪声分析对引导残差进一步放大。可以观察到，在高质量图像中，残差具有丰富的细节，并且不同篡改图像的残差之间存在明显差异。对于低质量图像，从第五行噪声分析中可以看到，在残差图像中存在白色块状纹理，难以区分。\n2.3 Attention Fusion Mechanism 利用注意力机制融合双流的特征，空域流特征适用于从低质量的图像中学习特征，残差流适用于从高质量的图像中学习特征，设计的AFM模块如下图所示。\n令得到的空域特征$f_{rgb}\\in\\mathbb{R}^{C\\times H\\times W}$，将其reshape得到$f_{rgb}\\in\\mathbb{R}^{C\\times N_p}$，其中$N_p=H\\times W$。经过矩阵乘法$f_{rgb}\\cdot f^T_{rgb}=M_{rgb}\\in\\mathbb{R}^{C\\times C}$，经过softmax得到注意力图$M_{rgb}$。同理得到残差域注意力图$M_{gr}$。再分别与reshape后的特征图相乘，得到新的特征图${f_{rgb},f_{gr}}$。\n根据交叉熵损失$L_1$和$L_2$的softmax输出来分配双流的权重$\\alpha$，$F_{attention}=\\alpha_1f_{rgb}+\\alpha_2f_{gr}$.\n3. Experiments 使用的数据集为Hybrid Fake Face (HFF)，后处理包括JPEG压缩(压缩率为60，JP60)和模糊操作(5x5的均值滤波，ME5)。\n3.1 消融实验 MTE与AFM模块消融实验\n不同残差提取方法消融实验\n特征融合模块的比较\n","permalink":"https://Achilles-10.github.io/posts/paper/resduals/","summary":"[paper] 1. Introduction 利用基于残差的特征能够突出细微的伪造痕迹并且抑制无关的图像内容。下图展示了从图像中提取伪造痕迹的理想流程，在原始图像中减去图像内容得到篡改痕迹。本文将通过这种方法提取的残差称为“引导残差”。 残差特征能够提高对高质量图像的检测性能，但对低质量图像的提升帮助甚微，因为低质量图像","title":"Exposing Deepfake Face Forgeries with Guided Residuals"},{"content":"einsum Einsum是爱因斯坦求和约定(Einstein summation convention)，提供一种间接的方式来计算多维线性代数数组运算，可以在计算表达式中省去求和符号。\n函数原型 numpy.einsum(subscripts, *operands, out=None, dtype=None, order='K', casting='safe', optimize=False)\n参数：\nsubscripts: str: 将求和的下标指定为逗号分隔的下标标签列表 operands: list of array_like: 操作的数组 out: ndarray, optional: 输出数组，可选 dtype: {data-type, None}, optional: 使用指定的数据类型计算，默认为None order: {'C','F','A','K'}, optional: 输出的内存布局，默认为\u0026rsquo;K' casting: {'no','equiv','safe','same_kind','unsafe'}, optional: 控制可能发生的数据转换类型，默认为\u0026rsquo;safe' optimize: {False,True,'greedy','optimal'}, optional: 控制是否进行中间过程优化，默认为False 返回值：\noutput: ndarray: 计算结果 详解einsum表达式 写出数学表达式 对于以下einsum表达式：\nA = np.arange(2*3*4).reshape(2,3,4) C = einsum(\u0026#39;ijk-\u0026gt;jik\u0026#39;, A) 该表达式的数学表达式为： $$ C_{jk}=A_{ijk} $$\n补充求和符号$\\sum$ 求和符号的下标为数学表达式右边的下标剪左边的下标，在这个例子中，求和下标为i。 $$ C_{jk}=\\sum_i{A_{ijk}} $$\n用for循环复现 求和的部分用+=即可\ni,j,k=A.shape[0],A.shape[1],A.shape[2] C_ = np.zeros((j,k)) for i_ in range(i): for j_ in range(j): for k_ in range(k): C_[j_,k_] += A[i_,j_,k_] C,C_ (array([[12, 14, 16, 18], [20, 22, 24, 26], [28, 30, 32, 34]]), array([[12., 14., 16., 18.], [20., 22., 24., 26.], [28., 30., 32., 34.]])) 特殊写法补充 若等号右边是一个标量，则-\u0026gt;右边可以什么都不写： $$ b=\\sum_{ijk}{A_{ijk}} $$\n\u0026gt;\u0026gt;\u0026gt; A = np.arange(1*2*3).reshape(1,2,3) \u0026gt;\u0026gt;\u0026gt; b = einsum(\u0026#39;ijk-\u0026gt;\u0026#39;, A) \u0026gt;\u0026gt;\u0026gt; b 15 举例 例如矩阵$A=\\begin{bmatrix}0\u0026amp; 1\u0026amp; 2\\\\3\u0026amp; 4\u0026amp; 5\\\\6\u0026amp; 7\u0026amp; 8\\end{bmatrix}$,$B=\\begin{bmatrix}0\u0026amp; 1\u0026amp; 2\\\\3\u0026amp; 4\u0026amp; 5\\end{bmatrix}$，\n求矩阵的迹(trace)：与np.trace等价\n\u0026gt;\u0026gt;\u0026gt; einsum(\u0026#39;ii\u0026#39;, a) # einsum(a, [0,0]) 12 einsum(a, [0,0])中的[0,0]与'ii'对应\n提取矩阵对角线元素：与np.diag等价\n\u0026gt;\u0026gt;\u0026gt; einsum(\u0026#39;ii-\u0026gt;i\u0026#39;, a) # einsum(a, [0,0], [0]) array([0, 4, 8]) \u0026lsquo;ii-\u0026gt;i\u0026rsquo;表示$b_i=\\sum_{i}{A_{ii}}$\n在某一轴上求和：与np.sum(a, axis)等价\n\u0026gt;\u0026gt;\u0026gt; einsum(\u0026#39;ij-\u0026gt;i\u0026#39;, a) # einsum(a, [0,1], [0]), np.sum(a, axis=1) array([ 3, 12, 21]) \u0026lsquo;ij-\u0026gt;i\u0026rsquo;表示$b_i=\\sum_{j}{A_{ij}}$，即行求和\n\u0026gt;\u0026gt;\u0026gt; einsum(\u0026#39;ij-\u0026gt;j\u0026#39;, a) # einsum(a, [0,1], [1]), np.sum(a, axis=0) array([ 9, 12, 15]) \u0026lsquo;ij-\u0026gt;j\u0026rsquo;表示$b_j=\\sum_{i}{A_{ij}}$，即列求和\n高维数组对单一轴求和可以结合省略号(ellipsis, \u0026hellip;)完成\n\u0026gt;\u0026gt;\u0026gt; np.einsum(\u0026#39;...j-\u0026gt;...\u0026#39;,a) # einsum(a, [Ellipsis,1], [Ellipsis]) array([ 3, 12, 21]) \u0026lsquo;\u0026hellip;j-\u0026gt;\u0026hellip;\u0026lsquo;与\u0026rsquo;ij-\u0026gt;i\u0026rsquo;等价\n矩阵转置或调整矩阵轴顺序：与np.transpose等价\n\u0026gt;\u0026gt;\u0026gt; einsum(\u0026#39;ji\u0026#39;, c) # einsum(\u0026#39;ij-\u0026gt;ji\u0026#39;, c), einsum(c, [1,0]) array([[0, 3], [1, 4], [2, 5]]) $B_{ij}=A_{ji}$\n向量内积(结果为标量)：与np.inner等价\n\u0026gt;\u0026gt;\u0026gt; np.einsum(\u0026#39;i,i\u0026#39;,b,b) # einsum(b,[0],b,[0]) 5 向量外积：与np.outer等价\n\u0026gt;\u0026gt;\u0026gt; einsum(\u0026#39;i,j\u0026#39;, b, b) # einsum(b,[0],b,[1]) array([[0, 0, 0], [0, 1, 2], [0, 2, 4]]) 矩阵向量相乘：与np.dot等价\n\u0026gt;\u0026gt;\u0026gt; einsum(\u0026#39;ij,j\u0026#39;,a,b) # einsum(a, [0,1], b, [1]),einsum(\u0026#39;...j,j\u0026#39;, a, b),np.dot(a,b) array([ 5, 14, 23]) \u0026gt;\u0026gt;\u0026gt; einsum(\u0026#39;ij,i\u0026#39;,a,b) # einsum(a, [0,1], b, [0]),einsum(\u0026#39;i...,i\u0026#39;, a, b),np.dot(b,a) array([15, 18, 21]) \u0026lsquo;ij,j\u0026rsquo;表示$c_i=\\sum_{j}{A_{ij}\\cdot b_j}$\n标量乘法：与np.multiply等价\n\u0026gt;\u0026gt;\u0026gt; einsum(\u0026#39;..., ...\u0026#39;, 3, c) # einsum(\u0026#39;,ij\u0026#39;, 3, c) array([[ 0, 3 , 6 ], [ 9, 12, 15]]) 张量收缩：与np.tensordot等价\n\u0026gt;\u0026gt;\u0026gt; a = np.arange(60.).reshape(3,4,5) \u0026gt;\u0026gt;\u0026gt; b = np.arange(24.).reshape(4,3,2) \u0026gt;\u0026gt;\u0026gt; einsum(\u0026#39;ijk,jil-\u0026gt;kl\u0026#39;, a, b) # einsum(a, [0,1,2], b, [1,0,3], [2,3]),np.tensordot(a,b, axes=([1,0],[0,1])) array([[4400., 4730.], [4532., 4874.], [4664., 5018.], [4796., 5162.], [4928., 5306.]]) einops rearrange rearrange( tensor: Tensor@rearrange | List[Tensor@rearrange], pattern: str, **axes_lengths: Any ) -\u0026gt; Tensor@rearrange\n基础操作：reordering, composition and decomposition of axes\nfrom einops import rearrange, reduce, repeat import numpy as np ims = np.load(\u0026#39;./test_images.npy\u0026#39;,allow_pickle=False) print(ims.shape,ims.dtype) # (6, 96, 96, 3) float64 ims[0] 转置：\nrearrange(ims[0],\u0026#39;h w c -\u0026gt; w h c\u0026#39;) 拼接轴\nrearrange(ims,\u0026#39;b h w c-\u0026gt; (b h) w c\u0026#39;) # [6, 96, 96, 3] -\u0026gt; [6*96, 96, 3] 分解轴\nrearrange(ims, \u0026#39;(b1 b2) h w c -\u0026gt; (b1 h) (b2 w) c\u0026#39;, b1=2) # 6分解为2*3 将部分高度尺寸移动到宽度：\nrearrange(ims, \u0026#39;b (h1 h2) w c -\u0026gt;h1 (b w h2) c\u0026#39;, h2=2) 轴的顺序：\n当分解轴的时候若顺序不同，则结果也不同，如下例\nrearrange(ims,\u0026#39;b h w c-\u0026gt; h (b w) c\u0026#39;) rearrange(ims, \u0026#39;b h w c -\u0026gt; h (w b) c\u0026#39;) 还可以在合成宽度时重新排序，得到不一样的字母顺序\nrearrange(ims, \u0026#39;(b1 b2) h w c -\u0026gt; h (b1 b2 w) c \u0026#39;, b1=2) # \u0026#39;einops\u0026#39; rearrange(ims, \u0026#39;(b1 b2) h w c -\u0026gt; h (b2 b1 w) c \u0026#39;, b1=2) # \u0026#39;eoipns\u0026#39; einops.reduce reduce( tensor: Tensor@reduce, pattern: str, reduction: Reduction('min', 'max', 'sum', 'mean', 'prod'), **axes_lengths: int ) -\u0026gt; Tensor@reduce\n均值\n单一轴\nreduce(ims,\u0026#39;b h w c -\u0026gt; h w c\u0026#39;, \u0026#39;mean\u0026#39;) # ims.mean(axis=0) 多轴\nreduce(ims,\u0026#39;b h w c -\u0026gt; h w\u0026#39;, \u0026#39;min\u0026#39;) # ims.min(axis=(0,3)) 池化\n以2x2最大池化为例\nreduce(ims, \u0026#39;b (h h2) (w w2) c -\u0026gt; h (b w) c\u0026#39;, \u0026#39;max\u0026#39;, h2=2, w2=2) 不按比例resize\nreduce(ims,\u0026#39;b (h 2) (w 3) c -\u0026gt; h (b w) c\u0026#39;,\u0026#39;mean\u0026#39;) Stack and concatenate rearrange可以处理list数据，list的长度是模式字符串里的第一项(\u0026lsquo;b\u0026rsquo;)\n\u0026gt;\u0026gt;\u0026gt; x = list(ims) \u0026gt;\u0026gt;\u0026gt; print(type(x), \u0026#39;with\u0026#39;, len(x), \u0026#39;tensors of shape\u0026#39;, x[0].shape) \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; with 6 tensors of shape (96, 96, 3) \u0026gt;\u0026gt;\u0026gt; rearrange(x, \u0026#39;b h w c -\u0026gt; h w c b\u0026#39;).shape # np.stack(x, axis=3) (96, 96, 3, 6) \u0026gt;\u0026gt;\u0026gt; rearrange(x, \u0026#39;b h w c -\u0026gt; h (b w) c\u0026#39;).shape # np.concatenate(x, axis=1) (96, 576, 3) 轴的添加或删除 用1来创建一个新的维度，用相似的方法也可以去除维度\n\u0026gt;\u0026gt;\u0026gt; x = rearrange(ims, \u0026#39;b h w c -\u0026gt; b 1 h w 1 c\u0026#39;) # np.expand_dims(ims, axis=(1, 4)) \u0026gt;\u0026gt;\u0026gt; print(x.shape) (6, 1, 96, 96, 1, 3) \u0026gt;\u0026gt;\u0026gt; print(rearrange(x, \u0026#39;b 1 h w 1 c -\u0026gt; b h w c\u0026#39;).shape) # np.squeeze(xx, axis=(1, 4)) (6, 96, 96, 3) 可以使用()来当做占位符，它具有单位长度\nx = reduce(ims, \u0026#39;b h w c -\u0026gt; b () () c\u0026#39;, \u0026#39;max\u0026#39;) - ims # np.expand_dims(ims.max(axis=(1, 2)),axis=(1,2))-ims rearrange(x, \u0026#39;b h w c -\u0026gt; h (b w) c\u0026#39;) einops.repeat repeat( tensor: Tensor@repeat, pattern: str, **axes_lengths: Any ) -\u0026gt; Tensor@repeat\n使用Repeat实现元素重复操作。\n\u0026gt;\u0026gt;\u0026gt; repeat(ims[0], \u0026#39;h w c -\u0026gt; h new_axis w c\u0026#39;, new_axis=5).shape # shortcut: repeat(ims[0], \u0026#39;h w c -\u0026gt; h 5 w c\u0026#39;) (96, 5, 96, 3) 沿已有的维度重复\nrepeat(ims[0], \u0026#39;h w c -\u0026gt; h (repeat w) c\u0026#39;, repeat=3) # np.tile(ims[0], (1, 3, 1)) 沿多个已有的维度重复\nrepeat(ims[0], \u0026#39;h w c -\u0026gt; (2 h) (3 w) c\u0026#39;) # np.tile(ims[0], (2, 3, 1)) 模式字符串中维度的顺序仍然很重要，可以通过改变重复次数和宽度的顺序来将每个元素重复多次\nrepeat(ims[0], \u0026#39;h w c -\u0026gt; h (w repeat) c\u0026#39;, repeat=4) # np.repeat(ims[0], 4, axis=1) ","permalink":"https://Achilles-10.github.io/posts/tech/matrix/","summary":"einsum Einsum是爱因斯坦求和约定(Einstein summation convention)，提供一种间接的方式来计算多维线性代数数组运算，可以在计算表达式中省去求和符号。 函数原型 numpy.einsum(subscripts, *operands, out=None, dtype=None, order='K', casting='safe', optimize=False) 参数： subscripts: str: 将求和的下标指定为逗号分隔的下标标签列表 operands: list of array_like: 操作的数组 out: ndarray, optional: 输出数组，可选 dtype: {data-type, None}, optional: 使用指定","title":"einsum与einops"},{"content":"pathlib在功能和易用性上已经超越os库，比如以下这个获取上层目录和上上层目录的例子，pathlib的链式调用比os的嵌套调用更加灵活方便。\nos方法\nimport os # 获取上层目录 os.path.dirname(os.getcwd()) # 获取上上层目录 os.path.dirname(os.path.dirname(os.getcwd())) pathlib方法\nfrom pathlib import Path # 获取上层目录 Path.cwd().parent # 获取上上层目录 Path.cwd().parent.parent glob基础使用 基础语法，glob默认不匹配隐藏文件\n通配符 描述 示例 匹配 不匹配 * 匹配0个或多个字符，包含空串 glob* glob,glob123 glo ? 匹配1个字符 ?lob glob,flob lob [abc] 匹配括号内字符集合中的单个字符 [gf]lob glob,flob lob,hlob [a-z] 匹配括号内字符范围中的单个字符 [a-z]lob alob,zlob lob,1lob [^abc]或[!abc] 匹配不在括号内字符集合中的单个字符 [^cb]at aat at,cat [^a-z]或[!a-z] 匹配不在括号内字符范围中的单个字符 [^a-z]at 1at at,cat 在 bash 命令行中[!abc]需要转义成[\\!abc]\n扩展语法\n通配符 描述 示例 匹配 不匹配 {x,y,...} Brace Expansion，展开花括号内容，支持展开嵌套括号 a.{png,jp{e}g} a.png,a.jpg,a.jpeg ** globstar，匹配所有文件和任意层目录，若**后面紧接着/则只匹配目录，不含隐藏目录 src/** src/a.py,src/b/c.txt,src/b/ src/.hide/ ?(pattern-list) 匹配0次或1次给定模式 *(pattern-list) 匹配0次或多次给定的模式 a.*(txt|py) a., a.txt, a.txtpy a +(pattern-list) 匹配1次或多次给定的模式 @(pattern-list) 匹配给定模式 !(pattern-list) 匹配非给定的模式 pattern-list是一组以|为分隔符的模式集合\npathlib基础使用 Path为pathlib的主类，首先导入主类：\nfrom pathlib import Path 列出子目录：\n\u0026gt;\u0026gt;\u0026gt; p=Path(\u0026#39;./Research/\u0026#39;) \u0026gt;\u0026gt;\u0026gt; [x for x in p.iterdir() if x.is_dir()] [PosixPath(\u0026#39;Research/Two_Stream\u0026#39;), PosixPath(\u0026#39;Research/pytorch_wavelets\u0026#39;), PosixPath(\u0026#39;Research/FDFL\u0026#39;)] 列出当前目录树下所有.py文件\n\u0026gt;\u0026gt;\u0026gt; p=Path(\u0026#39;./DFDC/\u0026#39;) \u0026gt;\u0026gt;\u0026gt; list(p.glob(\u0026#39;**/*.py\u0026#39;)) [PosixPath(\u0026#39;DFDC/processing/__init__.py\u0026#39;), PosixPath(\u0026#39;DFDC/processing/crop_face.py\u0026#39;), PosixPath(\u0026#39;DFDC/processing/make_dataset.py\u0026#39;)] 在目录树中移动，用'/'进行路径拼接\n\u0026gt;\u0026gt;\u0026gt; p=Path(\u0026#39;.\u0026#39;) \u0026gt;\u0026gt;\u0026gt; q = p/\u0026#39;DFDC\u0026#39;/\u0026#39;processing\u0026#39; \u0026gt;\u0026gt;\u0026gt; q PosixPath(\u0026#39;DFDC/processing\u0026#39;) 使用joinpath()。\n\u0026gt;\u0026gt;\u0026gt; p=Path.cwd() \u0026gt;\u0026gt;\u0026gt; p.joinpath(\u0026#39;pathlib\u0026#39;) PosixPath(\u0026#39;/media/sda/zhy/pathlib\u0026#39;) 按照分隔符将文件路径分割\n\u0026gt;\u0026gt;\u0026gt; q.parts (\u0026#39;DFDC\u0026#39;, \u0026#39;processing\u0026#39;) 查询路径属性\n\u0026gt;\u0026gt;\u0026gt; q.exists() True \u0026gt;\u0026gt;\u0026gt; q.is_dir() Trueq \u0026gt;\u0026gt;\u0026gt; q.is_file() False 创建目录和文件\np = Path(\u0026#39;./pathlib/\u0026#39;) # parents默认为False，若父目录不存在抛出异常 # exist_ok默认为False，若目录已存在抛出异常 p.mkdir(parents=True, exist_ok=True) p = Path(\u0026#39;./pathlib/test.txt\u0026#39;) # touch创建文件，父目录必须存在否则抛出异常 p.touch(exist_ok=True) 获取文件/目录信息\n\u0026gt;\u0026gt;\u0026gt; p = Path(\u0026#39;DFDC/processing/__init__.py\u0026#39;) # 获取文件/目录名 \u0026gt;\u0026gt;\u0026gt; p.name \u0026#39;__init__.py\u0026#39; # 获取不包含后缀的文件名 \u0026gt;\u0026gt;\u0026gt; p.stem \u0026#39;__init__\u0026#39; # 获取文件后缀名 \u0026gt;\u0026gt;\u0026gt; p.suffix \u0026#39;.py\u0026#39; \u0026gt;\u0026gt;\u0026gt; p = Path.cwd() # 获取上层目录路径 \u0026gt;\u0026gt;\u0026gt; p.parent PosixPath(\u0026#39;/media/sda\u0026#39;) # 获取所有上层目录路径 \u0026gt;\u0026gt;\u0026gt; [path for path in p.parents] [PosixPath(\u0026#39;/media/sda\u0026#39;), PosixPath(\u0026#39;/media\u0026#39;), PosixPath(\u0026#39;/\u0026#39;)] # 获取文件/目录属性 \u0026gt;\u0026gt;\u0026gt; p.stat() os.stat_result(st_mode=16895, st_ino=171704321, st_dev=2048, st_nlink=16, st_uid=1018, st_gid=1019, st_size=4096, st_atime=1684207391, st_mtime=1684207367, st_ctime=1684207367) 重命名/移动文件\n重命名文件时，当新命名的文件重复时，会抛出异常。\n\u0026gt;\u0026gt;\u0026gt; p = Path(\u0026#39;pathlib/test.txt\u0026#39;) # 重命名 \u0026gt;\u0026gt;\u0026gt; new_name = p.with_name(\u0026#39;test_new.txt\u0026#39;) \u0026gt;\u0026gt;\u0026gt; p.rename(new_name) PosixPath(\u0026#39;pathlib/test_new.txt\u0026#39;) # 修改后缀 \u0026gt;\u0026gt;\u0026gt; new_suffix = new_name.with_suffix(\u0026#39;.json\u0026#39;) \u0026gt;\u0026gt;\u0026gt; new_name.rename(new_suffix) PosixPath(\u0026#39;pathlib/test_new.json\u0026#39;) 移动文件，当新路径下文件已存在时，无法创建。\n\u0026gt;\u0026gt;\u0026gt; p = Path(\u0026#39;pathlib/test_new.json\u0026#39;) \u0026gt;\u0026gt;\u0026gt; p.rename(\u0026#39;test.json\u0026#39;) PosixPath(\u0026#39;test.json\u0026#39;) replace()与rename()用法基本相同，但是当新命名的文件重复时，replace()不会抛出异常而是直接覆盖旧文件。\n删除文件/目录\n删除文件，missing_ok=True设置文件不存在时不会抛出异常。\n\u0026gt;\u0026gt;\u0026gt; p = Path(\u0026#39;test.json\u0026#39;) \u0026gt;\u0026gt;\u0026gt; p.unlink(missing_ok=True) 删除目录，目录必须为空，否则抛出异常。\n\u0026gt;\u0026gt;\u0026gt; p=Path(\u0026#39;pathlib\u0026#39;) \u0026gt;\u0026gt;\u0026gt; p.rmdir() ","permalink":"https://Achilles-10.github.io/posts/tech/pathlib/","summary":"pathlib在功能和易用性上已经超越os库，比如以下这个获取上层目录和上上层目录的例子，pathlib的链式调用比os的嵌套调用更加灵活方便。 os方法 import os # 获取上层目录 os.path.dirname(os.getcwd()) # 获取上上层目录 os.path.dirname(os.path.dirname(os.getcwd())) pathlib方法 from pathlib import Path # 获取上层目录 Path.cwd().parent # 获取上上层目录 Path.cwd().parent.parent glob基础使用 基础语法，gl","title":"使用pathlib优雅操作路径"},{"content":"[paper] [code]\n1. 引言 参考NLP在大规模预训练模型上的突破，在CV中提取通用的视觉特征，可以是用于分类任务的图像级别特征，也可以是用于分割任务的像素级别特征。利用自监督的方法，在不同源、足够多的数据上训练即可生成这样的特征。\n本文工作探索了自监督学习是否在大规模数据上预训练有潜力学习通用的视觉特征。本文大部分技术贡献都是专为稳定和加速判别性自监督学习定制。\n对于预训练数据，本文构建了一个自动管道，从大量未处理的图像集合中筛选和平衡数据集。在本文工作中，使用一种朴素的聚类方法解决了在处理wild数据时重新平衡概念并避免在少数主导模式上的过拟合问题，并构建了一个小型但多样的142M图像的语料库来验证本文方法。\n本文提出了用不同ViT框架训练的DINOv2模型，下图展示了DINOv2在多种图像级和像素级CV任务中的性能（深蓝色为DINOv2，浅橙色是自监督方法，深粉色为弱监督方法），验证了与最好的开源的弱监督模型相比，自监督训练是学习可迁移冻结特征的一个很好的候选方法。\n2. 数据处理(Data Processing) 数据处理pipeline如下图所示：\n数据来源(Data selection)\n构建的LVD-142M数据集的所用的数据集如下表所示，该集合旨在为图像级和密集识别提供涵盖各种下游视觉任务的图像。总共有1.2B图像。\n图像相似度(Image similarity)\n使用余弦相似度(cosine similarity)将图像特征与下面的相似度函数m比较： $$ m(s,r)=\\text{cos-similarity}(f(s),f(r))=\\frac{f(s)\\cdot f(r)}{||f(s)||_2||f(r)||_2} $$ 其中s和r是一对比较的图像，f是模型生成的特征。\n去重(Deduplication)\n将[A self-supervised descriptor for image copy detection]的拷贝检测流程应用到未处理的数据中去除重复图像，减少冗余增加图像多样性。\nSelf-deduplication：检索每幅图像的k=64最近邻(余弦相似度)，只考虑相似度\u0026gt;0.6的邻居，通过可扩展的不相交集数据结构实现来提取关联k-NN图的连通分支，对重复图像的每个分量只保留一个代表性图像。自去重的结果有1.1B图像。 Relative deduplication：丢弃上一步骤中与评估数据集的训练和测试划分中相似的图像，采用与自去重中相似的步骤，丢弃相似度\u0026gt;0.45的所有重复图像。剩下744M数据。 Retrieval：检索相似图像来构建数据集。首先使用在ImageNet-22k预训练的ViT-H/16网络来计算Image Embedding，并使用余弦相似度来作为图像之间的距离度量。然后对未处理的数据进行k-means聚类。给定一个用于检索的查询数据集，如果它足够大，为每个查询图像检索N个(4)最近邻。如果较小，则从每个查询图像对应的簇中采样M张图像。 3. 判别性自监督预训练(Discriminative Self-supervised Pre-training) 使用一种判别性的自监督方法来学习特征，该方法可以看作是以SwAV为中心的DINO和iBOT损失的组合\nImage-level objective：考虑从学生和教师网络中提取特征之间的交叉熵损失。这两个特征来自ViT的class token，由同一张图的不同crop得到。学习学生网络的参数，通过指数异动平均(EMA)来构建教师网络。 Patch-level objective：随机mask学生网络输入图像的一些patch，然后在两个网络的每个掩码快上添加交叉熵损失，与图像级的损失结合。 Untying head weights between both objectives：将两个目标相关的权重绑定在一起会使得模型在patch-level上欠拟合，image-level上过拟合。通过解绑这些权重提高了在两个尺度上的性能。 Sinkhorn-Knopp centering：使用Sinkhorn-Knopp(SK)批归一化替代DINO和iBot的教师softmax-centering步骤。运行SK算法进行3轮迭代；对于学生，使用softmax归一化。 KoLeo regularizer：KoLeo 正则项来自于 Kozachenko-Leonenko differential entropy estimator.给定一个含有n向量的集合$(x_i,\\dots,x_n)$，$L_{\\text{koleo}}=-\\frac{1}{n}\\sum_{i=1}^{n}{\\log(d_{n,i})}$ ，其中 $d_{n,i}=\\min_{j\\neq i}||x_i-x_j||$是$x_i$与batch内其他点的最小距离。在计算koLeo正则项前还对特征进行L2正则化。 Adapting the resolution：高分辨率是分割或检测等像素级下游任务的关键，因为小物体在低分辨率下消失。然而，在高分辨率下进行训练需要更长的时间和更大内存。相反，在预训练结束的短时间内将图像的分辨率提高到518 × 518。Fixing the train-test resolution discrepancy 4. 高效实现(Efficient implementation) 相较于iBOT，DINOv2运行速度快2倍，使用1/3的内存。\nFast and memory-efficient attention：实现自己版本的FlashAttention以提高自注意力层的效率。由于GPU硬件的特性，当每个头(head)的嵌入维度为64倍数时效率最高，当全嵌入维度为256倍数时矩阵运算更高效。因此本文的ViT-g架构使用embedding dimension = 1536(24 heads, 64 dim/head)，而非embedding dimension = 1408(16 heads, 88 dim/head)。本文的ViT-g有1.1B参数。 Nested tensors in self-attention Efficient stochastic depth：本文实现了随机深度的一个高效版本，它跳过了丢弃残差计算而不是掩盖结果，以近似丢弃率的比例节省内存和计算量。本文丢弃率d=40%，显著提高计算效率和内存使用率。该实现在批维度上随机重排B个样本，并对前$(1-d)\\times B$个样本分块计算。 Fully-Sharded Data Parallel (FSDP)：使用AdamW优化器，对于ViT-g将使用16G内存。FSDP节省跨GPU的通信开销。 模型蒸馏(Model Distillation) 5. 消融研究(Ablation Studies) 设置一系列消融研究来验证本文pipeline中不同组件：技术修改、预训练数据和模型蒸馏。\n5.1 Improved Training Recipe 本文方法在iBOT基础上进行改进。本文通过在一个baseline iBOT模型中依次添加各个组件，训练了多个模型，结果如下图所示。几乎每个组件都能带来性能的提升，只有Layer Scale和Stochastic Depth在linear中降低了性能，但它们提高了训练的稳定性。\n5.2 Pretraining Data Source 预训练数据的质量直接影响到特征的质量，本实验对比LVD-142M，ImageNet-22k和未处理的原始数据。结果如下图所示。可见，在LVD-142M上预训练能够在ImageNet-1k上取得最好性能，同时在其他测试集也能取得较好的性能。于是可以得出LVD-142M数据集提供了不同类型的平衡的数据，能带来性能的提升。\n5.3 Model Size and Data 模型大小与数据量大小的重要性实验结果如下图所示。\n5.4 Loss Components 验证KoLeo Loss和masked image modeling(MIM)的影响，结果如下图所示：\n5.5 Impact of Knowledge Distillation 验证模型蒸馏的有效性，比较ViT-L/14从头训练和从ViT-g/14蒸馏的性能，结果如下图所示。可见，蒸馏得到的模型性能更高，甚至在有的benchmark上超过了教师模型。\n5.6 Impact of Resolution 衡量在预训练过程中改变分辨率对图像级和patch级特征的影响，结果如下图所示。可见，在训练结尾使用高分辨率训练10k次迭代，在增加很少计算量的同时带来和高分辨率训练几乎一样好的性能。\n6. 结果(Results) Baseline. ImageNet-1k top-1 ACC. 在其他评估中报告SSL(自监督)模型中最好的四个，以及弱监督中最好的OpenCLIP-G模型。\n与开源的SOTA自监督模型比较：MAE, DINO, SEERv2, MSN, EsViT, Mugs, iBOT.\n弱监督模型：CLIP, OpenCLIP, SWAG.\n6.1 ImageNet Classification 冻结特征层，仅训练一个线性分类器。\n能否微调编码器(Can we finetune the encoders)？\n下图是微调后的实验结果，取得了明显的性能提升，因此微调是可选的策略。\n鲁棒性分析(Robustness analysis)\n下图是泛化性(鲁棒性)的测试结果，相较于SSL模型，本文方法取得了明显更好的鲁棒性；相较于弱监督模型，仅在Im-R和Sketch上稍微落后。\n6.2 Additional Image and Video classification Benchmarks 6.3 Instance Recognition 6.4 Dense Recognition Tasks 语义分割(Semantic segmentation)\n深度估计(Depth estimation)\n6.5 定性结果(Qualitative Results) 语义分割和深度估计(Semantic Segmentation and Depth Estimation)\n分布外的泛化性(Out-of-distribution generalization)\n分布外数据的分割和深度估计例子如下图所示，展现了在不同特征域中良好的迁移性。\nPCA of patch features\n块匹配(Patch matching)\n7. Fairness and Bias Analysis 7.1 Geographical Fairness 7.2 Gender, Skintones and Age 8. Estimating the Environmental Impact of Training our Models ","permalink":"https://Achilles-10.github.io/posts/paper/dinov2/","summary":"[paper] [code] 1. 引言 参考NLP在大规模预训练模型上的突破，在CV中提取通用的视觉特征，可以是用于分类任务的图像级别特征，也可以是用于分割任务的像素级别特征。利用自监督的方法，在不同源、足够多的数据上训练即可生成这样的特征。 本文工作探索了自监督学习是否在大规模数据上预训练有潜力学习通用的视觉","title":"DINOv2: Learning Robust Visual Features without Supervision"},{"content":"48. 剑指 Offer 51. 数组中的逆序对(困难) 归并排序：\n归并排序的合并阶段，每当遇到左子数组元素\u0026gt;右子数组元素时，表示左子数组当前元素到末尾元素与右子数组当前元素构成若干逆序对。\n在归并时用一个tmp辅助数组来暂存nums[i:j]内的元素。\nclass Solution: def reversePairs(self, nums: List[int]) -\u0026gt; int: def merge(l,r): if l\u0026gt;=r: return 0 m=l+(r-l)//2 res = merge(l,m)+merge(m+1,r) tmp[l:r+1]=nums[l:r+1] i,j=l,m+1 for k in range(l,r+1): if i==m+1: nums[k]=tmp[j] j+=1 elif j==r+1 or tmp[i]\u0026lt;=tmp[j]: nums[k]=tmp[i] i+=1 else: nums[k]=tmp[j] res+= m-i+1 j+=1 return res tmp=[0]*len(nums) return merge(0,len(nums)-1) 49. 剑指 Offer 52. 两个链表的第一个公共节点(简单) 双指针：当指针遍历到链表末尾时，转移到另一链表表头，直到p1=p2。\nclass Solution: def getIntersectionNode(self, headA: ListNode, headB: ListNode) -\u0026gt; ListNode: A, B = headA, headB while A != B: A = A.next if A else headB B = B.next if B else headA return A 50. 剑指 Offer 53 - I. 在排序数组中查找数字 I(简单) 二分法：\n分别找到目标数字左边和右边的第一个元素索引left和right，答案为right-left-1。\nhelper函数旨在查找数字tar在nums中的插入位置，若存在值相同的元素，则插入右边。\nclass Solution: def search(self, nums: [int], target: int) -\u0026gt; int: def helper(tar): i, j = 0, len(nums) - 1 while i \u0026lt;= j: m = (i + j) // 2 if nums[m] \u0026lt;= tar: i = m + 1 else: j = m - 1 return i return helper(target) - helper(target - 1) 51. 剑指 Offer 53 - II. 0～n-1中缺失的数字(简单) 二分查找：\n数组可以划分为左子数组：nums[i]=i和右子数组：nums[i]!=i。缺失数字等于右子数组的首位元素索引。\nclass Solution: def missingNumber(self, nums: List[int]) -\u0026gt; int: i, j = 0, len(nums) - 1 while i \u0026lt;= j: m = (i + j) // 2 if nums[m] == m: i = m + 1 else: j = m - 1 return i 52. 剑指 Offer 54. 二叉搜索树的第k大节点(简单) 中序遍历：\n二叉搜索树的中序遍历的倒序为递减序列。\nclass Solution: def kthLargest(self, root: TreeNode, k: int) -\u0026gt; int: def dfs(root): if not root: return dfs(root.right) if self.k == 0: return self.k -= 1 if self.k == 0: self.res = root.val dfs(root.left) self.k = k dfs(root) return self.res 53. 剑指 Offer 55 - I. 二叉树的深度(简单) 层序遍历：\n每遍历一层深度+1\nclass Solution: def maxDepth(self, root: TreeNode) -\u0026gt; int: if not root: return 0 queue, res = [root], 0 while queue: tmp = [] for node in queue: if node.left: tmp.append(node.left) if node.right: tmp.append(node.right) queue = tmp res += 1 return res DFS：\n树的深度=max(左深度，右深度)+1\nclass Solution: def maxDepth(self, root: TreeNode) -\u0026gt; int: if not root: return 0 return max(self.maxDepth(root.left), self.maxDepth(root.right)) + 1 54. 剑指 Offer 55 - II. 平衡二叉树(简单) 树的深度=max(左深度，右深度)+1\n后序遍历+剪枝（自底向上）：当某子树不是平衡树时直接剪枝\nclass Solution: def isBalanced(self, root: TreeNode) -\u0026gt; bool: def recur(root): if not root: return 0 left = recur(root.left) if left == -1: return -1 right = recur(root.right) if right == -1: return -1 return max(left, right) + 1 if abs(left - right) \u0026lt;= 1 else -1 return recur(root) != -1 先序遍历+判断深度（自顶向下）：当所有子树都是平衡树则是平衡树，产生很多重复计算\nclass Solution: def isBalanced(self, root: TreeNode) -\u0026gt; bool: if not root: return True return abs(self.depth(root.left) - self.depth(root.right)) \u0026lt;= 1 and \\ self.isBalanced(root.left) and self.isBalanced(root.right) def depth(self, root): if not root: return 0 return max(self.depth(root.left), self.depth(root.right)) + 1 55. 剑指 Offer 56 - I. 数组中数字出现的次数(中等) 分组异或：\n对所有数字进行一次异或，得到两个出现一次的数字的异或值。\n在异或结果中找到任意为1的位。\n根据这一位对所有的数字进行分组。在每个组内进行异或操作，得到两个数字。\nclass Solution: def singleNumbers(self, nums: List[int]) -\u0026gt; List[int]: x,y,n,m=0,0,0,1 for num in nums: n^=num while n\u0026amp;m==0: m\u0026lt;\u0026lt;=1 for num in nums: if num\u0026amp;m: x^=num else: y^=num return x,y 56. 剑指 Offer 56 - II. 数组中数字出现的次数 II(中等) 遍历统计：\nclass Solution: def singleNumber(self, nums: List[int]) -\u0026gt; int: counts = [0] * 32 for num in nums: for j in range(32): counts[j] += num \u0026amp; 1 num \u0026gt;\u0026gt;= 1 res, m = 0, 3 for i in range(32): res \u0026lt;\u0026lt;= 1 res |= counts[31 - i] % m return res if counts[31] % m == 0 else ~(res ^ 0xffffffff) 有限状态自动机：\n考虑数字的二进制形式，对于出现三次的数字，各二进制位出现的次数都是3的倍数。统计所有数字的各二进制位中1的出现次数，并对3求余，结果则为只出现一次的数字。\n计算one的方法：one = one^n \u0026amp; ~two\n利用计算后的one计算two：two = two^n \u0026amp; ~one\nclass Solution: def singleNumber(self, nums: List[int]) -\u0026gt; int: ones, twos = 0, 0 for num in nums: ones = ones ^ num \u0026amp; ~twos twos = twos ^ num \u0026amp; ~ones return ones 57. 剑指 Offer 57. 和为s的两个数字(简单) 双指针：\nclass Solution: def twoSum(self, nums: List[int], target: int) -\u0026gt; List[int]: i, j = 0, len(nums) - 1 while i \u0026lt; j: s = nums[i] + nums[j] if s \u0026gt; target: j -= 1 elif s \u0026lt; target: i += 1 else: return nums[i], nums[j] return [] 58. 剑指 Offer 57 - II. 和为s的连续正数序列(简单) ","permalink":"https://Achilles-10.github.io/posts/algo/offer3/","summary":"48. 剑指 Offer 51. 数组中的逆序对(困难) 归并排序： 归并排序的合并阶段，每当遇到左子数组元素\u0026gt;右子数组元素时，表示左子数组当前元素到末尾元素与右子数组当前元素构成若干逆序对。 在归并时用一个tmp辅助数组来暂存nums[i:j]内的元素。 class Solution: def reversePairs(self, nums: List[int]) -\u0026gt; int: def merge(l,r): if l\u0026gt;=r: return 0 m=l+(r-l)//2 res = merge(l,m)+merge(m+1,r) tmp[l:r+1]=nums[l:r+1] i,j=l,m+1 for k in range(l,r+1):","title":"剑指offer复习笔记(3)"},{"content":"[paper]\n1. 引言 由于绝大多数伪造视频都是以逐帧伪造的方式生成的，这样独立生成的每张人脸在时序上不可避免地导致闪烁和不连续，如下图所示。所以可以利用时序相关性来实现更泛化和鲁棒的人脸伪造视频检测。\n人脸伪造视频主要有两类伪影，一类是空间相关的融合边界(blending boundary)、棋盘格和模糊伪影等，一类是时序相关性。但通常方法都侧重于检测空间相关伪影，为了学习到更多的时序不一致性信息，本文提出了FTCN（fully temporal convolution network），关键思想是限制模型学习空间相关的伪影。另外，发现一些不相邻的帧之间也会出现不一致性，故提出用Transformer来解决时间维度上的长依赖关系。\n本文的方法可以从头开始训练而不需要预训练模型，并且可以在没有人工标注的情况下定位和可视化伪造视频中的时序不一致性。\n本文主要贡献总结如下：\n探索充分利用时间相关性进行人脸伪造检测，并提出了一种结合全时序卷积网络(FTCN)和Transformer的框架来显式检测时间不一致性。 本文的检测器可以定位和可视化人脸伪造的时间不连续部分。 在各种数据集上的实验证明了本文提出的方法在泛化能力方面的优越性。 2. 方法 为了学习到更多的时序不一致性信息，提出FTCN。具体的，将所有与时间相关的卷积核大小不变，但将所有与空间相关的卷积核大小设置为1。用ResNet-50(R50)作为backbone，通过以下实验验证：\n3D R50 2D R50 3D R50 FTCN 通过在FF++数据集上训练，t-SNE可视化结果如下图。分析可知，虽然所有分类器都能区分真假数据，但是假数据的分布完全不同。3D R50和2D R50都会将不同的人脸操纵方法产生的虚假数据分离出来，这表明它们提取的特征包含了每种伪造算法的独特伪影，这会影响泛化能力。相反，3D R50 FTCN分类器的造伪数据更多的混合在一起，这证明了时序网络是通过更一般的时序不一致来学习分类的。\n(d)是FTCN结合Transformer的结果。\n","permalink":"https://Achilles-10.github.io/posts/paper/ftcn/","summary":"[paper] 1. 引言 由于绝大多数伪造视频都是以逐帧伪造的方式生成的，这样独立生成的每张人脸在时序上不可避免地导致闪烁和不连续，如下图所示。所以可以利用时序相关性来实现更泛化和鲁棒的人脸伪造视频检测。 人脸伪造视频主要有两类伪影，一类是空间相关的融合边界(blending boundary)、棋盘","title":"Exploring Temporal Coherence for More General Video Face Forgery Detection"},{"content":"图像阈值 全局简单阈值 对于图像里的每个像素，应用相同的阈值，如果像素值小于阈值，则将其设置为0，否者设置为最大值。使用函数cv2.threshold(src, thresh, maxval, type, dst)，src是原图像，必须是单通道图像(灰度)，type表示阈值类型，所有简单的阈值类型为：\ncv2.THRESH_BINARY：小于阈值置0，大于阈值置为最大值maxval cv2.THRESH_BINARY_INV：与上相反 cv2.THRESH_TRUNC：小于阈值不变，大于阈值置为阈值thresh，即大于阈值的部分显示为白色 cv2.THRESH_TOZERO：小于阈值置0，大于阈值保持原色 cv2.THRESH_TOZERO_INV：与上相反 有两个输出，第一个是使用的阈值，第二个是阈值处理后的图像。\n示例如下，灰度图像黑色为0，白色为255：\nimg = cv2.imread(\u0026#39;face.png\u0026#39;,0) ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY) ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV) ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC) ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO) ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV) titles = [\u0026#39;Original Image\u0026#39;,\u0026#39;BINARY\u0026#39;,\u0026#39;BINARY_INV\u0026#39;,\u0026#39;TRUNC\u0026#39;,\u0026#39;TOZERO\u0026#39;,\u0026#39;TOZERO_INV\u0026#39;] images = [img, thresh1, thresh2, thresh3, thresh4, thresh5] plt.figure(figsize=(9,6)) for i in range(6): plt.subplot(2,3,i+1),plt.imshow(images[i],\u0026#39;gray\u0026#39;) plt.title(titles[i]) plt.xticks([]),plt.yticks([]) plt.show() 自适应阈值 使用cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C, dst)实现自适应阈。thresholdType有cv2.THRESH_BINARY和cv2.THRESH_BINARY_INV两种，blockSize确定邻域大小，C是减去的常数，adaptiveMethod决定如何计算阈值，有以下两种：\ncv2.ADAPTIVE_THRESH_MEAN_C：局部邻域块均值减去常数C cv2.ADAPTIVE_THRESH_GAUSSIAN_C：局部邻域块高斯加权和减去常数C； 自适应阈值可以根据像素周围的区域来确定像素的阈值；亮度较高的图像区域的二值化阈值通常会较高，而亮度低的图像区域的二值化阈值则会相适应的变小；不同亮度、对比度、纹理的局部图像区域将会拥有相对应的局部二值化阈值。\n示例如下：\nimg = cv2.imread(\u0026#39;sudoku.png\u0026#39;,0) img = cv2.medianBlur(img,5) ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY) th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2) th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2) titles = [\u0026#39;Original\u0026#39;, \u0026#39;Global(v = 127)\u0026#39;,\u0026#39;Mean\u0026#39;, \u0026#39;Gaussian\u0026#39;] images = [img, th1, th2, th3] plt.figure(figsize=(8,8)) for i in range(4): plt.subplot(2,2,i+1),plt.imshow(images[i],\u0026#39;gray\u0026#39;) plt.title(titles[i]) plt.xticks([]),plt.yticks([]) plt.show() Otsu的二值化 在全局简单阈值中，我们使用任意选择的值作为阈值。Otsu的方法可以自动确定阈值，避免了必须选择一个值的情况。考虑仅具有两个不同图像值的图像（双峰图像），其中直方图将仅包含两个峰。一个好的阈值应该在这两个值的中间，Otsu的方法能从图像直方图中确定最佳全局阈值。\n仍然使用cv2.threshold函数，将cv2.THRESH_OTSU作为额外的标志位传递到函数，阈值thresh可任意选择。\n示例如下，三种情况分别是全局阈值(thresh=127)、Otsu阈值，经过高斯滤波去噪后的Otsu阈值：\nimg = cv2.imread(\u0026#39;noisy.jpeg\u0026#39;,0) ret1,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY) ret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU) blur = cv2.GaussianBlur(img,(5,5),0) ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU) # plot all the images and their histograms images = [img, 0, th1, img, 0, th2, blur, 0, th3] titles = [\u0026#39;Original Noisy Image\u0026#39;,\u0026#39;Histogram\u0026#39;,\u0026#39;Global Thresholding (v=127)\u0026#39;, \u0026#39;Original Noisy Image\u0026#39;,\u0026#39;Histogram\u0026#39;,\u0026#34;Otsu\u0026#39;s Thresholding\u0026#34;, \u0026#39;Gaussian filtered Image\u0026#39;,\u0026#39;Histogram\u0026#39;,\u0026#34;Otsu\u0026#39;s Thresholding\u0026#34;] plt.figure(figsize=(9,9)) for i in range(3): plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],\u0026#39;gray\u0026#39;) plt.title(titles[i*3]), plt.xticks([]), plt.yticks([]) plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256) plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([]) plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],\u0026#39;gray\u0026#39;) plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([]) plt.show() 图像平滑 2D卷积（图像过滤） 可以使用各类低通滤波器(LPF)和高通滤波器(HPF)对图像进行滤波，LPF有助于消除噪声、使图像模糊等，HPF有助于在图像中寻找边缘信息。使用函数cv2.filter2D(src, ddepth, kernel, dst, anchor, delta, borderType)来将滤波核与图像进行卷积，例如，5x5的均值滤波核如下： $$ K = \\frac{1}{25} \\begin{bmatrix} 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \\\\ 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \\\\ 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \\\\ 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \\\\ 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \\end{bmatrix} $$ 使用7x7的均值滤波示例如下：\nimg = cv.imread(\u0026#39;face.png\u0026#39;) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) kernel = np.ones((7,7),np.float32)/49 dst = cv.filter2D(img,-1,kernel) plt.subplot(121),plt.imshow(img),plt.title(\u0026#39;Original\u0026#39;) plt.xticks([]), plt.yticks([]) plt.subplot(122),plt.imshow(dst),plt.title(\u0026#39;Averaging\u0026#39;) plt.xticks([]), plt.yticks([]) plt.show() 图像模糊（图像平滑） 通过将图像与低通滤波器进行卷积来实现图像模糊，这对于消除噪声很有用。它实际上从图像中消除了噪声和边缘等高频部分。因此此操作会使边缘模糊，OpenCV主要提供四种模糊类型：\n均值\n获取核区域下所有像素的均值，然后替换中心元素。可以通过cv2.blur(src, ksize, dst, anchor, borderType)或cv2.boxFilter(src, ddepth, ksize, dst, anchor, normalize, borderType)完成。示例如下：\nimg = cv2.imread(\u0026#39;face.png\u0026#39;) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) blur = cv2.blur(img,(5,5)) plt.subplot(121),plt.imshow(img),plt.title(\u0026#39;Original\u0026#39;) plt.xticks([]), plt.yticks([]) plt.subplot(122),plt.imshow(blur),plt.title(\u0026#39;Blurred\u0026#39;) plt.xticks([]), plt.yticks([]) plt.show() 若不想使用标准化的滤波器，可以使用cv2.boxFilter()并且设置normalize=False。\n高斯模糊\n使用cv2.GaussianBlur()。需要指定高斯核的宽度和高度，宽度和高度都应该为正奇整数；还需指定X和Y方向的标准差sigmaX和sigmaY，如果仅指定sigmaX，则两者相同，若两者均为零，则根据高斯核大小计算。高斯模糊对于从图像中去除高斯噪声非常有效。\n可通过cv2.getGaussianKernel()创建高斯内核。\n修改上述代码实现高斯模糊：\nblur = cv2.GaussianBlur(img,(5,5),0) 中值模糊\n将中心元素替换为和区域的中值，对于消除椒盐噪声非常有效。内核大小应该为正奇整数。示例如下：\nmedian = cv.medianBlur(img,5) 椒盐噪声就是黑白噪点，椒指黑色噪点，盐指白色噪点。\n双边滤波\n双边滤波cv2.bilateralFilter(src, d, sigmaColor, sigmaSpace, dst, borderType)在去除噪声的同时保持边缘清晰锐利非常有效。但是该操作相较于其他滤波器速度较慢。\nd表示滤波时使用的每个像素邻域的直径 sigmaColor表示色彩空间中滤波的标准差，该值越大，滤波器在保留边缘信息上越弱 sigmaSpace表示坐标空间中滤波的标准差，该值越大，更远的颜色相近的元素会互相影响 双边滤波器在空间中也采用高斯滤波器，但是还有一个高斯滤波器，它是像素差的函数。空间的高斯函数确保仅考虑附近像素的模糊，而强度差的高斯函数确保仅考虑强度与中心像素相似的那些像素的模糊。由于边缘的像素强度变化较大，因此可以保留边缘。\nblur = cv.bilateralFilter(img,9,75,75) ","permalink":"https://Achilles-10.github.io/posts/tech/opencv4/","summary":"图像阈值 全局简单阈值 对于图像里的每个像素，应用相同的阈值，如果像素值小于阈值，则将其设置为0，否者设置为最大值。使用函数cv2.threshold(src, thresh, maxval, type, dst)，src是原图像，必须是单通道图像(灰度)，type表示阈值类型，所有简单的阈值类型为： cv2.THRESH_","title":"OpenCV-Python学习笔记(4)：图像阈值与图像平滑"},{"content":"26. 剑指 Offer 30. 包含min函数的栈(简单) 双栈：一个栈存储数据，一个栈存储最小值\nclass MinStack: def __init__(self): self.stack=[] self.minstack=[inf] def push(self, x: int) -\u0026gt; None: self.stack.append(x) self.minstack.append(min(x,self.minstack[-1])) def pop(self) -\u0026gt; None: self.stack.pop() self.minstack.pop() def top(self) -\u0026gt; int: return self.stack[-1] def min(self) -\u0026gt; int: return self.minstack[-1] 27. 剑指 Offer 31. 栈的压入、弹出序列 模拟：按顺序push，若和popped值相等，则pop，最后判断栈是否为空。\nclass Solution: def validateStackSequences(self, pushed: List[int], popped: List[int]) -\u0026gt; bool: stack,i=[],0 for num in pushed: stack.append(num) while stack and stack[-1]==popped[i]: stack.pop() i+=1 return not stack 28. 剑指 Offer 32 - II. 从上到下打印二叉树 II(简单) BFS\nclass Solution: def levelOrder(self, root: TreeNode) -\u0026gt; List[List[int]]: if not root: return [] ans,queue=[],[root] while queue: tmp=[] for i in range(len(queue)): node=queue.pop(0) tmp.append(node.val) if node.left: queue.append(node.left) if node.right: queue.append(node.right) ans.append(tmp) return ans 29. 剑指 Offer 33. 二叉搜索树的后序遍历序列 递归：找到第一个大于列表末尾(根节点)的位置，即为左右子树划分的点；判断右子树序列中是否所有节点都大于根节点(p==j)\nclass Solution: def verifyPostorder(self, postorder: List[int]) -\u0026gt; bool: def recur(i,j): if i\u0026gt;=j: return True p = i while postorder[p]\u0026lt;postorder[j]: p+=1 m=p while postorder[p]\u0026gt;postorder[j]: p+=1 return p==j and recur(i,m-1) and recur(m,j-1) return recur(0,len(postorder)-1) 单调栈：\n将后序遍历的序列倒序，即为根|右子树|左子树； 此时对于升序arr[i+1]\u0026gt;arr[i]，i+1一定是i的右节点； 对于倒序arr[i+1]\u0026lt;arr[i]，i+1是某节点root的左节点，且root为0~i中大于且最接近i+1的节点。 单调栈存储升序节点 遇到降序节点时，通过出栈来更新root 若arr[i]\u0026gt;root: 返回false；若arr[i]\u0026lt;root，满足定义，继续遍历 class Solution: def verifyPostorder(self, postorder: [int]) -\u0026gt; bool: stack, root = [], float(\u0026#34;+inf\u0026#34;) for i in range(len(postorder) - 1, -1, -1): if postorder[i] \u0026gt; root: return False while(stack and postorder[i] \u0026lt; stack[-1]): root = stack.pop() stack.append(postorder[i]) return True 30. 剑指 Offer 34. 二叉树中和为某一值的路径(中等) 回溯：\nclass Solution: def pathSum(self, root: TreeNode, target: int) -\u0026gt; List[List[int]]: ans,path=[],[] def dfs(node,s): if not node: return s+=node.val path.append(node.val) if s==target and not node.left and not node.right: ans.append(path[:]) dfs(node.left,s) dfs(node.right,s) path.pop() dfs(root,0) return ans 31. 剑指 Offer 35. 复杂链表的复制(中等) 拼接链表：\n第一次遍历构建原节点1--\u0026gt;新节点1--\u0026gt;原节点2--\u0026gt;新节点2的链表； 第二次遍历构建新链表的random指向：old.next.random = old.random.next 第三次遍历拆分原/新链表 class Solution: def copyRandomList(self, head: \u0026#39;Node\u0026#39;) -\u0026gt; \u0026#39;Node\u0026#39;: if not head: return None p=head while p: node = Node(p.val) p.next,node.next=node,p.next p=p.next.next p=head while p: if p.random: p.next.random = p.random.next p=p.next.next ans=p=head.next while p.next: p.next = p.next.next p=p.next return ans 哈希表：构建原链表节点和新链表节点的映射关系，\ndic[old]=new dic[old].next = dic[old.next] dic[old].random = dic[old.random] class Solution: def copyRandomList(self, head: \u0026#39;Node\u0026#39;) -\u0026gt; \u0026#39;Node\u0026#39;: if not head: return None dic,p={},head while p: dic[p]=Node(p.val) p=p.next p=head while p: dic[p].next = dic.get(p.next,None) dic[p].random = dic.get(p.random,None) p=p.next return dic[head] 32. 剑指 Offer 36. 二叉搜索树与双向链表(中等) 中序遍历：记录前驱节点和当前节点，self.pre.right,cur.left=cur,self.pre\nclass Solution: def treeToDoublyList(self, root: \u0026#39;Node\u0026#39;) -\u0026gt; \u0026#39;Node\u0026#39;: def dfs(node): if not node: return None dfs(node.left) if self.pre: self.pre.right,node.left=node,self.pre else: self.head=node self.pre=node dfs(node.right) if not root: return None self.pre=None dfs(root) self.pre.right,self.head.left=self.head,self.pre return self.head 33. 剑指 Offer 37. 序列化二叉树(困难) 层序遍历：反序列化时采用BFS和一个idx指针，idx指针指向的分别是当前节点的左节点和右节点\nclass Codec: def serialize(self, root): if not root: return \u0026#34;None\u0026#34; res = [] queue=[root] while queue: node = queue.pop(0) if node: res.append(str(node.val)) queue.append(node.left) queue.append(node.right) else: res.append(\u0026#39;N\u0026#39;) return \u0026#39;,\u0026#39;.join(res) def deserialize(self, data): if data==\u0026#39;None\u0026#39;: return None data,i = data.split(\u0026#39;,\u0026#39;),1 root=TreeNode(int(data[0])) queue=[root] while queue: node=queue.pop(0) if data[i]!=\u0026#39;N\u0026#39;: node.left=TreeNode(int(data[i])) queue.append(node.left) i+=1 if data[i]!=\u0026#39;N\u0026#39;: node.right=TreeNode(int(data[i])) queue.append(node.right) i+=1 return root 34. 剑指 Offer 38. 字符串的排列 回溯：dfs(idx)表示固定idx位置的字符；用dic=set()记录当前位置已经使用过的字符，达到剪枝的目的；遍历idx到len(lst)-1位置，依次将其固定至idx位置。\nclass Solution: def permutation(self, s: str) -\u0026gt; List[str]: lst,ans=list(s),[] def dfs(idx): if idx==len(lst)-1: ans.append(\u0026#39;\u0026#39;.join(lst)) return dic=set() for i in range(idx,len(lst)): if lst[i] in dic: continue dic.add(lst[i]) lst[i],lst[idx]=lst[idx],lst[i] dfs(idx+1) lst[i],lst[idx]=lst[idx],lst[i] dfs(0) return ans 35. 剑指 Offer 39. 数组中出现次数超过一半的数字(简单) 哈希表统计：用哈希表统计各数字出现的次数\n数组排序法：排序后的数组中点为众数\n摩尔投票法：票数正负抵消\nclass Solution: def majorityElement(self, nums: List[int]) -\u0026gt; int: ans,cnt=-1,0 for num in nums: if cnt==0: ans=num cnt+=1 if ans==num else -1 return ans 36. 剑指 Offer 40. 最小的k个数(简单) 排序或者冒泡k次\n堆：时间复杂度O(nlogk)，空间复杂度O(k)\nimport heapq class Solution: def getLeastNumbers(self, arr: List[int], k: int) -\u0026gt; List[int]: if k==0: return [] heap=[-x for x in arr[:k]] heapq.heapify(heap) for i in range(k,len(arr)): if -arr[i]\u0026gt;heap[0]: heapq.heappushpop(heap,-arr[i]) return [-x for x in heap] 基于快排：每次划分得到哨兵的下标idx，若刚好等于k，则返回arr[:k]，否测递归划分\nimport random class Solution: def getLeastNumbers(self, arr: List[int], k: int) -\u0026gt; List[int]: def partition(nums,l,r): idx = l+random.randint(0,r-l) nums[idx],nums[l]=nums[l],nums[idx] ll,rr=l+1,r while True: while ll\u0026lt;=rr and nums[ll]\u0026lt;nums[l]: ll+=1 while ll\u0026lt;=rr and nums[rr]\u0026gt;nums[l]: rr-=1 if ll\u0026gt;rr: break nums[ll],nums[rr]=nums[rr],nums[ll] ll,rr=ll+1,rr-1 nums[l],nums[rr]=nums[rr],nums[l] if rr==k: return arr[:k] elif rr\u0026lt;k: return partition(arr,rr+1,r) else: return partition(arr,l,rr-1) if k\u0026gt;=len(arr): return arr return partition(arr,0,len(arr)-1) 37. 剑指 Offer 41. 数据流中的中位数(困难) 堆：用一个最小堆和最小堆存储数据，最大堆存储数据流左半部分数据，最小堆存储右半部分数据，保证len(heapL)-len(heapR)\u0026lt;=1。当两个堆长度相等时，中位数为两个堆顶的均值，否则为最大堆的堆顶值。\nimport heapq class MedianFinder: def __init__(self): self.heapl=[] self.heapr=[] def addNum(self, num: int) -\u0026gt; None: if not self.heapl or -num\u0026gt;=self.heapl[0]: heapq.heappush(self.heapl,-num) if len(self.heapl)-len(self.heapr)\u0026gt;1: tmp = -heapq.heappop(self.heapl) heapq.heappush(self.heapr,tmp) else: heapq.heappush(self.heapr,num) if len(self.heapl)\u0026lt;len(self.heapr): tmp = heapq.heappop(self.heapr) heapq.heappush(self.heapl,-tmp) def findMedian(self) -\u0026gt; float: if len(self.heapl)\u0026gt;len(self.heapr): return -self.heapl[0] return (-self.heapl[0]+self.heapr[0])/2 38. 剑指 Offer 42. 连续子数组的最大和(简单) 动态规划：dp[i]为以i结尾的最大子数组和，最终返回max(dp)\nclass Solution: def maxSubArray(self, nums: List[int]) -\u0026gt; int: s,n=0,len(nums) dp=[] for num in nums: dp.append(s+num) s=max(0,dp[-1]) return max(dp) 可以压缩存储空间如下：\nclass Solution: def maxSubArray(self, nums: List[int]) -\u0026gt; int: s,n=0,len(nums) ans = -inf for num in nums: ans = max(ans,s+num) s=max(0,s+num) return ans 39. 剑指 Offer 43. 1～n 整数中 1 出现的次数(困难) 数学，枚举：将数字n分为高位high，当前位cur，低位low，以及位因子digit。统计某位中1出现的次数，分类讨论如下：\n当cur=0：hight x digit，以2304为例，其出现1的范围为0010~2219，即229-0+1=230次； 当cur=1：high x digit + low + 1，以2314为例，其出现1的范围为0010~2314，即234-0+1=235次； 当cur=2,3,...,9：(high+1) x digit，以2374为例，出现1的范围为0010~2319，即239-0+1=240次。 class Solution: def countDigitOne(self, n: int) -\u0026gt; int: ans=0 high,cur,low,digit=n//10,n%10,0,1 while high or cur: if cur==0: ans+=high*digit elif cur==1: ans+=high*digit+low+1 else: ans+=(high+1)*digit high,cur,low,digit=high//10,high%10,low+cur*digit,digit*10 return ans 40. 剑指 Offer 44. 数字序列中某一位的数字(中等) 迭代+求整/求余：\n确定n所在的数字的位数digit：循环执行n减去一位数，两位数。。。的数位量count，直到n\u0026lt;=count； 确定n所在的数字num：num=start+(n-1)//2； 确定n是num种的哪一数位，返回结果：srt(num)[(n-1)%digit] class Solution: def findNthDigit(self, n: int) -\u0026gt; int: start,digit,cnt=1,1,9 while n\u0026gt;cnt: n-=cnt start,digit=start*10,digit+1 cnt=start*digit*9 num = start+(n-1)//digit return int(str(num)[(n-1)%digit]) 41. 剑指 Offer 46. 把数字翻译成字符串(中等) 动态规划：若s[i-1:i+1]位于10~25之间，则可以翻译在一起，此时dp[i]=dp[i-1]+dp[i-2]，否则dp[i]=dp[i-1]\nclass Solution: def translateNum(self, num: int) -\u0026gt; int: s = str(num) n=len(s) dp=[1,1]+[0]*(n-1) for i in range(1,n): if s[i-1] in [\u0026#39;1\u0026#39;,\u0026#39;2\u0026#39;] and int(s[i-1:i+1])\u0026lt;26: dp[i+1]=dp[i]+dp[i-1] else: dp[i+1]=dp[i] return dp[-1] 42. 剑指 Offer 47. 礼物的最大价值(中等) 动态规划\nclass Solution: def maxValue(self, grid: List[List[int]]) -\u0026gt; int: m,n=len(grid),len(grid[0]) dp=[[0 for _ in range(n+1)]for _ in range(m+1)] for i in range(1,m+1): for j in range(1,n+1): dp[i][j]=max(dp[i-1][j],dp[i][j-1])+grid[i-1][j-1] return dp[-1][-1] 43. 剑指 Offer 48. 最长不含重复字符的子字符串(中等) 双指针+哈希表：哈希表记录字符最右的位置，当遍历到哈希表中存在的字符时，更新i为max(i,vis[s[j]])，每次计算最长长度j-i\nclass Solution: def lengthOfLongestSubstring(self, s: str) -\u0026gt; int: vis,ans,i={},0,-1 for j in range(len(s)): if s[j] in vis: i=max(i,vis[s[j]]) vis[s[j]]=j ans=max(ans,j-i) return ans 44. 剑指 Offer 49. 丑数(中等) 最小堆：每次取出堆顶元素x，然后将2x,3x,5x加入堆中，用哈希表去重，最后返回堆顶元素\nimport heapq class Solution: def nthUglyNumber(self, n: int) -\u0026gt; int: factors = [2,3,5] heap,vis=[1],{1} for i in range(n-1): curr = heapq.heappop(heap) for factor in factors: nxt = curr*factor if nxt not in vis: vis.add(nxt) heapq.heappush(heap,nxt) return heapq.heappop(heap) 动态规划：设置p2,p3,p5三个索引，dp[i]=min(dp[p2]*2,dp[p3]*3,dp[p5]*5)，独立判断dp[i]与这三个值的大小关系，若相等则将相应的索引+1\nclass Solution: def nthUglyNumber(self, n: int) -\u0026gt; int: dp=[1]*n p2,p3,p5=0,0,0 for i in range(1,n): n2,n3,n5=dp[p2]*2,dp[p3]*3,dp[p5]*5 dp[i]=min(n2,n3,n5) if dp[i]==n2: p2+=1 if dp[i]==n3: p3+=1 if dp[i]==n5: p5+=1 return dp[-1] 45. 剑指 Offer 50. 第一个只出现一次的字符(简单) 有序哈希表：OrderedDict()\nclass Solution: def firstUniqChar(self, s: str) -\u0026gt; str: dic = collections.OrderedDict() for c in s: dic[c] = not c in dic for k,v in dic.items(): if v: return k return \u0026#39; \u0026#39; 46. 剑指 Offer 51. 数组中的逆序对(困难) 归并排序：在归并排序的合并阶段，每当遇到左子数组当前元素\u0026gt;右子数组当前元素，意味着左子数组当前元素至末尾元素与右子树组当前元素构成了若干逆序对\nclass Solution: def reversePairs(self, nums: List[int]) -\u0026gt; int: def merge(l,r): if l\u0026gt;=r: return 0 m=l+(r-l)//2 res = merge(l,m)+merge(m+1,r) tmp[l:r+1]=nums[l:r+1] i,j=l,m+1 for k in range(l,r+1): if i==m+1: nums[k]=tmp[j] j+=1 elif j==r+1 or tmp[i]\u0026lt;=tmp[j]: nums[k]=tmp[i] i+=1 else: nums[k]=tmp[j] res+= m-i+1 j+=1 return res tmp=[0]*len(nums) return merge(0,len(nums)-1) 47. 剑指 Offer 52. 两个链表的第一个公共节点(简单) 双指针：当指针为空时，转移到另一个链表表头；当两个指针相遇时，即为第一个公共节点\nclass Solution: def getIntersectionNode(self, headA: ListNode, headB: ListNode) -\u0026gt; ListNode: pA,pB=headA,headB while pA!=pB: pA=pA.next if pA else headB pB=pB.next if pB else headA return pA ","permalink":"https://Achilles-10.github.io/posts/algo/offer2/","summary":"26. 剑指 Offer 30. 包含min函数的栈(简单) 双栈：一个栈存储数据，一个栈存储最小值 class MinStack: def __init__(self): self.stack=[] self.minstack=[inf] def push(self, x: int) -\u0026gt; None: self.stack.append(x) self.minstack.append(min(x,self.minstack[-1])) def pop(self) -\u0026gt; None: self.stack.pop() self.minstack.pop() def top(self) -\u0026gt; int: return self.stack[-1] def min(self) -\u0026gt; int: return self.minstack[-1] 27. 剑指 Offer 31. 栈的压入、弹出序列 模拟：按顺序push，若和popped值相等，则pop，最后判断栈是否为空。 class Solution: def validateStackSequences(self, pushed: List[int], popped: List[int]) -\u0026gt; bool: stack,i=[],0 for num in pushed: stack.append(num) while stack and","title":"剑指offer复习笔记(2)"},{"content":"[paper] [code]\n引言 由于通道注意力在特征建模上的简单性和有效性，成为深度学习领域流行的工具。而全局平均池化（GAP）由于其简单性成为了默认选择，但它的简单性也使得它很难很好地捕获各种输入的复杂信息。\n本文将信道的标量表示看作一个压缩问题。也就是说，一个通道的信息应该被一个标量紧凑地编码，同时尽可能地保留整个通道的表示能力。而如何有效地压缩具有标量的信道是一大难点。\n由于DCT的高压缩比可以满足用标量表示信道注意力的需求，以及它可微的性质可以简单地集成到CNN中，选择DCT定制通道注意力。本文主要贡献如下：\n把通道注意力看作一个压缩问题，并在通道注意力中引入DCT。证明了传统GAP是DCT的一个特例。基于这一证明，在频域推广了通道注意力，并提出了多谱通道注意力框架（Multi-Spectral Channel Attention , MSCA），称为FcaNet； 我们提出了三种频率成分选择标准（LF低频选择，TS两步选择，NAS神经架构搜索选择）以及所提出的多光谱通道注意框架来实现FcaNet。 在ImageNet和COCO数据集上达到SOTA水平。 方法 回顾DCT和通道注意力 DCT： $$ f^{2d}_{h,w}=\\sum_{i=0}^{H-1}\\sum_{j=0}^{W-1}{x^{2d}_{i,j}B^{i,j}_{h,w}}\\\\ B^{i,j}_{h,w}=\\cos(\\frac{\\pi h}{H}(i+\\frac{1}{2}))\\cos(\\frac{\\pi w}{W}(j+\\frac{1}{2}))\\tag{1} $$\n通道注意力：通道注意力用标量来表示和评估每个通道的重要性，可以写成如下形式： $$ att=sigmoid(fc(compress(X))) $$ compress: $\\mathbb {R}^{C\\times H\\times W}\\rightarrow\\mathbb{R}^C$ 是压缩方法。全局平均池化（GAP）可以视作一种压缩方法。\n多谱通道注意力（Multi-Spectral Channel Attention，MSCA） 通道注意力的理论分析，定理1：GAP是2D DCT的特例，其结果与2D DCT的最低频率成分成正比。\n证明：在公式(1)中，令h和w为0，有\n$$ \\begin{align} f^{2d}_{0,0} \u0026amp;=\\sum_{i=0}^{H-1}\\sum_{j=0}^{W-1}{x^{2d}_{i,j}B^{i,j}_{0,0}}\\\\ \u0026amp;=\\sum_{i=0}^{H-1}\\sum_{j=0}^{W-1}x^{2d}_{i,j}\\\\ \u0026amp;=GAP(x^{2d})\\cdot HW \\end{align}\\tag{2} $$\n在公式(2)中，$f^{2d}_{0,0}$表示2D DCT的最低频率成分，与GAP成正比，定理1得证。\n多谱通道注意力模块：\n通过定理1可知，在使用通道注意力中使用GAP意味着只保留了最低频的信息，为了更好地压缩信道并引入更多信息，需要利用DCT中更多的频率信息。\n首先，将输入X沿通道方向分块为$[X^0,X^1,\\dots,X^{n-1}]$，其中$X^i\\in\\mathbb{R}^{C\u0026rsquo;\\times H\\times W},\\ C\u0026rsquo;=\\frac{C}{n}$，C能被n整除。对每部分进行2D DCT操作，有： $$ Freq^i=2\\text{DDCT}(X^i) $$ 最终的压缩向量可以表示如下： $$ \\begin{align} Freq\u0026amp;=compress(X)\\ \u0026amp;=cat([Freq^0,Freq^1,\\dots,Freq^{n-1}]) \\end{align} $$ 最终的多谱注意力表示如下： $$ ms_att=sigmoid(fc(Freq)) $$\n频率成分选择标准（Criteria for Choosing Frequency Components）\n提出三种选择频率成分的标准：\nFcaNet-LF：选择低频成分 FceNet-TS：通过两步选择方案确定，首先确定每个频率分量的重要性，然后评估不同频率分量数量的效果 FcaNet-NAS：通过神经架构搜索来搜索通道的最佳频率成分 实验 消融实验 单体频率分量的影响（The effects of individual frequency components）\nImageNet上的最小特征图大小为7x7，因此将2D DCT的频率空间划分为7x7，测试每部分的性能如下图（TOP-1 准确率）：\n可以看出，低频有更好的表现，也验证了SENet的成功和深度网络偏好低频信息的结论。然而几乎所有的频率成分(除最高频率外)与最低频率成分之间的差距非常小(\u0026lt;=0.5% Top-1准确率)。这说明其他频率成分也能很好地应对通道注意力机制，在频域上泛化通道注意力是有效的。\n频率分量的数量的影响（The effects of different numbers of frequency components）\n对于TS，选取上图中Top-K性能最高的频率成分；对于LF，选取K个最低频率成分的结果。结果如下图所示，可以发现：\n使用多谱注意力的性能比仅使用通道注意力中的GAP都有提高 当k=2和16时效果最好 与完全可学习的通道注意力相比：2D DCT的基函数可以看做是包含DCT系数的张量\nFR：Fixed tensor with Random initialization，随机初始化固定张量\nLR：Learned tensor with Random initialization，随机初始化可学习张量\nLD：Learned tensor with DCT initialization，DCT初始化可学习张量\nFD：Fixed tensor with DCT initialization，DCT初始化固定张量\n讨论 多谱框架（multi-spectrum framework）如何压缩和嵌入更多信息：\n由于深度网络是冗余的，若两个通道是冗余的，则通过GAP只能得到相同的信息；而在多谱注意力中，不同的频率分量包含不同的信息，因此可以从冗余通道中提取更多的信息。\n复杂度分析：\nDCT权重是预定义的常数，没有额外参数；额外计算成本与SENet相当。\n代码实现：\n多谱注意力与SENet的区别仅在于信道压缩方法（GAP vs. multi-spectrum 2D DCT），2D DCT可以看做是输入的加权和，因此该方法可以很容易地集成到任意通道注意力方法中。\n在ImageNet上的图像分类 在COCO上的目标检测 ","permalink":"https://Achilles-10.github.io/posts/paper/fcanet/","summary":"[paper] [code] 引言 由于通道注意力在特征建模上的简单性和有效性，成为深度学习领域流行的工具。而全局平均池化（GAP）由于其简单性成为了默认选择，但它的简单性也使得它很难很好地捕获各种输入的复杂信息。 本文将信道的标量表示看作一个压缩问题。也就是说，一个通道的信息应该被一个标量紧凑地编码，同时尽","title":"FcaNet: Frequency Channel Attention Networks"},{"content":"变换 OpenCV提供了cv2.warpAffine和cv2.warpPerspective两个转换函数，cv2.warpAffine采用2x3的转换矩阵，cv2.warpPerspective采用3x3转换矩阵。\n缩放 使用cv2.resize实现图像的缩放，可以指定缩放尺寸或缩放比例，以及插值方法。首选的插值方法是用于缩小的 cv2.INTER_AREA 和用于缩放的 cv2.INTER_CUBIC（慢）和 cv2.INTER_LINEAR。cv2.INTER_LINEAR是默认的缩放插值方法。可以用一下两种方法实现：\nimport numpy as np import cv2 img = cv2.imread(\u0026#39;face.png\u0026#39;) res = cv2.resize(img, None,fx=2, fy=2, interpolation = cv2.INTER_CUBIC) # OR height, width = img.shape[:2] res = cv2.resize(img,(2*width, 2*height), interpolation = cv2.INTER_CUBIC) 平移 如果在(x,y)方向上的平移量为$(t_x,t_y)$，则可以得到转换矩阵M: $$ M=\\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; t_x \\\\ 0 \u0026amp; 1 \u0026amp; t_y \\end{bmatrix} $$ 将其转换为np.float32的numpy数组并传入cv2.warpAffine函数，以平移(100,50)为例：\nrows,cols,_ = img.shape M = np.float32([[1,0,100],[0,1,50]]) dst = cv2.warpAffine(img,M,(cols,rows)) cv2.warpAffine的第三个参数是输出图像的大小，形式为(width,height)\n旋转 图像旋转角度为$\\theta$是通过以下变换矩阵实现的： $$ M = \\begin{bmatrix} \\cos\\theta \u0026amp; -\\sin\\theta \\\\ \\sin\\theta \u0026amp; \\cos\\theta \\end{bmatrix} $$ OpenCV提供了可缩放的旋转和可调整的旋转中心，修改后的变换矩阵为： $$ \\begin{bmatrix} \\alpha \u0026amp; \\beta \u0026amp; (1- \\alpha ) \\cdot center.x - \\beta \\cdot center.y \\\\ - \\beta \u0026amp; \\alpha \u0026amp; \\beta \\cdot center.x + (1- \\alpha ) \\cdot center.y \\end{bmatrix} $$ 其中： $$ \\alpha=scale\\cdot\\cos\\theta,\\\\\\beta=scale\\cdot\\sin\\theta $$ 为了得到该变换矩阵，OpenCV提供了cv2.getRotationMatrix2D函数，以将图像相对于中心旋转逆时针90度缩放比例为1：\nrows,cols,_ = img.shape # cols-1 和 rows-1 是坐标限制 M = cv2.getRotationMatrix2D(((cols-1)/2.0,(rows-1)/2.0),90,1) dst = cv2.warpAffine(img,M,(cols,rows)) 仿射变换（Affine Transformation） 在仿射转换中，原始图像中的所有并行线仍将在输出图像中平行。为了得到转换矩阵，需要从输入图像中的三个点及其在输出图像中的对应位置。通过cv2.getAffineTransform函数创建一个2x3的矩阵，并传递给cv2.warpAffine。\nrows,cols,ch = img.shape pts1 = np.float32([[100,100],[100,400],[400,100]]) pts2 = np.float32([[50,50],[100,400],[350,50]]) M = cv2.getAffineTransform(pts1,pts2) dst = cv2.warpAffine(img,M,(cols,rows)) 透视变换（Perspective Transformation） 透视转换需要一个3x3转换矩阵。即使在转换后，直线也将保持直线。需要在输入图像上有四个点，在输出图像中需要对应的四个点，其中三个点不共线。可通过cv2.getPersperctiveTransform得到变换矩阵，并传递给cv2.warpPerspective。\nrows,cols,ch = img.shape pts1 = np.float32([[40,100],[400,100],[0,400],[360,400]]) pts2 = np.float32([[0,0],[500,0],[0,500],[500,500]]) M = cv2.getPerspectiveTransform(pts1,pts2) dst = cv2.warpPerspective(img,M,(cols,rows)) ","permalink":"https://Achilles-10.github.io/posts/tech/opencv3/","summary":"变换 OpenCV提供了cv2.warpAffine和cv2.warpPerspective两个转换函数，cv2.warpAffine采用2x3的转换矩阵，cv2.warpPerspective采用3x3转换矩阵。 缩放 使用cv2.resize实现图像的缩放，可以指定缩放尺寸或缩放比","title":"OpenCV-Python学习笔记(3)：几何变换"},{"content":"1. 剑指 Offer 03. 数组中重复的数字(简单) 哈希表：用哈希表（Set）记录遍历到的数字，若找到重复的数字则返回。\n原地交换：数组元素的索引和值是一对多的关系。因此，可遍历数组并通过交换操作，使元素的索引与值一一对应（即$nums[i]=i$）。\n算法流程\n遍历数组，索引初始值i=0; 若nums[i]=i：说明该数字已在对应的索引处，无需交换，跳过； 若nums[nums[i]]=nums[i]：说明索引nums[i]处和索引i处的值均为nums[i]，即找到一组重复，返回nums[i]； 否则交换nums[nums[i]]与nums[i]； 若遍历完未返回，返回-1。 复杂度：时间O(N)，空间O(1)\n代码：\nclass Solution: def findRepeatNumber(self, nums: List[int]) -\u0026gt; int: n=len(nums) i=0 while i\u0026lt;n: if nums[i]==i: i+=1 continue if nums[nums[i]]==nums[i]: return nums[i] nums[nums[i]],nums[i]=nums[i],nums[nums[i]] Python中a,b=c,d的原理是暂存元组(c,d)，然后按左右顺序赋值，在此处需要先给nums[nums[i]]赋值。\n2. 剑指 Offer 04. 二维数组中的查找(中等) 暴力法：时间复杂度O(MN)，未利用到数组的排序信息\n二分法：时间复杂度O(M+N)\n如下图，考虑将二维数组旋转45°，类似一棵二叉搜索树：故我们可以从数组的左下角(n-1,0)或右上角(0,m-1)开始，运用二分的思想进行搜索。\nclass Solution: def findNumberIn2DArray(self, matrix: List[List[int]], target: int) -\u0026gt; bool: i,j=len(matrix)-1,0 while 0\u0026lt;=i and j\u0026lt;len(matrix[0]): if target==matrix[i][j]: return True elif target\u0026gt;matrix[i][j]: j+=1 else: i-=1 return False 3. 剑指 Offer 05. 替换空格(简单) 库函数:return s.replace(' ','%20')\n遍历添加：初始化一个新的str，时间空间复杂度O(N)\n原地修改(python str是不可修改，无法实现)：\n遍历得到空格数cnt 修改s长度为len+2*cnt 倒序遍历，i指向原字符串末尾，j指向新字符串末尾，当i=j时跳出（左方已没有空格）； s[i]=' '：s[j-2:j]=\u0026rsquo;%20\u0026rsquo;，j-=2 s[i]!=' '：s[j]=s[i] string replaceSpace(string s) { int count = 0, len = s.size(); for (char c : s) { if (c == \u0026#39; \u0026#39;) count++; } s.resize(len + 2 * count); for(int i = len - 1, j = s.size() - 1; i \u0026lt; j; i--, j--) { if (s[i] != \u0026#39; \u0026#39;) s[j] = s[i]; else { s[j - 2] = \u0026#39;%\u0026#39;; s[j - 1] = \u0026#39;2\u0026#39;; s[j] = \u0026#39;0\u0026#39;; j -= 2; } } return s; } 4. 剑指 Offer 06. 从尾到头打印链表(简单) 辅助栈：遍历链表，将各节点入栈，返回倒序列表。时间空间复杂度O(N)\n递归：时间空间复杂度O(N)\nclass Solution: def reversePrint(self, head: ListNode) -\u0026gt; List[int]: return self.reversePrint(head.next) + [head.val] if head else [] 5. 剑指 Offer 07. 重建二叉树(中等) 递归：\npreorder=[root,L,R], inorder=[L,root,R]\n找到root在inorder中的下标，构建root的左右子树\nclass Solution: def buildTree(self, preorder: List[int], inorder: List[int]) -\u0026gt; TreeNode: if not preorder: return None root=TreeNode(preorder[0]) rootidx=inorder.index(preorder[0]) root.left=self.buildTree(preorder[1:rootidx+1],inorder[:rootidx]) root.right=self.buildTree(preorder[rootidx+1:],inorder[rootidx+1:]) return root 迭代：待续\n6. 剑指 Offer 09. 用两个栈实现队列(简单) 双栈：将一个栈当作输入栈，用于将数据入队；另一个栈当作输出栈，用于数据出队。每次出队时，若输出栈不为空，则直接从输出栈弹出；否则现将所有数据从输入栈弹出并压入输出栈，再从输出栈弹出。 class CQueue: def __init__(self): self.stack1, self.stack2=[],[] def appendTail(self, value: int) -\u0026gt; None: self.stack1.append(value) def deleteHead(self) -\u0026gt; int: if self.stack2: return self.stack2.pop() if not self.stack1: return -1 while self.stack1: self.stack2.append(self.stack1.pop()) return self.stack2.pop() 7. 剑指 Offer 10- I. 斐波那契数列(简单) 动态规划：\nclass Solution: def fib(self, n: int) -\u0026gt; int: a,b=0,1 while n: a,b=b,a+b n-=1 return a%(10**9+7) 矩阵快速幂：时间复杂度O(log n)，空间复杂度O(1)\n$$ \\left[\\begin{matrix} 1\u0026amp;1 \\\\ 1\u0026amp;0 \\end{matrix} \\right] \\left[\\begin{matrix} F(n) \\\\ F(n-1) \\end{matrix} \\right] = \\left[ \\begin{matrix} F(n)+F(n-1)\\\\ F(n) \\end{matrix} \\right] =\\left[\\begin{matrix} F(n+1) \\\\ F(n) \\end{matrix}\\right] $$\n$$ \\left[\\begin{matrix} F(n+1) \\\\ F(n) \\end{matrix}\\right] = \\left[\\begin{matrix} 1\u0026amp;1 \\\\ 1\u0026amp;0 \\end{matrix} \\right]^n \\left[\\begin{matrix} F(1) \\\\ F(0) \\end{matrix}\\right] $$\n令： $$ M=\\left[\\begin{matrix} 1\u0026amp;1 \\\\ 1\u0026amp;0 \\end{matrix} \\right] $$ 关键在于快速计算矩阵M的n次幂。\nclass Solution: def fib(self, n: int) -\u0026gt; int: MOD = 10 ** 9 + 7 if n \u0026lt; 2: return n def multiply(a: List[List[int]], b: List[List[int]]) -\u0026gt; List[List[int]]: c = [[0, 0], [0, 0]] for i in range(2): for j in range(2): c[i][j] = (a[i][0] * b[0][j] + a[i][1] * b[1][j]) % MOD return c def matrix_pow(a: List[List[int]], n: int) -\u0026gt; List[List[int]]: ret = [[1, 0], [0, 1]] while n \u0026gt; 0: if n \u0026amp; 1: ret = multiply(ret, a) n \u0026gt;\u0026gt;= 1 a = multiply(a, a) return ret res = matrix_pow([[1, 1], [1, 0]], n - 1) return res[0][0] 8. 剑指 Offer 11. 旋转数组的最小数字(简单) 二分法：\n如下图，考虑数组最后一个元素x，最小值右侧的元素一定小于等于x，最小值左侧的元素一定大于等于x。\n可以分为三种情况：\nnums[mid]\u0026gt;x：left=mid+1 nums[mid]\u0026lt;x：right=mid nums[mid]=x：此时无法判断nums[mid]在最小值左侧还是右侧，但可以确定nums[right]有nums[mid]这个替代值，故可以忽略右端点。right-=1 class Solution: def minArray(self, numbers: List[int]) -\u0026gt; int: n=len(numbers) l,r=0,n-1 while l\u0026lt;r: mid = l+(r-l)//2 if numbers[mid]\u0026gt;numbers[r]: l=mid+1 elif numbers[mid]\u0026lt;numbers[r]: r=mid else: r-=1 return numbers[l] 9. 剑指 Offer 12. 矩阵中的路径(中等) 回溯(DFS)：时间复杂度$O(MN3^L)$，空间复杂度O(MN)\n用backtracking(i,j,idx)表示从位置(i,j)出发能否匹配字符串word[idx:]，执行步骤如下：\n若board[i][j]!=word[idx]，不匹配返回False 若当前字符匹配且到了字符串末尾，返回True 否则，遍历当前相邻位置 class Solution: def exist(self, board: List[List[str]], word: str) -\u0026gt; bool: m,n=len(board),len(board[0]) vis=set() directions=[(1,0),(-1,0),(0,1),(0,-1)] def backtracking(i,j,idx): if board[i][j]!=word[idx]: return False if idx==len(word)-1: return True vis.add((i,j)) flag=False for di,dj in directions: ii,jj=i+di,j+dj if 0\u0026lt;=ii\u0026lt;m and 0\u0026lt;=jj\u0026lt;n and (ii,jj) not in vis: if backtracking(ii,jj,idx+1): flag=True break vis.remove((i,j)) return flag for i in range(m): for j in range(n): if backtracking(i,j,0): return True return False 10. 剑指 Offer 14- I. 剪绳子(中等) 动态规划：时间空间复杂度O(n)\ndp[1]=1,dp[2]=1,状态转移方程： $$ dp[i]=max(2*dp[i-2],3*dp[i-3],2*(i-2),3*(i-3)) $$\nclass Solution: def cuttingRope(self, n: int) -\u0026gt; int: dp=[0]*(n+1) dp[1]=dp[2]=1 for i in range(3,n+1): dp[i]=max(2*dp[i-2],3*dp[i-3],2*(i-2),3*(i-3)) return dp[n] 数学推导（贪心）:\nclass Solution: def cuttingRope(self, n: int) -\u0026gt; int: if n\u0026lt;4: return n-1 a,b=n//3,n%3 if b==1: return int(math.pow(3,a-1)*4) elif b==2: return int(math.pow(3,a)*2) return int(math.pow(3,a)) 11. 剑指 Offer 15. 二进制中1的个数(简单) 循环遍历\n位运算优化：时间复杂度O(log n)。每次将n与n-1做与操作，可以将n的最低位的1变为0。例如6(110)\u0026amp;5(101)=4(100)。\nclass Solution: def hammingWeight(self, n: int) -\u0026gt; int: ans=0 while n: n\u0026amp;=(n-1) ans+=1 return ans 12. 剑指 Offer 16. 数值的整数次方(中等) 快速幂乘法：递归和迭代\nclass Solution: def myPow(self, x: float, n: int) -\u0026gt; float: # 迭代 def quickMul(n): ans=1.0 xx=x while n: if n\u0026amp;1: ans*=xx xx*=xx n\u0026gt;\u0026gt;=1 return ans return quickMul(n) if n\u0026gt;=0 else 1/quickMul(-n) class Solution: def myPow(self, x: float, n: int) -\u0026gt; float: def quickMul(n): if n==0: return 1.0 y=quickMul(n//2) return y*y if n\u0026amp;1==0 else y*y*x return quickMul(n) if n\u0026gt;=0 else 1/quickMul(-n) 13. 剑指 Offer 17. 打印从1到最大的n位数(简单) DFS：用字符串来正确表示大数（本题不需要），依次遍历长度1~n的数，第一位只能为1~9，其他位为0~9。\nclass Solution: def printNumbers(self, n: int) -\u0026gt; List[int]: ans=[] def dfs(k,n,s): if k==n: ans.append(int(s)) return for i in range(10): dfs(k+1,n,s+str(i)) for i in range(1,n+1): for j in range(1,10): dfs(1,i,str(j)) return ans 15. 剑指 Offer 18. 删除链表的节点(简单) 前驱结点遍历：考虑要删除节点为头结点的特殊情况。\nclass Solution: def deleteNode(self, head: ListNode, val: int) -\u0026gt; ListNode: if head.val==val: return head.next pre,p=head,head.next while p and p.val!=val: pre,p=p,p.next if p: pre.next = p.next return head 16. 剑指 Offer 19. 正则表达式匹配(困难) 动态规划：\ndp[i][j]表示s[:i]与p[:j]是否匹配，考虑以下情况：\np[j]='*': 若s[i]与p[j-1不匹配，则p[j-1]匹配零次即为dp[i][j]=dp[i][j-2]；否则p[j-1]匹配1次或多次，即dp[i][j]=dp[i-1][j] or dp[i][j-2] p[j]!='*'：若s[i]与p[j]匹配，则dp[i][j]=dp[i-1[j-1] s[i]与p[j]匹配时满足，s[i]=p[j] or p[j]=='.' 初始化时，dp[0][0]=True，考虑s为空数组，只有p的偶数位为*时能够匹配 class Solution: def isMatch(self, s: str, p: str) -\u0026gt; bool: m,n=len(s),len(p) dp = [[False for _ in range(n+1)]for _ in range(m+1)] dp[0][0]=True for j in range(2,n+1,2): if p[j-1]==\u0026#39;*\u0026#39;: dp[0][j]=dp[0][j-2] for i in range(1,m+1): for j in range(1,n+1): if p[j-1]==\u0026#39;*\u0026#39;: if s[i-1]==p[j-2] or p[j-2]==\u0026#39;.\u0026#39;: dp[i][j]=dp[i-1][j] or dp[i][j-2] else: dp[i][j]=dp[i][j-2] else: if s[i-1]==p[j-1] or p[j-1]==\u0026#39;.\u0026#39;: dp[i][j]=dp[i-1][j-1] return dp[-1][-1] 17. 剑指 Offer 20. 表示数值的字符串(中等) 模拟\n有限状态机：定义状态-\u0026gt;画状态转移图-\u0026gt;编写代码\n字符类型：空格 ，数字1-9，正负号+-，小数点.，幂符号eE。\n状态定义：\n开始的空格 幂符号前的正负号 小数点前的数字 小数点，小数点后的数字 当小数点前为空格时，小数点和小数点后的数字 幂符号 幂符号后的正负号 幂符号后的数字 结尾的空格 状态转移图：\nclass Solution: def isNumber(self, s: str) -\u0026gt; bool: states = [ {\u0026#39; \u0026#39;:0,\u0026#39;s\u0026#39;:1,\u0026#39;d\u0026#39;:2,\u0026#39;.\u0026#39;:4}, # 0. start with \u0026#39;blank\u0026#39; {\u0026#39;d\u0026#39;:2,\u0026#39;.\u0026#39;:4}, # 1. \u0026#39;sign\u0026#39; before \u0026#39;e\u0026#39; {\u0026#39;d\u0026#39;:2,\u0026#39;.\u0026#39;:3,\u0026#39;e\u0026#39;:5,\u0026#39; \u0026#39;:8}, # 2. \u0026#39;digit\u0026#39; before \u0026#39;dot\u0026#39; {\u0026#39;d\u0026#39;:3,\u0026#39;e\u0026#39;:5,\u0026#39; \u0026#39;:8}, # 3. \u0026#39;digit\u0026#39; after \u0026#39;dot\u0026#39; {\u0026#39;d\u0026#39;:3}, # 4. \u0026#39;digit\u0026#39; after \u0026#39;dot\u0026#39; (‘blank’ before \u0026#39;dot\u0026#39;) {\u0026#39;s\u0026#39;:6,\u0026#39;d\u0026#39;:7}, # 5. \u0026#39;e\u0026#39; {\u0026#39;d\u0026#39;:7}, # 6. \u0026#39;sign\u0026#39; after \u0026#39;e\u0026#39; {\u0026#39;d\u0026#39;:7,\u0026#39; \u0026#39;:8}, # 7. \u0026#39;digit\u0026#39; after \u0026#39;e\u0026#39; {\u0026#39; \u0026#39;:8} # 8. end with \u0026#39;blank\u0026#39; ] p = 0 # start with state 0 for c in s: if \u0026#39;0\u0026#39;\u0026lt;=c\u0026lt;=\u0026#39;9\u0026#39;: t = \u0026#39;d\u0026#39; # digit elif c in \u0026#34;+-\u0026#34;: t = \u0026#39;s\u0026#39; # sign elif c in \u0026#34;eE\u0026#34;: t = \u0026#39;e\u0026#39; # e or E elif c in \u0026#34;. \u0026#34;: t = c # dot, blank else: t = \u0026#39;?\u0026#39; # unknown if t not in states[p]: return False p = states[p][t] return p in (2, 3, 7, 8) 18. 剑指 Offer 21. 调整数组顺序使奇数位于偶数前面(简单) 双指针交换\nclass Solution: def exchange(self, nums: List[int]) -\u0026gt; List[int]: i,j=0,len(nums)-1 while i\u0026lt;j: while i\u0026lt;j and nums[i]%2: i+=1 while i\u0026lt;j and nums[j]%2==0: j-=1 nums[i],nums[j]=nums[j],nums[i] return nums 19. 剑指 Offer 22. 链表中倒数第k个节点(简单) 双指针：让快指针先走k个节点\nclass Solution: def getKthFromEnd(self, head: ListNode, k: int) -\u0026gt; ListNode: former, latter = head, head for _ in range(k): former = former.next while former: former, latter = former.next, latter.next return latter 20. 剑指 Offer 24. 反转链表(简单) 迭代（双指针）：\nclass Solution: def reverseList(self, head: ListNode) -\u0026gt; ListNode: pre,cur=None,head while cur: cur.next,pre,cur=pre,cur,cur.next return pre 递归：\nclass Solution: def reverseList(self, head: ListNode) -\u0026gt; ListNode: def recur(pre,cur): if not cur: return pre res = recur(cur,cur.next) cur.next=pre return res return recur(None,head) 21. 剑指 Offer 25. 合并两个排序的链表(简单) 递归：\nclass Solution: def mergeTwoLists(self, l1: ListNode, l2: ListNode) -\u0026gt; ListNode: if not l1 or not l2: return l1 or l2 if l1.val\u0026lt;l2.val: l1.next = self.mergeTwoLists(l1.next,l2) return l1 else: l2.next = self.mergeTwoLists(l1,l2.next) return l2 22. 剑指 Offer 26. 树的子结构(中等) 先序遍历：\n分为两步，先序遍历树A中的每个节点$n_A$；判断以$n_A$为根节点的子树是否包含树B。\nsame函数判断以$n_A$为根节点的子树是否包含树B，若B为空，则表示树B匹配完成，返回True；若A为空，则说明越过A，返回False；若A和B值不同，则不匹配，返回False。\nclass Solution: def isSubStructure(self, A: TreeNode, B: TreeNode) -\u0026gt; bool: def same(A,B): if not B: return True if not A: return False return A.val==B.val and same(A.left,B.left) and same(A.right,B.right) return bool(A and B) and (same(A,B) or self.isSubStructure(A.left,B) or self.isSubStructure(A.right,B)) 23. 剑指 Offer 27. 二叉树的镜像(简单) 递归：注意同时赋值或者临时保存子树\nclass Solution: def mirrorTree(self, root: TreeNode) -\u0026gt; TreeNode: if not root: return None root.left,root.right = self.mirrorTree(root.right),self.mirrorTree(root.left) return root 迭代：用栈保存节点\nclass Solution: def mirrorTree(self, root: TreeNode) -\u0026gt; TreeNode: if not root: return None stack=[root] while stack: node = stack.pop() if node.left: stack.append(node.left) if node.right: stack.append(node.right) node.left,node.right=node.right,node.left return root 24. 剑指 Offer 28. 对称的二叉树(简单) 递归：\nclass Solution: def isSymmetric(self, root: TreeNode) -\u0026gt; bool: def recur(L,R): if not L and not R: return True if not L or not R: return False return L.val==R.val and recur(L.left,R.right) and recur(L.right,R.left) return not root or recur(root.left,root.right) 迭代：\nclass Solution: def isSymmetric(self, root: TreeNode) -\u0026gt; bool: if not root or not (root.left or root.right): return True queue=[root.left,root.right] while queue: l=queue.pop(0) r=queue.pop(0) if not l and not r: continue if not l or not r or l.val!=r.val: return False queue.append(l.left) queue.append(r.right) queue.append(l.right) queue.append(r.left) return True 25. 剑指 Offer 29. 顺时针打印矩阵(简单) 设置边界：设置top，bottom，left，right，遍历\nclass Solution: def spiralOrder(self, matrix: List[List[int]]) -\u0026gt; List[int]: if not matrix: return [] top,bottom,left,right,ans=0,len(matrix)-1,0,len(matrix[0])-1,[] while True: for j in range(left,right+1): ans.append(matrix[top][j]) top+=1 if top\u0026gt;bottom: break for i in range(top,bottom+1): ans.append(matrix[i][right]) right-=1 if right\u0026lt;left: break for j in range(right,left-1,-1): ans.append(matrix[bottom][j]) bottom-=1 if top\u0026gt;bottom: break for i in range(bottom,top-1,-1): ans.append(matrix[i][left]) left+=1 if right\u0026lt;left: break return ans ","permalink":"https://Achilles-10.github.io/posts/algo/offer1/","summary":"1. 剑指 Offer 03. 数组中重复的数字(简单) 哈希表：用哈希表（Set）记录遍历到的数字，若找到重复的数字则返回。 原地交换：数组元素的索引和值是一对多的关系。因此，可遍历数组并通过交换操作，使元素的索引与值一一对应（即$nums[i]=i$）。 算法流程 遍历数组，索引初始值i=0; 若nums[","title":"剑指offer复习笔记(1)"},{"content":"[paper]\n1. 介绍 使用结合CNN和Transformer的双流网络来融合伪造人脸的局部和全局伪造信息，进而提高模型的泛化能力。同时使用高频信息在CNN和Transformer之间交互，实现更通用和鲁棒的伪造检测。\n低频信息和中高频信息通常表现出不同的特征，其中低频分量主要包括图像的自然内容信息，中高频分量则主要包含混合边界、模糊伪影和棋盘格(checkboard)等细粒度信息。\n主要贡献如下：\n提出了一种用于人脸伪造检测的双流网络，分层频域辅助交互网络（Hierarchical Frequency-assisted Interactive Networks, HFI-Net）。 我们设计了一个新颖的频域特征改进模块（Frequency-based Feature Refinement，FFR）来提取RGB特征上的中高频信息，充分利用更通用和鲁棒的频域特征，避免了空间伪影的脆弱性。 我们提出了一种共享和频域辅助的全局局部交互模块（Global Local Interaction, GLI），该模块放置在HFI-Net的多级层中，以在全局上下文和局部特征之间进行有效的交互。 2. 方法 2.1 概述 HFI-Net是由CNN分支和Transformer分支组成的双流网络，旨在捕获全局上下文信息和局部细节信息。\nTransformer分支的backbone是ViT。CNN分支有一个瓶颈卷积(Bottleneck)和四个可分离阶段，其中瓶颈卷积包含两个3x3卷积层用于提取边缘和纹理等初始局部特征；每个可分离阶段有三个可分离卷积块组成，以及阶段输入和输出之间的残差连接。\nGLI模块放置在HFI-Net的每个阶段，由两个FFR模块组成，用于融合全局和局部信息，并在学习中高频伪造痕迹的同时抑制共享的高级语义特征。\nTransformer的输入为$x^g\\in\\mathbb{R}^{T\\times D},\\ T=196,\\ D=768$，bottleneck输入为$x^l\\in\\mathbb{R}^{C\\times H\\times W},\\ C=768,\\ H=W=14$。在CNN分支中没有下采样操作，故特征维度不会改变。\n最后，每个分支使用一个分类器进行训练。在训练阶段，采用交叉熵损失作为损失函数。在测试期间，将两个分类器的输出的均值作为最终预测结果。\n2.2 FFR (Frequency-based Feature Refinement) DCT\n频率选择准则（Frequency Selection Criterion, FSC）：\n与高频信息相比，CNN倾向于强调低频通道，其中包含图像的背景和真实部分；同时，已有许多研究证实了频域中的真实人脸和伪造人脸之间存在差异。如下图，伪造人脸和真实人脸在RGB图像，RGB特征图和低频特征图上几乎一致，但在中高频特征图上存在关键差异。\n所以本文在RGB特征图上使用2D DCT提取中高频分量，如下图，假设n表示提取的中高频基数，将这n个频域特征拼接在一起得到$\\tilde{X}_{u,v}=cat[F_i,\\dots,F_n]$。其中用到了FcaNet: Frequency Channel Attention Networks。\nFrequency-Based Feature Refinement（FFR）：\n聚合特征T： $$ T=\\sum_{h=0}^{H-1}\\sum_{w=0}^{W-1}\\tilde{X}_{h,w} $$ 用一个MLP层（2个全连接层）和一个sigmoid函数$\\sigma$来生成注意力权重： $$ W=\\sigma(MLP(T)) $$\n2.3 Global-Local Interaction Module（GLC）： Frequency-Assisted Global-Local Interaction (GLI) Module：\nGLI 模块利用FFR模块得到频域注意力权重，通过使用注意力权重和残差连接特征获得最终输出： $$ X^g_{freq}=X^g+W^l\\odot X^g\\\\\\ X^l_{freq}=X_l+W^g\\odot X^l $$\nMulti-Level Frequency Feature Extraction：\n浅层特征可以捕获局部区域的细微差异，但随着模型越来越深，人脸的高级语义特征仍然包含原始人脸和操纵人脸的许多共同特征。高级语义信息对人脸检测有负面影响，可能导致模型过拟合而导致泛化性能差。所以将GLI模块插入双流网络的每个阶段来增强局部伪造线索并抑制RGB特征图上共享的高级语义信息。\n3. 实验 3.1 数据集和设置 类内实验：FF++ 未知数据集实验： Celeb-DF(V2)：590+5639 TIMIT：320+640 DFDCp：1131+4113 UADFV：49+49 未知伪造方法实验：GID-DF/GID-FF，在DF/FF上训练，其余部分测试 未知扰动实验：DeeperForensics-1.0 (DFo)，60000+ 实现细节： backbone：ViT(ImageNet-1K), CNN(randomly init). optimizer: Adam; lr:2e-5; weight decay=1e-7 trainset: FF++(C40) 3.2 模块分析 在FF++(C40)上训练，测试指标为帧级AUC。\n消融实验：测试结果和可视化结果如下图，w/o FSC表示使用所有频域信息进行训练而非中高频信息；w/o dual-branch表示只使用ViT；w/o GLI表示不使用GLI交互模块。可视化结果中(a), (b), (c)和(d)分别对应消融实验的四种情况，可见HFI-Net能够对操纵区域有较高的响应。\n不同层级的交互作用分析：下图分别是将模型分割为n个阶段和在哪些阶段设置GLI模块的消融实验。可见，将模型划分为4个阶段，并在每个阶段都设置GLI模块能达到最佳性能。\n不同频率成分分析：如下图，FCS方法提取中高频的方法由于其他频率选择方法，对于未知的测试场景，中高频的特征比单频（低，中，高）更具一般性。\n对2D DCT的分析：实验测试不同U(V)参数的性能。\n$$ F^{2d}_{u,v}=\\sum_{i=0}^{H-1}\\sum_{j=0}^{W-1}{x^{2d}_{i,j}B^{i,j}_{u,v}}\\\\\\ B^{i,j}_{u,v}=\\cos(\\frac{\\pi u}{U}(i+\\frac{1}{2}))\\cos(\\frac{\\pi v}{U}(j+\\frac{1}{2})) $$\n不同频率变换方式的分析：对比DWT（小波换换）和DCT，DCT更适合这个网络架构。DWT捕获频率信息的同时会对特征图进行下采样，可能会损害与伪造区域相关的注意力权重。\n思考：使用DWT时将FFR中的FcaNet修改为WaveNets?\n不同特征细化方式的分析（FFR）：对比SE-Net和CBAM，本文的FFR模块强调中高频的伪造线索，抑制图像在空域上的原始部分和在RGB特征上的高阶语义信息，提高了泛化性。\n不同融合方式的分析（fusion）：比较特征图fusion和最后输出的fusion。\n3.3 和近期工作的比较 和SOTA对比： 未知数据集泛化性测试：下图评价指标为Image-level AUC 未知伪造方法泛化性测试：Image-based Video-level AUC 未知扰动的鲁棒性测试：Image-based Video-level AUC 计算复杂度对比：Image-level AUC ","permalink":"https://Achilles-10.github.io/posts/paper/hfinet/","summary":"[paper] 1. 介绍 使用结合CNN和Transformer的双流网络来融合伪造人脸的局部和全局伪造信息，进而提高模型的泛化能力。同时使用高频信息在CNN和Transformer之间交互，实现更通用和鲁棒的伪造检测。 低频信息和中高频信息通常表现出不同的特征，其中低频分量主要包括图像的自然内容信","title":"Hierarchical Frequency-Assisted Interactive Networks for Face Manipulation Detection"},{"content":"颜色空间 RGB颜色空间 RGB（红绿蓝）是依据人眼识别的颜色定义出的空间，可表示大部分颜色。但在科学研究一般不采用RGB颜色空间，因为它的细节难以进行数字化的调整。它将色调，亮度，饱和度三个量放在一起表示，很难分开。它是最通用的面向硬件的彩色模型。RGB颜色空间适合于显示系统，不适合于图像处理。\nHSV颜色空间 HSV表达彩色图像的方式由三个部分组成：\nHue（色调，色相） Saturation（饱和度，色彩纯净度） Value（明度） 在HSV颜色空间下，比RGB更容易跟踪某种颜色的物体，常用与分割指定颜色的物体。\n用下面这个圆柱体来表示HSV颜色空间，圆柱体的横截面可以看做是一个极坐标系 ，H用极坐标的极角表示，S用极坐标的极轴长度表示，V用圆柱中轴的高度表示。\n在RGB颜色空间中，颜色由三个值共同决定，比如黄色为(255,255,0)，在HSV颜色空间中，黄色只有一个值决定，Hue=60。\n饱和度表示颜色接近光谱色的程度：饱和度越高，说明颜色越深，越接近光谱色；饱和度为0表示纯白色。\n明度决定颜色空间中颜色的明暗程度：明度越高，表示颜色越明亮；明度为0表示纯黑色（此时颜色最暗）。\nHLS 颜色空间 HLS颜色空间和HSV颜色空间比较类似，区别在于最后一个分量不同。HLS中的L表示Lightness（亮度），亮度为100表示白色，亮度为0表示黑色。HSV中的V表示明度，明度为100表示光谱色，明度为0表示黑色。\n提取白色物体时，使用HLS更方便，因为HSV中的H没有白色，需要由S和V共同决定（S=0，V=100）；在HLS中白色仅有亮度L一个分量决定。\nYUV/YCbCr YUV是通过亮度-色差来描述颜色的颜色空间。Y是亮度信号，色度信号由两个互相独立的信号组成，根据颜色系统和格式不同，色度信号被称作UV/PbPr/CbCr。在DVD中，色度信号被存储为Cb和Cr（C表示颜色，b蓝色，r红色）。\n改变颜色空间 颜色空间 考虑BGR$\\leftrightarrow$Gray，BGR$\\leftrightarrow$HSV和BGR$\\leftrightarrow$YCrCB颜色空间的转换。\ncv2.cvtColor(input_image, flag)函数用于颜色空间转换，flag决定转换的类型：\ncv2.COLOR_BGR2GRAY cv2.COLOR_BGR2HSV cv2.COLOR_BGR2YCR_CB 可以用以下命令获取其他标记：\nflags = [i for i in dir(cv2) if i.startswith(\u0026#39;COLOR_\u0026#39;)] print(flags) HSV的色相范围为[0,179]，饱和度为[0,255]，值域为[0,255]。不同软件使用不同的规模，若要将OpenCV的值和它们比较，需要做标准化操作。\n对象追踪 HSV比BGR颜色空间更容易表示颜色，可以使用HSV来提取有颜色的对象。以下代码尝试提取一个蓝色对象，步骤：截取视频的每一帧$\\rightarrow$转换到HSV颜色空间$\\rightarrow$设置蓝色范围的阈值$\\rightarrow$单独提取蓝色对象。\nimport cv2 import numpy as np cap = cv2.VideoCapture(0) while(1): # 读取帧 _, frame = cap.read() # 转换颜色空间 BGR 到 HSV hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # 定义HSV中蓝色的范围 lower_blue = np.array([110,50,50]) upper_blue = np.array([130,255,255]) # 设置HSV的阈值使得只取蓝色 mask = cv2.inRange(hsv, lower_blue, upper_blue) # 将掩膜和图像逐像素相加 res = cv2.bitwise_and(frame,frame, mask= mask) cv2.namedWindow(\u0026#39;frame\u0026#39;, cv2.WINDOW_NORMAL) cv2.imshow(\u0026#39;frame\u0026#39;,frame) cv2.namedWindow(\u0026#39;mask\u0026#39;, cv2.WINDOW_NORMAL) cv2.imshow(\u0026#39;mask\u0026#39;,mask) cv2.namedWindow(\u0026#39;res\u0026#39;, cv2.WINDOW_NORMAL) cv2.imshow(\u0026#39;res\u0026#39;,res) k = cv2.waitKey(5) \u0026amp; 0xFF if k == 27: break cv2.destroyAllWindows() 在上面的HLS颜色空间示意图中测试白色的检测：\nimport cv2 import numpy as np import matplotlib.pyplot as plt img = cv2.imread(\u0026#34;hls.jpeg\u0026#34;) # Convert BGR to HLS imgHLS = cv2.cvtColor(img, cv2.COLOR_BGR2HLS) # range of white color in L channel # mask = cv2.inRange(imgHLS[:,:,1], lowerb=250, upperb=255) mask = cv2.inRange(imgHLS, np.array([0,250,0]), np.array([255,255,255])) # Apply Mask to original image white_mask = cv2.bitwise_and(img, img, mask=mask) 找到要追踪的HSV值 使用cv2.cvtColor(color,cv2.COLOR_BGR2HSV)，传递颜色而非图像。示例如下：\nimport cv2 import numpy as np red = np.uint8([[[0,0,255 ]]]) hsv_red = cv2.cvtColor(red,cv2.COLOR_BGR2HSV) print( hsv_red ) 如果想要同时追踪多种颜色，可以将多种颜色的掩码经过按位或操作得到新的掩码：\nmask = cv2.bitwise_or(mask_blue,mask_green,mask_red) ","permalink":"https://Achilles-10.github.io/posts/tech/opencv2/","summary":"颜色空间 RGB颜色空间 RGB（红绿蓝）是依据人眼识别的颜色定义出的空间，可表示大部分颜色。但在科学研究一般不采用RGB颜色空间，因为它的细节难以进行数字化的调整。它将色调，亮度，饱和度三个量放在一起表示，很难分开。它是最通用的面向硬件的彩色模型。RGB颜色空间适合于显示系统，不适","title":"OpenCV-Python学习笔记(2)：颜色空间"},{"content":"1. 说一下了解的激活函数和各自的应用场景 sigmoid: $$ \\sigma(x)=\\frac{1}{1+e^{-x}} $$ sigmoid是第一个被广泛应用于神级网络的激活函数，其值域为$[0,1]$，但是它存在输出均值不为0和梯度消失的问题，在深层网络中被其他激活函数替代。在逻辑回归中使用该激活函数用于输出分类。\ntanh: $$ tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}=2\\sigma(2x)-1 $$ tanh函数解决了sigmoid函数均值不为0的情况，值域为$[-1,1]$，但仍然存在梯度消失的问题。在LSTM中使用了tanh。\nReLU: $$ ReLU(x)= \\begin{cases} x,\\ x\\geq0\\\\\\ 0,\\ x\u0026lt;0\\ \\end{cases} $$ ReLU函数能有效避免梯度消失的问题，但在负值区域处于饱和状态（“死区”）。Alex-Net使用了ReLU，在使用深层网络时最好使用ReLU而不是sigmoid。\nLeaky ReLU： $$ Leaky\\ ReLU(x)= \\begin{cases} x,\\ x\\geq0\\\\\\ \\alpha\\cdot x,\\ x\u0026lt;0 \\end{cases} $$ Leaky ReLU在负值区添加了一个斜率参数，缓解了饱和性问题（“死区”）。但缺点是超参数$\\alpha$的合适值不好设定，当我们想让神经网络学习到负值区的信息时可以使用该函数。\n参数化ReLU(P-ReLU)：解决超参数$\\alpha$不好设定的问题，将其作为模型参数融入到模型的训练过程中，在反向传播时更新参数。\n随机化ReLU(R-ReLU)：随机化超参数$\\alpha$，使不同的层学习不同的参数。其随机化参数的分布符合均匀分布或高斯分布。\nELU： $$ ELU(x)= \\begin{cases} x,\\ x\\geq0\\\\\\ \\lambda\\cdot(e^x-1),\\ x\u0026lt;0 \\end{cases} $$ 解决饱和性问题，但缺点是指数计算量大。\nGELU： $$ GELU(x)=x\\text{P}(\\text{X}\\leq x)=x\\Phi(x) $$ ​\t其中$\\Phi(x)$是正态分布的概率函数，计算时近似计算的数学公式如下： $$ GELU(x)=\\frac{1}{2}x(1+tanh[\\sqrt{\\frac{2}{\\pi}}(x+0.044715x^3)]) $$\n2. 为什么需要激活函数？ 在线性模型中引入非线性激活函数，可以使线性模型非线性化，提高模型的非线性表达能力，也就是拟合能力。\n3. 激活函数的特征？ 非线性性 几乎处处可微 计算简单 单调性：符号不变容易收敛 非饱和性：饱和指在某些区间的梯度接近零，即梯度消失，使得参数无法继续更新 输出范围有限 接近恒等变换 参数少 4. Leaky ReLU相对于ReLU的优势在哪？ Leaky ReLU在负值增加了一个斜率$\\alpha$，缓解了ReLU在$x\u0026lt;0$时的饱和性问题(\u0026ldquo;死区\u0026rdquo;，梯度消失)，但Leaky ReLU得超参数$\\alpha$的合适值不好设定。\n当我们想让神经网络能够学到负值信息时可以使用该激活函数。\n5. 什么是ReLU6？ ReLU的值域为$[0,\\infty]$，在实际应用中需要限定输出的最大值，将输出在6处截断，即为ReLU6。\n6. Sigmoid函数有什么缺点？怎么解决？ 缺点：输出均值不为0，存在梯度消失的情况。\n解决办法：\n用ReLU，Leaky ReLU等其他激活函数代替 采用适合的权重初始化方法，如He_init 在分类问题中，sigmoid作为激活函数时，用交叉熵损失函数替代MSE 加入BN层 分层训练权重 7. ReLU在零点可导吗？如何进行反向传播？ 不可导，可以人为的将零点梯度规定为0。\ncaffe源码~/caffe/src/caffe/layers/relu_layer.cpp倒数第十行代码如下：\nbottom_diff[i] = top_diff[i] * ((bottom_data[i] \u0026gt; 0)+ negative_slope * (bottom_data[i] \u0026lt;= 0)); 可见，间断点（$\\leq0$）处的导数为negtive_slope（默认为0）。\n8. Softmax的溢出问题怎么解决？ 由于Softmax的指数运算，可能导致溢出问题。\n令$M=\\max(x_i)$，将计算$f(x_i)$转换为计算$f(x_i-M)$的值，就可以解决溢出问题了，且理论上计算结果与计算$f(x_i)$保持一致，该操作类似与Min-Max归一化。\n9. 推导Sigmoid的求导公式 sigmoid公式如下：\n$$ \\sigma(z)=\\frac{1}{1+e^{-z}} $$\n求导公式推导如下：\n$$ \\begin{align}\\sigma'(z)\u0026=(\\frac{1}{1+e^{-z}})'\\\\\u0026=(e^{-z})\\cdot\\frac{1}{(1+e^{-z})^2}\\\\\u0026=\\frac{1}{1+e^{-z}}\\cdot\\frac{e^{-z}}{1+e^{-z}}\\\\\u0026=\\frac{1}{1+e^{-z}}\\cdot(1-\\frac{1}{1+e^{-z}})\\\\\u0026=\\sigma(z)\\cdot(1-\\sigma(z))\\end{align} $$ 10. 推导Softmax的求导公式 softmax公式如下： $$ s(z_i)=\\frac{e^{z_i}}{\\sum_{k=1}^{n}{e^{z_k}}} $$ 求导公式推导如下：\n当$j=i$时： $$ \\begin{align} \\frac{\\partial s_i}{\\partial z_i} \u0026=\\frac{\\partial(\\frac{e^{z_i}}{\\sum_{k=1}^{n}{e^{z_k}}})}{\\partial z_i}\\\\ \u0026=\\frac{e^{z_i}\\cdot\\sum{e^{z_k}}-(e^{z_i})^2}{(\\sum{e^{z_k}})^2}\\\\ \u0026=\\frac{e^{z_i}}{\\sum{e^{z_k}}}\\cdot\\frac{\\sum{e^{z_k}}-e^{z_i}}{\\sum{e^{z_k}}}\\\\ \u0026=\\frac{e^{z_i}}{\\sum{e^{z_k}}}\\cdot(1-\\frac{e^{z_i}}{\\sum{e^{z_k}}})\\\\ \u0026=s_i(1-s_i) \\end{align} $$ 当$j\\neq i$时： $$ \\begin{align} \\frac{\\partial s_j}{\\partial z_i} \u0026=\\frac{\\partial(\\frac{e^{z_j}}{\\sum_{k=1}^{n}{e^{z_k}}})}{\\partial z_i}\\\\ \u0026=e^{z_j}\\cdot-(\\frac{1}{\\sum{e^{z_k}}})^2\\cdot e^{z_i}\\\\ \u0026=-\\frac{e^{z_j}}{\\sum{e^{z_k}}}\\cdot\\frac{e^{z_i}}{\\sum{e^{e_k}}}\\\\ \u0026=-s_j\\cdot s_i \\end{align} $$ p.s.基本初等函数的求导公式与法则 ","permalink":"https://Achilles-10.github.io/posts/tech/activation/","summary":"1. 说一下了解的激活函数和各自的应用场景 sigmoid: $$ \\sigma(x)=\\frac{1}{1+e^{-x}} $$ sigmoid是第一个被广泛应用于神级网络的激活函数，其值域为$[0,1]$，但是它存在输出均值不为0和梯度消失的问题，在深层网络中被其他激活函数替代。在逻辑回归中使用该激活函数用于输出分类。 tanh: $$ tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}=2\\sigma(2x)-1 $$ tanh函数解决了sigmoid函","title":"深度学习面试题：激活函数"},{"content":"[paper] [code]\n1. 引言 Transformer 取代了以往递归神经网络为主导的骨干架构，随着ViT的引入，彻底改变了网络架构设计的格局。但ViT的全局注意力机制对输入大小的复杂度过高，难以处理高分辨率的输入。\n层级Transformer采用混合方法来解决这个问题，例如Swin Transformer采用了“滑动窗口”策略，也说明了卷积仍然非常受欢迎。本文目标是为卷积网络弥补前ViT时代和后ViT时代的差距，并测试纯卷积网络可以达到的极限。\n2. Modernizing a ConvNet: a Roadmap（研究路线图） 以ResNet-50作为baseline，考虑以下几种设计决策：\nmarco design（宏观设计） ResNeXt inverted bottlenect（倒置瓶颈） large kernel size（更大的卷积核） various layer-wise micro designs（多样的分层微设计） 2.1 训练技巧 epoch: 90-\u0026gt;300 optimizer: AdamW data augmentation: Mixup, Cutmix, RandAugment, RandomErasing\u0026hellip; regularization: Stochastic Depth, Label Smoothing 2.2 Marco Design（宏观设计） 改变阶段计算比：Swin-T的阶段计算比为1:1:3:1，更大型的Swin的阶段计算比为1:1:9:1。对此，将ResNet-50中的(3,4,6,3)改为 (3,3,9,3)，使模型准确率从78.8%提升至79.4%。 将stem改为\u0026quot;Patchify\u0026quot;（非重叠的卷积）：标准的ResNet中stem为(k=7,p=3,s=2)的卷积后跟一个(k=3,p=1,s=2)的最大池化，这导致输入图像的4倍下采样。将其更换为 (k=4,s=4)的卷积，模型准确率从79.4%提升至79.5%。 2.3 ResNeXt-ify 采用深度可分离卷积，使得每个操作单独混合空间或通道的信息。使用分组卷积(depthwise conv)能够降低网络的FLOPs，但也会降低准确率(78.3%)。将网络宽度从64扩展到96，准确率提升到80.5%。\n2.4 Inverted Bottlenect（倒置瓶颈） Transformer中的MLP的隐藏维度比输入维度大4倍（384:96），这就是倒置瓶颈。对倒置瓶颈的探索如下图(a)(b)，这使得准确率提升(80.5%-\u0026gt;80.6%)的同时降低了FLOPs(下采样残差1x1卷积的FLOPs减少)。\n2.5 Large Kernel Sizes（大卷积核） VGG推广的黄金标准是堆叠3x3的小卷积核，这在现代化GPU上更高效，但Swin中的窗口大小至少为7x7。\n上移分组卷积层：如上图(b)(c)，使复杂低效的模块(MSA)有更少的通道数，降低FLOPS至4.1G，性能暂时下降到79.9%。 增大卷积核：将卷积核大小从3x3增大到7x7，FLOPs大致保持不变，准确率提升至80.6%。当继续增大卷积核时并没有带来更大准确率增益。 2.6 Micro Design（微观设计） 将ReLU更换为GELU：准确率不变 更少的激活函数：如下图所示，复制Swin的样式，将残差块中的激活函数去掉，去掉两个卷积层中的一个激活函数，准确度提升至81.3%。 更少的归一化层：去掉两个归一化层，在1x1卷积前只留下一个BN层，准确率提升到81.4%，超过Swin。 将BN替换为LN：BN能够加速收敛并减少过拟合，但BN错综复杂，可能对模型的性能产生不利影响。在ResNet中直接将BN替换为LN会导致性能不佳，但随着对网络结构和训练技巧的修改，使用LN将准确率提升至81.5%。 可分离的下采样层：ResNet中的下采样是通过每个阶段开始时的残差块实现的。Swin中添加了一个单独的下采样层。本文用单独的(k=2,s=2)卷积实现下采样，后续实验发现在分辨率变化的地方添加归一化层有助于稳定训练，这时准确率达到82.0%。 3. 在ImageNet上的评估 构建了不同的ConvNeXt变体：\nConvNeXt-T: C =(96, 192, 384, 768), B =(3, 3, 9, 3) ConvNeXt-S: C =(96, 192, 384, 768), B =(3, 3, 27, 3) ConvNeXt-B: C =(128, 256, 512, 1024), B =(3, 3, 27, 3) ConvNeXt-L: C =(192, 384, 768, 1536), B =(3, 3, 27, 3) ConvNeXt-XL: C =(256, 512, 1024, 2048), B =(3, 3, 27, 3) 3.1 结果 ImageNet-1K：\nImageNet-22K 预训练，ImageNet-1K 微调：\n3.2 Isotropic ConvNeXt vs. ViT（同质性比较） 同质架构（Isotropic architecture）：同质架构模型没有下采样层，在所有深度都保持相同的特征图分辨率，只需要用特征大小（即patch embedding的维度）和网络深度（即blocks数量）两个参数定义。\nConvNeXt的性能同ViT相当，说明ConvNeXt块设计在用于非层级模型时具有竞争力。\n4. 在下游任务上的评估 4.1 COCO数据集上的目标检测和分割 4.2 ADE20K上的语义分割 4.3 关于模型效率的评论 5. 总结 ConvNeXt模型本身不是全新的，里面的许多设计都被单独测试过，但没有放在一起测试过。ConvNeXt的实验结果是优秀的，在多个计算机视觉基准测试中与最先进的层级Transformer竞争的同时，还保留着标准卷积网络的简单性和效率。\n","permalink":"https://Achilles-10.github.io/posts/paper/convnext/","summary":"[paper] [code] 1. 引言 Transformer 取代了以往递归神经网络为主导的骨干架构，随着ViT的引入，彻底改变了网络架构设计的格局。但ViT的全局注意力机制对输入大小的复杂度过高，难以处理高分辨率的输入。 层级Transformer采用混合方法来解决这个问题，例如Swin Transformer采用了“滑动窗口”策","title":"A ConvNet for the 2020s"},{"content":"图像入门 读取图像 使用cv2.imread(filename,flags)函数读取图像，参数说明如下：\nfilename - 待读取图像的路径\nflags - 读取图像的方式\ncv2.IMREAD_COLOR - 加载彩色图像，图像的透明度会被忽略，默认标志 cv2.IMREAD_GRAYSCALE - 以灰度模式加载图像 cv2.IMREAD_UNCHANGED - 加载图像，不会忽略透明度 可以分别传递整数1，0，-1\nimport numpy as np import cv2 img = cv2.imread(\u0026#39;face.png\u0026#39;,0) 即使图像路径错误，也不会报错，但print(img)会输出None\n写入图像 使用cv2.imwrite(filename,image)函数保存图像，参数说明如下：\nfilename - 保存的文件名 image - 要保存的图像 cv2.imwrite(\u0026#39;save.png\u0026#39;, img) 使用Matplotlib显示图像 from matplotlib import pyplot as plt plt.imshow(img, cmap = \u0026#39;gray\u0026#39;, interpolation = \u0026#39;bicubic\u0026#39;) plt.xticks([]), plt.yticks([]) # 隐藏 x 轴和 y 轴上的刻度值 plt.show() 图像的基本操作 访问和修改像素值 可以通过行列坐标来访问和修改像素值。对于BGR图像，返回一个[BLUE值 GREEN值 RED值]数组；对于灰度图像，只返回对应的灰度。\n\u0026gt;\u0026gt;\u0026gt; px=img[100,100] \u0026gt;\u0026gt;\u0026gt; print(px) [237 217 186] # 访问BLUE值 \u0026gt;\u0026gt;\u0026gt; blue = img[100,100,0] \u0026gt;\u0026gt;\u0026gt; print(blue) 237 \u0026gt;\u0026gt;\u0026gt; img[100,100]=[255,255,255] \u0026gt;\u0026gt;\u0026gt; print(img[100,100]) [255 255 255] 上述方法用于选择数组的区域。对于单像素访问，Numpy数组方法array.item()和array.itemset()返回标量，相对更好。\n\u0026gt;\u0026gt;\u0026gt; img.item(100,100,2) 255 \u0026gt;\u0026gt;\u0026gt; # 修改RED值 \u0026gt;\u0026gt;\u0026gt; img.itemset((10,10,2),99) \u0026gt;\u0026gt;\u0026gt; img.item(10,10,2) 99 访问图像属性 图像属性包括行列通道数，数据类型和像素数等。\n图像的形状由img.shape访问，返回行列通道数的元组，如果图像是灰度的，返回值仅包括行列数。\n像素总数由img.size访问，图像数据类型由img.dtype访问。\n\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;shape:\u0026#39;,img.shape) shape: (512, 512, 3) \u0026gt;\u0026gt;\u0026gt; print(\u0026#39;size:\u0026#39;,img.size) size: 786432 \u0026gt;\u0026gt;\u0026gt; print(\u0026#39;dtype:\u0026#39;,img.dtype) dtype: uint8 img.dtype在调试时很重要，因为OpenCV代码中的大量错误是由无效的数据类型引起的。\n图像感兴趣区域(Region of Interest, ROI) 用Numpy获取ROI，例如将图像中的人脸复制到图像的另一个区域\n\u0026gt;\u0026gt;\u0026gt; face = img[10:300,210:430] \u0026gt;\u0026gt;\u0026gt; img[0:290,0:220]=face 拆分和合并图像通道 有时候需要分别处理图像的B, G, R通道，或者将单独的通道加入到BGR图像，在这种情况下需要拆分或合并图像通道。\n\u0026gt;\u0026gt;\u0026gt; b,g,r=cv2.split(img) \u0026gt;\u0026gt;\u0026gt; img=cv2.merge((b,g,r)) 或者采用Numpy索引，例如将所有红色值设置为零：\n\u0026gt;\u0026gt;\u0026gt; img[:,:,2]=0 cv2.split()是一个耗时的操作，非必要时使用Numpy索引。\n为图像设置边框（填充） 可以使用copyMakeBorder(src, top, bottom, left, right, borderType[, dst[, value]]) -\u0026gt; dst在图像周围创建边框，该函数在卷积运算，零填充等方面有更多应用。参数说明如下：\nsrc - 输入图像 top, bottom, left, right - 边界宽度 borderType - 边框类型标志，可以是一下类型： cv2.BORDER_CONSTANT - 添加恒定的彩色边框，该值由下一个参数给出 cv2.BORDER_REFLECT - 边框是边框元素的镜像 cv2.BORDER_REFLECT_101或cv2.BORDER_DEFAULT与上述相同，但略有变化 cv2.BORDER_REPLICATE - 最后一个元素被复制 cv2.BORDER_WRAP value - 边框的颜色，如果边框类型为cv2.BORDER_CONSTANT import cv2 import numpy as np from matplotlib import pyplot as plt BLUE = [255,0,0] img1 = cv2.imread(\u0026#39;face.png\u0026#39;) img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB) replicate = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REPLICATE) reflect = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT) reflect101 = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT_101) wrap = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_WRAP) constant= cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_CONSTANT,value=BLUE) plt.subplot(231),plt.imshow(img1,\u0026#39;gray\u0026#39;),plt.title(\u0026#39;ORIGINAL\u0026#39;) plt.subplot(232),plt.imshow(replicate,\u0026#39;gray\u0026#39;),plt.title(\u0026#39;REPLICATE\u0026#39;) plt.subplot(233),plt.imshow(reflect,\u0026#39;gray\u0026#39;),plt.title(\u0026#39;REFLECT\u0026#39;) plt.subplot(234),plt.imshow(reflect101,\u0026#39;gray\u0026#39;),plt.title(\u0026#39;REFLECT_101\u0026#39;) plt.subplot(235),plt.imshow(wrap,\u0026#39;gray\u0026#39;),plt.title(\u0026#39;WRAP\u0026#39;) plt.subplot(236),plt.imshow(constant,\u0026#39;gray\u0026#39;),plt.title(\u0026#39;CONSTANT\u0026#39;) plt.show() 图像上的运算 图像加法 可以通过cv2.add()或Numpy操作res=img1+img2完成图像加法操作。相加的图像应该具有相同的深度和类型，或者第二个图像是一个标量值。\nOpenCV加法是饱和运算，Numpy加法是模运算。\n\u0026gt;\u0026gt;\u0026gt; x=np.uint8([250]) \u0026gt;\u0026gt;\u0026gt; y=np.uint8([10]) \u0026gt;\u0026gt;\u0026gt; print(cv2.add(x,y)) [[255]] \u0026gt;\u0026gt;\u0026gt; print(x+y) [4] 当添加两个图像时，尽量使用OpenCV的功能，能提供更好的结果。\n图像融合 这也是图像加法，但是对相加的图像赋予给定的权重，使其具有融合或透明的感觉。\n$$ G(x)=(1-\\alpha)f_0(x)+\\alpha f_1(x) $$\n将$\\alpha$从$0\\rightarrow1$更改，可以实现图像过渡的效果。cv2.addWeighted()在图像上应用以下公式：\n$$ dst=\\alpha\\cdot img_1+\\beta\\cdot img_2+\\gamma $$\n在这里，$\\gamma$ 被视为零。\nimg1 = cv2.imread(\u0026#39;face1.png\u0026#39;) img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB) img2 = cv2.imread(\u0026#39;face2.png\u0026#39;) img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB) dst = cv2.addWeighted(img1,0.6,img2,0.4,0) plt.figure(figsize=(15, 9)) plt.subplot(131),plt.imshow(img1),plt.title(\u0026#39;IMG1\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(132),plt.imshow(img2),plt.title(\u0026#39;IMG2\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(133),plt.imshow(dst),plt.title(\u0026#39;DST\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.show() 按位运算 按位运算包括AND,OR,NOT,XOR操作。这些操作在提取图像的任意部分、定义和处理非矩形ROI方面非常有用。下面的例子是想把OpenCV的标志放到一个图像上。\n如果我们直接使用图像加法，它会改变颜色，无法达到我们想要的效果；如果使用图像融合，会得到一个透明的效果，也不是我们想要的效果。如果是一个矩形区域，我们可以使用ROI，但OpenCV的标志并不是矩形的，故可以用按位操作来实现：\n# 加载两张图片 img1 = cv2.cvtColor(cv2.imread(\u0026#39;shuyi.png\u0026#39;),cv2.COLOR_BGR2RGB) img2 = cv2.cvtColor(cv2.imread(\u0026#39;logo.jpg\u0026#39;),cv2.COLOR_BGR2RGB) # 我想把logo放在左上角，所以我创建了ROI rows,cols,channels = img2.shape roi = img1[0:rows, 0:cols] # 现在创建logo的掩码，并同时创建其相反掩码 img2gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY) ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY) mask_inv = cv2.bitwise_not(mask) # 现在将ROI中logo的区域涂黑 img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv) # 仅从logo图像中提取logo区域 img2_fg = cv2.bitwise_and(img2,img2,mask = mask) # 将logo放入ROI并修改主图像 dst = cv2.add(img1_bg,img2_fg) img1[0:rows, 0:cols ] = dst plt.figure(figsize=(9, 6)) plt.subplot(121),plt.imshow(mask,\u0026#39;gray\u0026#39;),plt.title(\u0026#39;MASK\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(122),plt.imshow(img1),plt.title(\u0026#39;RESULT\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.show() 在计算mask时用到了cv2.bitwise_not(src,dst=None,mask=None)函数，在计算前景和背景区域时用到了cv2.bitwise_and(src1,src2,dst=None,mask=None)，参数说明如下：\nsrc1 - 参与运算的图像 src2 - 参与运算的图像 dst - 可选运算结果输出数组 mask - 可选操作掩码 threshold(src, thresh, maxval, type[, dst])-\u0026gt;ret,dst函数的作用是将一幅灰度图二值化，参数说明如下：\nsrc - 输入的灰度图\nthresh - 阈值\nmaxval - 最大值\ntype - 阈值类型\n阈值类型 灰度值大于阈值(val\u0026gt;threshold) 其他情况 cv2.THRESH_BINARY maxval 0 cv2.THRESH_BINARY_INV 0 maxval cv2.THRESH_TRUNC thresh 当前灰度值 cv2.THRESH_TOZERO 当前灰度值 0 cv2.THRESH_TOZERO_INV 0 当前灰度值 性能衡量和提升技术 使用OpenCV衡量性能 cv2.getTickCount()函数返回从参考时间到调用此函数时的时钟周期数，可以在函数执行前后调用它获得执行函数的时钟周期数。\ncv2.getTickFrequency()函数返回时钟周期的频率或者每秒的时钟周期数。下列代码可以获得执行函数所用时间（以秒为单位）。\ne1 = cv2.getTickCount() # 你的执行代码 e2 = cv2.getTickCount() time = (e2 - e1)/ cv2.getTickFrequency() 也可以使用两次time.time()函数，取两次的差来获得函数所用时间。\nOpenCV中的默认优化 OpenCV默认运行优化的代码。可以使用cv2.useOptimized()来检查是否启用优化，使用cv2.setUseOptimized(bool)来启用/禁用优化。\ncv2.setUseOptimized(True) print(cv2.useOptimized()) %timeit res = cv2.medianBlur(img1,59) cv2.setUseOptimized(False) print(cv2.useOptimized()) %timeit res = cv2.medianBlur(img1,59) True 35 ms ± 2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) False 36.5 ms ± 2.37 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) 在IPython或者Jupyter中衡量性能 使用%timeit。实例如下：\nx=5 z=np.uint8([5]) %timeit y=x**2 %timeit y=z*z %timeit y=x**x %timeit y=np.square(z) 273 ns ± 13.9 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) 659 ns ± 37.2 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) 334 ns ± 10.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) 646 ns ± 48.1 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) 可以看到，Python的标量操作比Numpy的标量操作快，对于包含一两个元素的运算，Python标量比Numpy数组好，当数组大小稍大时Numpy会占优势。\n下面测试cv2.countNonZero()函数和np.count_nonzero()函数对于同一张图片的性能。\nimg = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY) %timeit z=cv2.countNonZero(img) %timeit z=np.count_nonzero(img) 13.5 µs ± 481 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) 23.2 µs ± 970 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each) 可以看到OpenCV函数比Numpy函数快。\n性能优化技术 尽量避免在Python中使用循环，特别是双重/三重循环等，因为它们本质上速度较慢。 最大程度地向量化算法/代码，因为Numpy和OpenCV针对向量运算进行了优化。 利用缓存一致性。 尽量不要复制数组，因为数组复制是一项代价昂贵的操作。 参考资源 Python优化技术 Scipy讲义-高级Numpy IPython中的时序和性能分析 ","permalink":"https://Achilles-10.github.io/posts/tech/opencv1/","summary":"图像入门 读取图像 使用cv2.imread(filename,flags)函数读取图像，参数说明如下： filename - 待读取图像的路径 flags - 读取图像的方式 cv2.IMREAD_COLOR - 加载彩色图像，图像的透明度会被忽略，默认标志 cv2.IMREAD_GRAYSCALE - 以灰度模式加载图像 cv2.IMREAD_UNCHANGED - 加载图像，不会忽略透明度 可以分别传递整数1，0，-1 import numpy as np import cv2 img =","title":"OpenCV-Python学习笔记(1)：核心操作"},{"content":"[paper] [code]\n动机与介绍 已有方法对跨域数据集和高压缩高曝光数据的检测能力大幅下降(泛化性差)；\n难以识别的fake样本通常包含更一般伪造痕迹，故要学习更通用和鲁棒的面部伪造表征；\n定义了四种常见的伪影(artifacts)： 主要贡献 提出了source-target generator (STG) and mask generator (MG)来学习更一般鲁棒的人脸伪造表征 通过自换脸而非寻找最接近的landmark换脸，降低了计算成本 在cross-dataset和cross-maniputation测试中都取得了SOTA 方法 学习伪造人脸与背景的不一致分为下列三个模块\nSource-Target Generator(STG):\n对source和target进行数据增强以产生不一致，并且对source进行resize和translate以再现边界混合和landmarks不匹配； 首先对Target和Source之一做图像增强 (color：RGB channels, hue, saturation, value, brightness, and contrast；frequency：downsample or sharpen)； 然后对source进行裁剪：$H_r=u_hH,\\quad W_r=u_wW$,其中$\\ u_h和u_w$是一组均分分布中的随机值，再对裁剪后的图像zero-padded 或者 center-cropped还原回初始大小； 最后对source做变形(translate)：traslate vector$\\ t=[t_h,t_w]$,$\\ t_h=v_hH,t_w=v_wW$，$v_h和v_w$是一组均分分布中的随机值。 Mask Generator: 生成变形的灰度mask图\n计算面部landmarks的convex hull来初始化mask，然后对mask变形(elastic deformation)，在用两个不同参数的高斯滤波器(gaussian filter)对mask进行平滑处理。最后在{0.25, 0.5, 0.75, 1, 1, 1}中选取混合指数(blending ration)； Blending: 用Mask来混合source和target图得到SBI\n$$I_{SB}=I_s\\odot M+I_t\\odot(1-M)$$\nTrain with SBIs: 将target而非原图作为”REAL“，使得模型集中在伪造痕迹上\n实验 实现细节 预处理：Dlib和RetinaFace裁帧，面部区域裁剪：4~20%(训练),12.5%(推理)； Source-Target Augmentation：RGBShift, HueSaturationValue, RandomBrightnessContrast, Downscale, and Sharpen 推理策略：如果在一帧中检测到两个或多个人脸，则将分类器应用于所有人脸，并将最高的虚假置信度用作该帧的预测置信度。 实验设定：各类baseline 跨数据集评估 跨操作评估 定量分析 消融实验 定性分析 局限性 缺乏时序信息、无法解决GAN生成的伪造图像\n","permalink":"https://Achilles-10.github.io/posts/paper/sbi/","summary":"[paper] [code] 动机与介绍 已有方法对跨域数据集和高压缩高曝光数据的检测能力大幅下降(泛化性差)； 难以识别的fake样本通常包含更一般伪造痕迹，故要学习更通用和鲁棒的面部伪造表征； 定义了四种常见的伪影(artifacts)： 主要贡献 提出了source-target generator (STG) and mask generator (MG)来学习更一般","title":"Detecting Deepfakes with Self-Blended Images"},{"content":" 英文名: Achilles Zhang 职业: 学生 爱好: 篮球、健身、Dota2 个性签名: 垒山不止就是幸福 ","permalink":"https://Achilles-10.github.io/about/","summary":"英文名: Achilles Zhang 职业: 学生 爱好: 篮球、健身、Dota2 个性签名: 垒山不止就是幸福","title":"关于"}]