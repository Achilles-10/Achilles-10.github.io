[{"content":"[paper] [code]\n引言 由于通道注意力在特征建模上的简单性和有效性，成为深度学习领域流行的工具。而全局平均池化（GAP）由于其简单性成为了默认选择，但它的简单性也使得它很难很好地捕获各种输入的复杂信息。\n本文将信道的标量表示看作一个压缩问题。也就是说，一个通道的信息应该被一个标量紧凑地编码，同时尽可能地保留整个通道的表示能力。而如何有效地压缩具有标量的信道是一大难点。\n由于DCT的高压缩比可以满足用标量表示信道注意力的需求，以及它可微的性质可以简单地集成到CNN中，选择DCT定制通道注意力。本文主要贡献如下：\n把通道注意力看作一个压缩问题，并在通道注意力中引入DCT。证明了传统GAP是DCT的一个特例。基于这一证明，在频域推广了通道注意力，并提出了多谱通道注意力框架（Multi-Spectral Channel Attention , MSCA），称为FcaNet； 我们提出了三种频率成分选择标准（LF低频选择，TS两步选择，NAS神经架构搜索选择）以及所提出的多光谱通道注意框架来实现FcaNet。 在ImageNet和COCO数据集上达到SOTA水平。 方法 回顾DCT和通道注意力 DCT： $$ f^{2d}_{h,w}=\\sum_{i=0}^{H-1}\\sum_{j=0}^{W-1}{x^{2d}_{i,j}B^{i,j}_{h,w}}\\\\ B^{i,j}_{h,w}=\\cos(\\frac{\\pi h}{H}(i+\\frac{1}{2}))\\cos(\\frac{\\pi w}{W}(j+\\frac{1}{2}))\\tag{1} $$\n通道注意力：通道注意力用标量来表示和评估每个通道的重要性，可以写成如下形式： $$ att=sigmoid(fc(compress(X))) $$ compress: $\\mathbb {R}^{C\\times H\\times W}\\rightarrow\\mathbb{R}^C$ 是压缩方法。全局平均池化（GAP）可以视作一种压缩方法。\n多谱通道注意力（Multi-Spectral Channel Attention，MSCA） 通道注意力的理论分析，定理1：GAP是2D DCT的特例，其结果与2D DCT的最低频率成分成正比。\n证明：在公式(1)中，令h和w为0，有\n$$ \\begin{align} f^{2d}_{0,0} \u0026amp;=\\sum_{i=0}^{H-1}\\sum_{j=0}^{W-1}{x^{2d}_{i,j}B^{i,j}_{0,0}}\\\\ \u0026amp;=\\sum_{i=0}^{H-1}\\sum_{j=0}^{W-1}x^{2d}_{i,j}\\\\ \u0026amp;=GAP(x^{2d})\\cdot HW \\end{align}\\tag{2} $$\n在公式(2)中，$f^{2d}_{0,0}$表示2D DCT的最低频率成分，与GAP成正比，定理1得证。\n多谱通道注意力模块：\n通过定理1可知，在使用通道注意力中使用GAP意味着只保留了最低频的信息，为了更好地压缩信道并引入更多信息，需要利用DCT中更多的频率信息。\n首先，将输入X沿通道方向分块为$[X^0,X^1,\\dots,X^{n-1}]$，其中$X^i\\in\\mathbb{R}^{C\u0026rsquo;\\times H\\times W},\\ C\u0026rsquo;=\\frac{C}{n}$，C能被n整除。对每部分进行2D DCT操作，有： $$ Freq^i=2\\text{DDCT}(X^i) $$ 最终的压缩向量可以表示如下： $$ \\begin{align} Freq\u0026amp;=compress(X)\\ \u0026amp;=cat([Freq^0,Freq^1,\\dots,Freq^{n-1}]) \\end{align} $$ 最终的多谱注意力表示如下： $$ ms_att=sigmoid(fc(Freq)) $$\n频率成分选择标准（Criteria for Choosing Frequency Components）\n提出三种选择频率成分的标准：\nFcaNet-LF：选择低频成分 FceNet-TS：通过两步选择方案确定，首先确定每个频率分量的重要性，然后评估不同频率分量数量的效果 FcaNet-NAS：通过神经架构搜索来搜索通道的最佳频率成分 实验 消融实验 单体频率分量的影响（The effects of individual frequency components）\nImageNet上的最小特征图大小为7x7，因此将2D DCT的频率空间划分为7x7，测试每部分的性能如下图（TOP-1 准确率）：\n可以看出，低频有更好的表现，也验证了SENet的成功和深度网络偏好低频信息的结论。然而几乎所有的频率成分(除最高频率外)与最低频率成分之间的差距非常小(\u0026lt;=0.5% Top-1准确率)。这说明其他频率成分也能很好地应对通道注意力机制，在频域上泛化通道注意力是有效的。\n频率分量的数量的影响（The effects of different numbers of frequency components）\n对于TS，选取上图中Top-K性能最高的频率成分；对于LF，选取K个最低频率成分的结果。结果如下图所示，可以发现：\n使用多谱注意力的性能比仅使用通道注意力中的GAP都有提高 当k=2和16时效果最好 与完全可学习的通道注意力相比：2D DCT的基函数可以看做是包含DCT系数的张量\nFR：Fixed tensor with Random initialization，随机初始化固定张量\nLR：Learned tensor with Random initialization，随机初始化可学习张量\nLD：Learned tensor with DCT initialization，DCT初始化可学习张量\nFD：Fixed tensor with DCT initialization，DCT初始化固定张量\n讨论 多谱框架（multi-spectrum framework）如何压缩和嵌入更多信息：\n由于深度网络是冗余的，若两个通道是冗余的，则通过GAP只能得到相同的信息；而在多谱注意力中，不同的频率分量包含不同的信息，因此可以从冗余通道中提取更多的信息。\n复杂度分析：\nDCT权重是预定义的常数，没有额外参数；额外计算成本与SENet相当。\n代码实现：\n多谱注意力与SENet的区别仅在于信道压缩方法（GAP vs. multi-spectrum 2D DCT），2D DCT可以看做是输入的加权和，因此该方法可以很容易地集成到任意通道注意力方法中。\n在ImageNet上的图像分类 在COCO上的目标检测 ","permalink":"https://Achilles-10.github.io/posts/paper/fcanet/","summary":"[paper] [code] 引言 由于通道注意力在特征建模上的简单性和有效性，成为深度学习领域流行的工具。而全局平均池化（GAP）由于其简单性成为了默认选择，但它的简单性也使得它很难很好地捕获各种输入的复杂信息。 本文将信道的标量表示看作一个压缩问题。也就是说，一个通道的信息应该被一个标量紧凑地编码，同时尽","title":"FcaNet: Frequency Channel Attention Networks"},{"content":"变换 OpenCV提供了cv2.warpAffine和cv2.warpPerspective两个转换函数，cv2.warpAffine采用2x3的转换矩阵，cv2.warpPerspective采用3x3转换矩阵。\n缩放 使用cv2.resize实现图像的缩放，可以指定缩放尺寸或缩放比例，以及插值方法。首选的插值方法是用于缩小的 cv2.INTER_AREA 和用于缩放的 cv2.INTER_CUBIC（慢）和 cv2.INTER_LINEAR。cv2.INTER_LINEAR是默认的缩放插值方法。可以用一下两种方法实现：\nimport numpy as np import cv2 img = cv2.imread(\u0026#39;face.png\u0026#39;) res = cv2.resize(img, None,fx=2, fy=2, interpolation = cv2.INTER_CUBIC) # OR height, width = img.shape[:2] res = cv2.resize(img,(2*width, 2*height), interpolation = cv2.INTER_CUBIC) 平移 如果在(x,y)方向上的平移量为$(t_x,t_y)$，则可以得到转换矩阵M: $$ M=\\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; t_x \\\\ 0 \u0026amp; 1 \u0026amp; t_y \\end{bmatrix} $$ 将其转换为np.float32的numpy数组并传入cv2.warpAffine函数，以平移(100,50)为例：\nrows,cols,_ = img.shape M = np.float32([[1,0,100],[0,1,50]]) dst = cv2.warpAffine(img,M,(cols,rows)) cv2.warpAffine的第三个参数是输出图像的大小，形式为(width,height)\n旋转 图像旋转角度为$\\theta$是通过以下变换矩阵实现的： $$ M = \\begin{bmatrix} \\cos\\theta \u0026amp; -\\sin\\theta \\\\ \\sin\\theta \u0026amp; \\cos\\theta \\end{bmatrix} $$ OpenCV提供了可缩放的旋转和可调整的旋转中心，修改后的变换矩阵为： $$ \\begin{bmatrix} \\alpha \u0026amp; \\beta \u0026amp; (1- \\alpha ) \\cdot center.x - \\beta \\cdot center.y \\\\ - \\beta \u0026amp; \\alpha \u0026amp; \\beta \\cdot center.x + (1- \\alpha ) \\cdot center.y \\end{bmatrix} $$ 其中： $$ \\alpha=scale\\cdot\\cos\\theta,\\\\\\beta=scale\\cdot\\sin\\theta $$ 为了得到该变换矩阵，OpenCV提供了cv2.getRotationMatrix2D函数，以将图像相对于中心旋转逆时针90度缩放比例为1：\nrows,cols,_ = img.shape # cols-1 和 rows-1 是坐标限制 M = cv2.getRotationMatrix2D(((cols-1)/2.0,(rows-1)/2.0),90,1) dst = cv2.warpAffine(img,M,(cols,rows)) 仿射变换（Affine Transformation） 在仿射转换中，原始图像中的所有并行线仍将在输出图像中平行。为了得到转换矩阵，需要从输入图像中的三个点及其在输出图像中的对应位置。通过cv2.getAffineTransform函数创建一个2x3的矩阵，并传递给cv2.warpAffine。\nrows,cols,ch = img.shape pts1 = np.float32([[100,100],[100,400],[400,100]]) pts2 = np.float32([[50,50],[100,400],[350,50]]) M = cv2.getAffineTransform(pts1,pts2) dst = cv2.warpAffine(img,M,(cols,rows)) 透视变换（Perspective Transformation） 透视转换需要一个3x3转换矩阵。即使在转换后，直线也将保持直线。需要在输入图像上有四个点，在输出图像中需要对应的四个点，其中三个点不共线。可通过cv2.getPersperctiveTransform得到变换矩阵，并传递给cv2.warpPerspective。\nrows,cols,ch = img.shape pts1 = np.float32([[40,100],[400,100],[0,400],[360,400]]) pts2 = np.float32([[0,0],[500,0],[0,500],[500,500]]) M = cv2.getPerspectiveTransform(pts1,pts2) dst = cv2.warpPerspective(img,M,(cols,rows)) ","permalink":"https://Achilles-10.github.io/posts/tech/opencv3/","summary":"变换 OpenCV提供了cv2.warpAffine和cv2.warpPerspective两个转换函数，cv2.warpAffine采用2x3的转换矩阵，cv2.warpPerspective采用3x3转换矩阵。 缩放 使用cv2.resize实现图像的缩放，可以指定缩放尺寸或缩放比","title":"OpenCV-Python学习笔记(3)：几何变换"},{"content":"1. 剑指 Offer 03. 数组中重复的数字(简单) 哈希表：用哈希表（Set）记录遍历到的数字，若找到重复的数字则返回。\n原地交换：数组元素的索引和值是一对多的关系。因此，可遍历数组并通过交换操作，使元素的索引与值一一对应（即$nums[i]=i$）。\n算法流程\n遍历数组，索引初始值i=0; 若nums[i]=i：说明该数字已在对应的索引处，无需交换，跳过； 若nums[nums[i]]=nums[i]：说明索引nums[i]处和索引i处的值均为nums[i]，即找到一组重复，返回nums[i]； 否则交换nums[nums[i]]与nums[i]； 若遍历完未返回，返回-1。 复杂度：时间O(N)，空间O(1)\n代码：\nclass Solution: def findRepeatNumber(self, nums: List[int]) -\u0026gt; int: n=len(nums) i=0 while i\u0026lt;n: if nums[i]==i: i+=1 continue if nums[nums[i]]==nums[i]: return nums[i] nums[nums[i]],nums[i]=nums[i],nums[nums[i]] Python中a,b=c,d的原理是暂存元组(c,d)，然后按左右顺序赋值，在此处需要先给nums[nums[i]]赋值。\n2. 剑指 Offer 04. 二维数组中的查找(中等) 暴力法：时间复杂度O(MN)，未利用到数组的排序信息\n二分法：时间复杂度O(M+N)\n如下图，考虑将二维数组旋转45°，类似一棵二叉搜索树：故我们可以从数组的左下角(n-1,0)或右上角(0,m-1)开始，运用二分的思想进行搜索。\nclass Solution: def findNumberIn2DArray(self, matrix: List[List[int]], target: int) -\u0026gt; bool: i,j=len(matrix)-1,0 while 0\u0026lt;=i and j\u0026lt;len(matrix[0]): if target==matrix[i][j]: return True elif target\u0026gt;matrix[i][j]: j+=1 else: i-=1 return False 3. 剑指 Offer 05. 替换空格(简单) 库函数:return s.replace(' ','%20')\n遍历添加：初始化一个新的str，时间空间复杂度O(N)\n原地修改(python str是不可修改，无法实现)：\n遍历得到空格数cnt 修改s长度为len+2*cnt 倒序遍历，i指向原字符串末尾，j指向新字符串末尾，当i=j时跳出（左方已没有空格）； s[i]=' '：s[j-2:j]=\u0026rsquo;%20\u0026rsquo;，j-=2 s[i]!=' '：s[j]=s[i] string replaceSpace(string s) { int count = 0, len = s.size(); for (char c : s) { if (c == \u0026#39; \u0026#39;) count++; } s.resize(len + 2 * count); for(int i = len - 1, j = s.size() - 1; i \u0026lt; j; i--, j--) { if (s[i] != \u0026#39; \u0026#39;) s[j] = s[i]; else { s[j - 2] = \u0026#39;%\u0026#39;; s[j - 1] = \u0026#39;2\u0026#39;; s[j] = \u0026#39;0\u0026#39;; j -= 2; } } return s; } 4. 剑指 Offer 06. 从尾到头打印链表(简单) 辅助栈：遍历链表，将各节点入栈，返回倒序列表。时间空间复杂度O(N)\n递归：时间空间复杂度O(N)\nclass Solution: def reversePrint(self, head: ListNode) -\u0026gt; List[int]: return self.reversePrint(head.next) + [head.val] if head else [] 5. 剑指 Offer 07. 重建二叉树(中等) 递归：\npreorder=[root,L,R], inorder=[L,root,R]\n找到root在inorder中的下标，构建root的左右子树\nclass Solution: def buildTree(self, preorder: List[int], inorder: List[int]) -\u0026gt; TreeNode: if not preorder: return None root=TreeNode(preorder[0]) rootidx=inorder.index(preorder[0]) root.left=self.buildTree(preorder[1:rootidx+1],inorder[:rootidx]) root.right=self.buildTree(preorder[rootidx+1:],inorder[rootidx+1:]) return root 迭代：待续\n6. 剑指 Offer 09. 用两个栈实现队列(简单) 双栈：将一个栈当作输入栈，用于将数据入队；另一个栈当作输出栈，用于数据出队。每次出队时，若输出栈不为空，则直接从输出栈弹出；否则现将所有数据从输入栈弹出并压入输出栈，再从输出栈弹出。 class CQueue: def __init__(self): self.stack1, self.stack2=[],[] def appendTail(self, value: int) -\u0026gt; None: self.stack1.append(value) def deleteHead(self) -\u0026gt; int: if self.stack2: return self.stack2.pop() if not self.stack1: return -1 while self.stack1: self.stack2.append(self.stack1.pop()) return self.stack2.pop() 7. 剑指 Offer 10- I. 斐波那契数列(简单) 动态规划：\nclass Solution: def fib(self, n: int) -\u0026gt; int: a,b=0,1 while n: a,b=b,a+b n-=1 return a%(10**9+7) 矩阵快速幂：时间复杂度O(log n)，空间复杂度O(1)\n$$ \\left[\\begin{matrix} 1\u0026amp;1 \\\\ 1\u0026amp;0 \\end{matrix} \\right] \\left[\\begin{matrix} F(n) \\\\ F(n-1) \\end{matrix} \\right] = \\left[ \\begin{matrix} F(n)+F(n-1)\\\\ F(n) \\end{matrix} \\right] =\\left[\\begin{matrix} F(n+1) \\\\ F(n) \\end{matrix}\\right] $$\n$$ \\left[\\begin{matrix} F(n+1) \\\\ F(n) \\end{matrix}\\right] = \\left[\\begin{matrix} 1\u0026amp;1 \\\\ 1\u0026amp;0 \\end{matrix} \\right]^n \\left[\\begin{matrix} F(1) \\\\ F(0) \\end{matrix}\\right] $$\n令： $$ M=\\left[\\begin{matrix} 1\u0026amp;1 \\\\ 1\u0026amp;0 \\end{matrix} \\right] $$ 关键在于快速计算矩阵M的n次幂。\nclass Solution: def fib(self, n: int) -\u0026gt; int: MOD = 10 ** 9 + 7 if n \u0026lt; 2: return n def multiply(a: List[List[int]], b: List[List[int]]) -\u0026gt; List[List[int]]: c = [[0, 0], [0, 0]] for i in range(2): for j in range(2): c[i][j] = (a[i][0] * b[0][j] + a[i][1] * b[1][j]) % MOD return c def matrix_pow(a: List[List[int]], n: int) -\u0026gt; List[List[int]]: ret = [[1, 0], [0, 1]] while n \u0026gt; 0: if n \u0026amp; 1: ret = multiply(ret, a) n \u0026gt;\u0026gt;= 1 a = multiply(a, a) return ret res = matrix_pow([[1, 1], [1, 0]], n - 1) return res[0][0] 8. 剑指 Offer 11. 旋转数组的最小数字(简单) 二分法：\n如下图，考虑数组最后一个元素x，最小值右侧的元素一定小于等于x，最小值左侧的元素一定大于等于x。\n可以分为三种情况：\nnums[mid]\u0026gt;x：left=mid+1 nums[mid]\u0026lt;x：right=mid nums[mid]=x：此时无法判断nums[mid]在最小值左侧还是右侧，但可以确定nums[right]有nums[mid]这个替代值，故可以忽略右端点。right-=1 class Solution: def minArray(self, numbers: List[int]) -\u0026gt; int: n=len(numbers) l,r=0,n-1 while l\u0026lt;r: mid = l+(r-l)//2 if numbers[mid]\u0026gt;numbers[r]: l=mid+1 elif numbers[mid]\u0026lt;numbers[r]: r=mid else: r-=1 return numbers[l] 9. 剑指 Offer 12. 矩阵中的路径(中等) 回溯(DFS)：时间复杂度$O(MN3^L)$，空间复杂度O(MN)\n用backtracking(i,j,idx)表示从位置(i,j)出发能否匹配字符串word[idx:]，执行步骤如下：\n若board[i][j]!=word[idx]，不匹配返回False 若当前字符匹配且到了字符串末尾，返回True 否则，遍历当前相邻位置 class Solution: def exist(self, board: List[List[str]], word: str) -\u0026gt; bool: m,n=len(board),len(board[0]) vis=set() directions=[(1,0),(-1,0),(0,1),(0,-1)] def backtracking(i,j,idx): if board[i][j]!=word[idx]: return False if idx==len(word)-1: return True vis.add((i,j)) flag=False for di,dj in directions: ii,jj=i+di,j+dj if 0\u0026lt;=ii\u0026lt;m and 0\u0026lt;=jj\u0026lt;n and (ii,jj) not in vis: if backtracking(ii,jj,idx+1): flag=True break vis.remove((i,j)) return flag for i in range(m): for j in range(n): if backtracking(i,j,0): return True return False 10. 剑指 Offer 14- I. 剪绳子(中等) 动态规划：时间空间复杂度O(n)\ndp[1]=1,dp[2]=1,状态转移方程： $$ dp[i]=max(2*dp[i-2],3*dp[i-3],2*(i-2),3*(i-3)) $$\nclass Solution: def cuttingRope(self, n: int) -\u0026gt; int: dp=[0]*(n+1) dp[1]=dp[2]=1 for i in range(3,n+1): dp[i]=max(2*dp[i-2],3*dp[i-3],2*(i-2),3*(i-3)) return dp[n] 数学推导（贪心）:\nclass Solution: def cuttingRope(self, n: int) -\u0026gt; int: if n\u0026lt;4: return n-1 a,b=n//3,n%3 if b==1: return int(math.pow(3,a-1)*4) elif b==2: return int(math.pow(3,a)*2) return int(math.pow(3,a)) 11. 剑指 Offer 15. 二进制中1的个数(简单) 循环遍历\n位运算优化：时间复杂度O(log n)。每次将n与n-1做与操作，可以将n的最低位的1变为0。例如6(110)\u0026amp;5(101)=4(100)。\nclass Solution: def hammingWeight(self, n: int) -\u0026gt; int: ans=0 while n: n\u0026amp;=(n-1) ans+=1 return ans 12. 剑指 Offer 16. 数值的整数次方(中等) 快速幂乘法：递归和迭代\nclass Solution: def myPow(self, x: float, n: int) -\u0026gt; float: # 迭代 def quickMul(n): ans=1.0 xx=x while n: if n\u0026amp;1: ans*=xx xx*=xx n\u0026gt;\u0026gt;=1 return ans return quickMul(n) if n\u0026gt;=0 else 1/quickMul(-n) class Solution: def myPow(self, x: float, n: int) -\u0026gt; float: def quickMul(n): if n==0: return 1.0 y=quickMul(n//2) return y*y if n\u0026amp;1==0 else y*y*x return quickMul(n) if n\u0026gt;=0 else 1/quickMul(-n) 13. 剑指 Offer 17. 打印从1到最大的n位数(简单) DFS：用字符串来正确表示大数（本题不需要），依次遍历长度1~n的数，第一位只能为1~9，其他位为0~9。\nclass Solution: def printNumbers(self, n: int) -\u0026gt; List[int]: ans=[] def dfs(k,n,s): if k==n: ans.append(int(s)) return for i in range(10): dfs(k+1,n,s+str(i)) for i in range(1,n+1): for j in range(1,10): dfs(1,i,str(j)) return ans 15. 剑指 Offer 18. 删除链表的节点(简单) 前驱结点遍历：考虑要删除节点为头结点的特殊情况。\nclass Solution: def deleteNode(self, head: ListNode, val: int) -\u0026gt; ListNode: if head.val==val: return head.next pre,p=head,head.next while p and p.val!=val: pre,p=p,p.next if p: pre.next = p.next return head 16. 剑指 Offer 19. 正则表达式匹配(困难) 动态规划：\ndp[i][j]表示s[:i]与p[:j]是否匹配，考虑以下情况：\np[j]='*': 若s[i]与p[j-1不匹配，则p[j-1]匹配零次即为dp[i][j]=dp[i][j-2]；否则p[j-1]匹配1次或多次，即dp[i][j]=dp[i-1][j] or dp[i][j-2] p[j]!='*'：若s[i]与p[j]匹配，则dp[i][j]=dp[i-1[j-1] s[i]与p[j]匹配时满足，s[i]=p[j] or p[j]=='.' 初始化时，dp[0][0]=True，考虑s为空数组，只有p的偶数位为*时能够匹配 class Solution: def isMatch(self, s: str, p: str) -\u0026gt; bool: m,n=len(s),len(p) dp = [[False for _ in range(n+1)]for _ in range(m+1)] dp[0][0]=True for j in range(2,n+1,2): if p[j-1]==\u0026#39;*\u0026#39;: dp[0][j]=dp[0][j-2] for i in range(1,m+1): for j in range(1,n+1): if p[j-1]==\u0026#39;*\u0026#39;: if s[i-1]==p[j-2] or p[j-2]==\u0026#39;.\u0026#39;: dp[i][j]=dp[i-1][j] or dp[i][j-2] else: dp[i][j]=dp[i][j-2] else: if s[i-1]==p[j-1] or p[j-1]==\u0026#39;.\u0026#39;: dp[i][j]=dp[i-1][j-1] return dp[-1][-1] 17. 剑指 Offer 20. 表示数值的字符串(中等) 模拟\n有限状态机：定义状态-\u0026gt;画状态转移图-\u0026gt;编写代码\n字符类型：空格 ，数字1-9，正负号+-，小数点.，幂符号eE。\n状态定义：\n开始的空格 幂符号前的正负号 小数点前的数字 小数点，小数点后的数字 当小数点前为空格时，小数点和小数点后的数字 幂符号 幂符号后的正负号 幂符号后的数字 结尾的空格 状态转移图：\nclass Solution: def isNumber(self, s: str) -\u0026gt; bool: states = [ {\u0026#39; \u0026#39;:0,\u0026#39;s\u0026#39;:1,\u0026#39;d\u0026#39;:2,\u0026#39;.\u0026#39;:4}, # 0. start with \u0026#39;blank\u0026#39; {\u0026#39;d\u0026#39;:2,\u0026#39;.\u0026#39;:4}, # 1. \u0026#39;sign\u0026#39; before \u0026#39;e\u0026#39; {\u0026#39;d\u0026#39;:2,\u0026#39;.\u0026#39;:3,\u0026#39;e\u0026#39;:5,\u0026#39; \u0026#39;:8}, # 2. \u0026#39;digit\u0026#39; before \u0026#39;dot\u0026#39; {\u0026#39;d\u0026#39;:3,\u0026#39;e\u0026#39;:5,\u0026#39; \u0026#39;:8}, # 3. \u0026#39;digit\u0026#39; after \u0026#39;dot\u0026#39; {\u0026#39;d\u0026#39;:3}, # 4. \u0026#39;digit\u0026#39; after \u0026#39;dot\u0026#39; (‘blank’ before \u0026#39;dot\u0026#39;) {\u0026#39;s\u0026#39;:6,\u0026#39;d\u0026#39;:7}, # 5. \u0026#39;e\u0026#39; {\u0026#39;d\u0026#39;:7}, # 6. \u0026#39;sign\u0026#39; after \u0026#39;e\u0026#39; {\u0026#39;d\u0026#39;:7,\u0026#39; \u0026#39;:8}, # 7. \u0026#39;digit\u0026#39; after \u0026#39;e\u0026#39; {\u0026#39; \u0026#39;:8} # 8. end with \u0026#39;blank\u0026#39; ] p = 0 # start with state 0 for c in s: if \u0026#39;0\u0026#39;\u0026lt;=c\u0026lt;=\u0026#39;9\u0026#39;: t = \u0026#39;d\u0026#39; # digit elif c in \u0026#34;+-\u0026#34;: t = \u0026#39;s\u0026#39; # sign elif c in \u0026#34;eE\u0026#34;: t = \u0026#39;e\u0026#39; # e or E elif c in \u0026#34;. \u0026#34;: t = c # dot, blank else: t = \u0026#39;?\u0026#39; # unknown if t not in states[p]: return False p = states[p][t] return p in (2, 3, 7, 8) 18. 剑指 Offer 21. 调整数组顺序使奇数位于偶数前面(简单) 双指针交换\nclass Solution: def exchange(self, nums: List[int]) -\u0026gt; List[int]: i,j=0,len(nums)-1 while i\u0026lt;j: while i\u0026lt;j and nums[i]%2: i+=1 while i\u0026lt;j and nums[j]%2==0: j-=1 nums[i],nums[j]=nums[j],nums[i] return nums 19. 剑指 Offer 22. 链表中倒数第k个节点(简单) 双指针：让快指针先走k个节点\nclass Solution: def getKthFromEnd(self, head: ListNode, k: int) -\u0026gt; ListNode: former, latter = head, head for _ in range(k): former = former.next while former: former, latter = former.next, latter.next return latter 20. 剑指 Offer 24. 反转链表(简单) 迭代（双指针）：\nclass Solution: def reverseList(self, head: ListNode) -\u0026gt; ListNode: pre,cur=None,head while cur: cur.next,pre,cur=pre,cur,cur.next return pre 递归：\nclass Solution: def reverseList(self, head: ListNode) -\u0026gt; ListNode: def recur(pre,cur): if not cur: return pre res = recur(cur,cur.next) cur.next=pre return res return recur(None,head) 21. 剑指 Offer 25. 合并两个排序的链表(简单) 递归：\nclass Solution: def mergeTwoLists(self, l1: ListNode, l2: ListNode) -\u0026gt; ListNode: if not l1 or not l2: return l1 or l2 if l1.val\u0026lt;l2.val: l1.next = self.mergeTwoLists(l1.next,l2) return l1 else: l2.next = self.mergeTwoLists(l1,l2.next) return l2 22. 剑指 Offer 26. 树的子结构(中等) 先序遍历：\n分为两步，先序遍历树A中的每个节点$n_A$；判断以$n_A$为根节点的子树是否包含树B。\nsame函数判断以$n_A$为根节点的子树是否包含树B，若B为空，则表示树B匹配完成，返回True；若A为空，则说明越过A，返回False；若A和B值不同，则不匹配，返回False。\nclass Solution: def isSubStructure(self, A: TreeNode, B: TreeNode) -\u0026gt; bool: def same(A,B): if not B: return True if not A: return False return A.val==B.val and same(A.left,B.left) and same(A.right,B.right) return bool(A and B) and (same(A,B) or self.isSubStructure(A.left,B) or self.isSubStructure(A.right,B)) 23. 剑指 Offer 27. 二叉树的镜像(简单) 递归：注意同时赋值或者临时保存子树\nclass Solution: def mirrorTree(self, root: TreeNode) -\u0026gt; TreeNode: if not root: return None root.left,root.right = self.mirrorTree(root.right),self.mirrorTree(root.left) return root 迭代：用栈保存节点\nclass Solution: def mirrorTree(self, root: TreeNode) -\u0026gt; TreeNode: if not root: return None stack=[root] while stack: node = stack.pop() if node.left: stack.append(node.left) if node.right: stack.append(node.right) node.left,node.right=node.right,node.left return root 24. 剑指 Offer 28. 对称的二叉树(简单) 递归：\nclass Solution: def isSymmetric(self, root: TreeNode) -\u0026gt; bool: def recur(L,R): if not L and not R: return True if not L or not R: return False return L.val==R.val and recur(L.left,R.right) and recur(L.right,R.left) return not root or recur(root.left,root.right) 迭代：\nclass Solution: def isSymmetric(self, root: TreeNode) -\u0026gt; bool: if not root or not (root.left or root.right): return True queue=[root.left,root.right] while queue: l=queue.pop(0) r=queue.pop(0) if not l and not r: continue if not l or not r or l.val!=r.val: return False queue.append(l.left) queue.append(r.right) queue.append(l.right) queue.append(r.left) return True 25. 剑指 Offer 29. 顺时针打印矩阵(简单) 设置边界：设置top，bottom，left，right，遍历\nclass Solution: def spiralOrder(self, matrix: List[List[int]]) -\u0026gt; List[int]: if not matrix: return [] top,bottom,left,right,ans=0,len(matrix)-1,0,len(matrix[0])-1,[] while True: for j in range(left,right+1): ans.append(matrix[top][j]) top+=1 if top\u0026gt;bottom: break for i in range(top,bottom+1): ans.append(matrix[i][right]) right-=1 if right\u0026lt;left: break for j in range(right,left-1,-1): ans.append(matrix[bottom][j]) bottom-=1 if top\u0026gt;bottom: break for i in range(bottom,top-1,-1): ans.append(matrix[i][left]) left+=1 if right\u0026lt;left: break return ans ","permalink":"https://Achilles-10.github.io/posts/algo/offer1/","summary":"1. 剑指 Offer 03. 数组中重复的数字(简单) 哈希表：用哈希表（Set）记录遍历到的数字，若找到重复的数字则返回。 原地交换：数组元素的索引和值是一对多的关系。因此，可遍历数组并通过交换操作，使元素的索引与值一一对应（即$nums[i]=i$）。 算法流程 遍历数组，索引初始值i=0; 若nums[","title":"剑指offer复习笔记(1)"},{"content":"[paper]\n1. 介绍 使用结合CNN和Transformer的双流网络来融合伪造人脸的局部和全局伪造信息，进而提高模型的泛化能力。同时使用高频信息在CNN和Transformer之间交互，实现更通用和鲁棒的伪造检测。\n低频信息和中高频信息通常表现出不同的特征，其中低频分量主要包括图像的自然内容信息，中高频分量则主要包含混合边界、模糊伪影和棋盘格(checkboard)等细粒度信息。\n主要贡献如下：\n提出了一种用于人脸伪造检测的双流网络，分层频域辅助交互网络（Hierarchical Frequency-assisted Interactive Networks, HFI-Net）。 我们设计了一个新颖的频域特征改进模块（Frequency-based Feature Refinement，FFR）来提取RGB特征上的中高频信息，充分利用更通用和鲁棒的频域特征，避免了空间伪影的脆弱性。 我们提出了一种共享和频域辅助的全局局部交互模块（Global Local Interaction, GLI），该模块放置在HFI-Net的多级层中，以在全局上下文和局部特征之间进行有效的交互。 2. 方法 2.1 概述 HFI-Net是由CNN分支和Transformer分支组成的双流网络，旨在捕获全局上下文信息和局部细节信息。\nTransformer分支的backbone是ViT。CNN分支有一个瓶颈卷积(Bottleneck)和四个可分离阶段，其中瓶颈卷积包含两个3x3卷积层用于提取边缘和纹理等初始局部特征；每个可分离阶段有三个可分离卷积块组成，以及阶段输入和输出之间的残差连接。\nGLI模块放置在HFI-Net的每个阶段，由两个FFR模块组成，用于融合全局和局部信息，并在学习中高频伪造痕迹的同时抑制共享的高级语义特征。\nTransformer的输入为$x^g\\in\\mathbb{R}^{T\\times D},\\ T=196,\\ D=768$，bottleneck输入为$x^l\\in\\mathbb{R}^{C\\times H\\times W},\\ C=768,\\ H=W=14$。在CNN分支中没有下采样操作，故特征维度不会改变。\n最后，每个分支使用一个分类器进行训练。在训练阶段，采用交叉熵损失作为损失函数。在测试期间，将两个分类器的输出的均值作为最终预测结果。\n2.2 FFR (Frequency-based Feature Refinement) DCT\n频率选择准则（Frequency Selection Criterion, FSC）：\n与高频信息相比，CNN倾向于强调低频通道，其中包含图像的背景和真实部分；同时，已有许多研究证实了频域中的真实人脸和伪造人脸之间存在差异。如下图，伪造人脸和真实人脸在RGB图像，RGB特征图和低频特征图上几乎一致，但在中高频特征图上存在关键差异。\n所以本文在RGB特征图上使用2D DCT提取中高频分量，如下图，假设n表示提取的中高频基数，将这n个频域特征拼接在一起得到$\\tilde{X}_{u,v}=cat[F_i,\\dots,F_n]$。其中用到了FcaNet: Frequency Channel Attention Networks。\nFrequency-Based Feature Refinement（FFR）：\n聚合特征T： $$ T=\\sum_{h=0}^{H-1}\\sum_{w=0}^{W-1}\\tilde{X}_{h,w} $$ 用一个MLP层（2个全连接层）和一个sigmoid函数$\\sigma$来生成注意力权重： $$ W=\\sigma(MLP(T)) $$\n2.3 Global-Local Interaction Module（GLC）： Frequency-Assisted Global-Local Interaction (GLI) Module：\nGLI 模块利用FFR模块得到频域注意力权重，通过使用注意力权重和残差连接特征获得最终输出： $$ X^g_{freq}=X^g+W^l\\odot X^g\\\\\\ X^l_{freq}=X_l+W^g\\odot X^l $$\nMulti-Level Frequency Feature Extraction：\n浅层特征可以捕获局部区域的细微差异，但随着模型越来越深，人脸的高级语义特征仍然包含原始人脸和操纵人脸的许多共同特征。高级语义信息对人脸检测有负面影响，可能导致模型过拟合而导致泛化性能差。所以将GLI模块插入双流网络的每个阶段来增强局部伪造线索并抑制RGB特征图上共享的高级语义信息。\n3. 实验 3.1 数据集和设置 类内实验：FF++ 未知数据集实验： Celeb-DF(V2)：590+5639 TIMIT：320+640 DFDCp：1131+4113 UADFV：49+49 未知伪造方法实验：GID-DF/GID-FF，在DF/FF上训练，其余部分测试 未知扰动实验：DeeperForensics-1.0 (DFo)，60000+ 实现细节： backbone：ViT(ImageNet-1K), CNN(randomly init). optimizer: Adam; lr:2e-5; weight decay=1e-7 trainset: FF++(C40) 3.2 模块分析 在FF++(C40)上训练，测试指标为帧级AUC。\n消融实验：测试结果和可视化结果如下图，w/o FSC表示使用所有频域信息进行训练而非中高频信息；w/o dual-branch表示只使用ViT；w/o GLI表示不使用GLI交互模块。可视化结果中(a), (b), (c)和(d)分别对应消融实验的四种情况，可见HFI-Net能够对操纵区域有较高的响应。\n不同层级的交互作用分析：下图分别是将模型分割为n个阶段和在哪些阶段设置GLI模块的消融实验。可见，将模型划分为4个阶段，并在每个阶段都设置GLI模块能达到最佳性能。\n不同频率成分分析：如下图，FCS方法提取中高频的方法由于其他频率选择方法，对于未知的测试场景，中高频的特征比单频（低，中，高）更具一般性。\n对2D DCT的分析：实验测试不同U(V)参数的性能。\n$$ F^{2d}_{u,v}=\\sum_{i=0}^{H-1}\\sum_{j=0}^{W-1}{x^{2d}_{i,j}B^{i,j}_{u,v}}\\\\\\ B^{i,j}_{u,v}=\\cos(\\frac{\\pi u}{U}(i+\\frac{1}{2}))\\cos(\\frac{\\pi v}{U}(j+\\frac{1}{2})) $$\n不同频率变换方式的分析：对比DWT（小波换换）和DCT，DCT更适合这个网络架构。DWT捕获频率信息的同时会对特征图进行下采样，可能会损害与伪造区域相关的注意力权重。\n思考：使用DWT时将FFR中的FcaNet修改为WaveNets?\n不同特征细化方式的分析（FFR）：对比SE-Net和CBAM，本文的FFR模块强调中高频的伪造线索，抑制图像在空域上的原始部分和在RGB特征上的高阶语义信息，提高了泛化性。\n不同融合方式的分析（fusion）：比较特征图fusion和最后输出的fusion。\n3.3 和近期工作的比较 和SOTA对比： 未知数据集泛化性测试：下图评价指标为Image-level AUC 未知伪造方法泛化性测试：Image-based Video-level AUC 未知扰动的鲁棒性测试：Image-based Video-level AUC 计算复杂度对比：Image-level AUC ","permalink":"https://Achilles-10.github.io/posts/paper/hfinet/","summary":"[paper] 1. 介绍 使用结合CNN和Transformer的双流网络来融合伪造人脸的局部和全局伪造信息，进而提高模型的泛化能力。同时使用高频信息在CNN和Transformer之间交互，实现更通用和鲁棒的伪造检测。 低频信息和中高频信息通常表现出不同的特征，其中低频分量主要包括图像的自然内容信","title":"Hierarchical Frequency-Assisted Interactive Networks for Face Manipulation Detection"},{"content":"颜色空间 RGB颜色空间 RGB（红绿蓝）是依据人眼识别的颜色定义出的空间，可表示大部分颜色。但在科学研究一般不采用RGB颜色空间，因为它的细节难以进行数字化的调整。它将色调，亮度，饱和度三个量放在一起表示，很难分开。它是最通用的面向硬件的彩色模型。RGB颜色空间适合于显示系统，不适合于图像处理。\nHSV颜色空间 HSV表达彩色图像的方式由三个部分组成：\nHue（色调，色相） Saturation（饱和度，色彩纯净度） Value（明度） 在HSV颜色空间下，比RGB更容易跟踪某种颜色的物体，常用与分割指定颜色的物体。\n用下面这个圆柱体来表示HSV颜色空间，圆柱体的横截面可以看做是一个极坐标系 ，H用极坐标的极角表示，S用极坐标的极轴长度表示，V用圆柱中轴的高度表示。\n在RGB颜色空间中，颜色由三个值共同决定，比如黄色为(255,255,0)，在HSV颜色空间中，黄色只有一个值决定，Hue=60。\n饱和度表示颜色接近光谱色的程度：饱和度越高，说明颜色越深，越接近光谱色；饱和度为0表示纯白色。\n明度决定颜色空间中颜色的明暗程度：明度越高，表示颜色越明亮；明度为0表示纯黑色（此时颜色最暗）。\nHLS 颜色空间 HLS颜色空间和HSV颜色空间比较类似，区别在于最后一个分量不同。HLS中的L表示Lightness（亮度），亮度为100表示白色，亮度为0表示黑色。HSV中的V表示明度，明度为100表示光谱色，明度为0表示黑色。\n提取白色物体时，使用HLS更方便，因为HSV中的H没有白色，需要由S和V共同决定（S=0，V=100）；在HLS中白色仅有亮度L一个分量决定。\nYUV/YCbCr YUV是通过亮度-色差来描述颜色的颜色空间。Y是亮度信号，色度信号由两个互相独立的信号组成，根据颜色系统和格式不同，色度信号被称作UV/PbPr/CbCr。在DVD中，色度信号被存储为Cb和Cr（C表示颜色，b蓝色，r红色）。\n改变颜色空间 颜色空间 考虑BGR$\\leftrightarrow$Gray，BGR$\\leftrightarrow$HSV和BGR$\\leftrightarrow$YCrCB颜色空间的转换。\ncv2.cvtColor(input_image, flag)函数用于颜色空间转换，flag决定转换的类型：\ncv2.COLOR_BGR2GRAY cv2.COLOR_BGR2HSV cv2.COLOR_BGR2YCR_CB 可以用以下命令获取其他标记：\nflags = [i for i in dir(cv2) if i.startswith(\u0026#39;COLOR_\u0026#39;)] print(flags) HSV的色相范围为[0,179]，饱和度为[0,255]，值域为[0,255]。不同软件使用不同的规模，若要将OpenCV的值和它们比较，需要做标准化操作。\n对象追踪 HSV比BGR颜色空间更容易表示颜色，可以使用HSV来提取有颜色的对象。以下代码尝试提取一个蓝色对象，步骤：截取视频的每一帧$\\rightarrow$转换到HSV颜色空间$\\rightarrow$设置蓝色范围的阈值$\\rightarrow$单独提取蓝色对象。\nimport cv2 import numpy as np cap = cv2.VideoCapture(0) while(1): # 读取帧 _, frame = cap.read() # 转换颜色空间 BGR 到 HSV hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # 定义HSV中蓝色的范围 lower_blue = np.array([110,50,50]) upper_blue = np.array([130,255,255]) # 设置HSV的阈值使得只取蓝色 mask = cv2.inRange(hsv, lower_blue, upper_blue) # 将掩膜和图像逐像素相加 res = cv2.bitwise_and(frame,frame, mask= mask) cv2.namedWindow(\u0026#39;frame\u0026#39;, cv2.WINDOW_NORMAL) cv2.imshow(\u0026#39;frame\u0026#39;,frame) cv2.namedWindow(\u0026#39;mask\u0026#39;, cv2.WINDOW_NORMAL) cv2.imshow(\u0026#39;mask\u0026#39;,mask) cv2.namedWindow(\u0026#39;res\u0026#39;, cv2.WINDOW_NORMAL) cv2.imshow(\u0026#39;res\u0026#39;,res) k = cv2.waitKey(5) \u0026amp; 0xFF if k == 27: break cv2.destroyAllWindows() 在上面的HLS颜色空间示意图中测试白色的检测：\nimport cv2 import numpy as np import matplotlib.pyplot as plt img = cv2.imread(\u0026#34;hls.jpeg\u0026#34;) # Convert BGR to HLS imgHLS = cv2.cvtColor(img, cv2.COLOR_BGR2HLS) # range of white color in L channel # mask = cv2.inRange(imgHLS[:,:,1], lowerb=250, upperb=255) mask = cv2.inRange(imgHLS, np.array([0,250,0]), np.array([255,255,255])) # Apply Mask to original image white_mask = cv2.bitwise_and(img, img, mask=mask) 找到要追踪的HSV值 使用cv2.cvtColor(color,cv2.COLOR_BGR2HSV)，传递颜色而非图像。示例如下：\nimport cv2 import numpy as np red = np.uint8([[[0,0,255 ]]]) hsv_red = cv2.cvtColor(red,cv2.COLOR_BGR2HSV) print( hsv_red ) 如果想要同时追踪多种颜色，可以将多种颜色的掩码经过按位或操作得到新的掩码：\nmask = cv2.bitwise_or(mask_blue,mask_green,mask_red) ","permalink":"https://Achilles-10.github.io/posts/tech/opencv2/","summary":"颜色空间 RGB颜色空间 RGB（红绿蓝）是依据人眼识别的颜色定义出的空间，可表示大部分颜色。但在科学研究一般不采用RGB颜色空间，因为它的细节难以进行数字化的调整。它将色调，亮度，饱和度三个量放在一起表示，很难分开。它是最通用的面向硬件的彩色模型。RGB颜色空间适合于显示系统，不适","title":"OpenCV-Python学习笔记(2)：颜色空间"},{"content":"1. 说一下了解的激活函数和各自的应用场景 sigmoid: $$ \\sigma(x)=\\frac{1}{1+e^{-x}} $$ sigmoid是第一个被广泛应用于神级网络的激活函数，其值域为$[0,1]$，但是它存在输出均值不为0和梯度消失的问题，在深层网络中被其他激活函数替代。在逻辑回归中使用该激活函数用于输出分类。\ntanh: $$ tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}=2\\sigma(2x)-1 $$ tanh函数解决了sigmoid函数均值不为0的情况，值域为$[-1,1]$，但仍然存在梯度消失的问题。在LSTM中使用了tanh。\nReLU: $$ ReLU(x)= \\begin{cases} x,\\ x\\geq0\\\\\\ 0,\\ x\u0026lt;0\\ \\end{cases} $$ ReLU函数能有效避免梯度消失的问题，但在负值区域处于饱和状态（“死区”）。Alex-Net使用了ReLU，在使用深层网络时最好使用ReLU而不是sigmoid。\nLeaky ReLU： $$ Leaky\\ ReLU(x)= \\begin{cases} x,\\ x\\geq0\\\\\\ \\alpha\\cdot x,\\ x\u0026lt;0 \\end{cases} $$ Leaky ReLU在负值区添加了一个斜率参数，缓解了饱和性问题（“死区”）。但缺点是超参数$\\alpha$的合适值不好设定，当我们想让神经网络学习到负值区的信息时可以使用该函数。\n参数化ReLU(P-ReLU)：解决超参数$\\alpha$不好设定的问题，将其作为模型参数融入到模型的训练过程中，在反向传播时更新参数。\n随机化ReLU(R-ReLU)：随机化超参数$\\alpha$，使不同的层学习不同的参数。其随机化参数的分布符合均匀分布或高斯分布。\nELU： $$ ELU(x)= \\begin{cases} x,\\ x\\geq0\\\\\\ \\lambda\\cdot(e^x-1),\\ x\u0026lt;0 \\end{cases} $$ 解决饱和性问题，但缺点是指数计算量大。\nGELU： $$ GELU(x)=x\\text{P}(\\text{X}\\leq x)=x\\Phi(x) $$ ​\t其中$\\Phi(x)$是正态分布的概率函数，计算时近似计算的数学公式如下： $$ GELU(x)=\\frac{1}{2}x(1+tanh[\\sqrt{\\frac{2}{\\pi}}(x+0.044715x^3)]) $$\n2. 为什么需要激活函数？ 在线性模型中引入非线性激活函数，可以使线性模型非线性化，提高模型的非线性表达能力，也就是拟合能力。\n3. 激活函数的特征？ 非线性性 几乎处处可微 计算简单 单调性：符号不变容易收敛 非饱和性：饱和指在某些区间的梯度接近零，即梯度消失，使得参数无法继续更新 输出范围有限 接近恒等变换 参数少 4. Leaky ReLU相对于ReLU的优势在哪？ Leaky ReLU在负值增加了一个斜率$\\alpha$，缓解了ReLU在$x\u0026lt;0$时的饱和性问题(\u0026ldquo;死区\u0026rdquo;，梯度消失)，但Leaky ReLU得超参数$\\alpha$的合适值不好设定。\n当我们想让神经网络能够学到负值信息时可以使用该激活函数。\n5. 什么是ReLU6？ ReLU的值域为$[0,\\infty]$，在实际应用中需要限定输出的最大值，将输出在6处截断，即为ReLU6。\n6. Sigmoid函数有什么缺点？怎么解决？ 缺点：输出均值不为0，存在梯度消失的情况。\n解决办法：\n用ReLU，Leaky ReLU等其他激活函数代替 采用适合的权重初始化方法，如He_init 在分类问题中，sigmoid作为激活函数时，用交叉熵损失函数替代MSE 加入BN层 分层训练权重 7. ReLU在零点可导吗？如何进行反向传播？ 不可导，可以人为的将零点梯度规定为0。\ncaffe源码~/caffe/src/caffe/layers/relu_layer.cpp倒数第十行代码如下：\nbottom_diff[i] = top_diff[i] * ((bottom_data[i] \u0026gt; 0)+ negative_slope * (bottom_data[i] \u0026lt;= 0)); 可见，间断点（$\\leq0$）处的导数为negtive_slope（默认为0）。\n8. Softmax的溢出问题怎么解决？ 由于Softmax的指数运算，可能导致溢出问题。\n令$M=\\max(x_i)$，将计算$f(x_i)$转换为计算$f(x_i-M)$的值，就可以解决溢出问题了，且理论上计算结果与计算$f(x_i)$保持一致，该操作类似与Min-Max归一化。\n9. 推导Sigmoid的求导公式 sigmoid公式如下：\n$$ \\sigma(z)=\\frac{1}{1+e^{-z}} $$\n求导公式推导如下：\n$$ \\begin{align}\\sigma'(z)\u0026=(\\frac{1}{1+e^{-z}})'\\\\\u0026=(e^{-z})\\cdot\\frac{1}{(1+e^{-z})^2}\\\\\u0026=\\frac{1}{1+e^{-z}}\\cdot\\frac{e^{-z}}{1+e^{-z}}\\\\\u0026=\\frac{1}{1+e^{-z}}\\cdot(1-\\frac{1}{1+e^{-z}})\\\\\u0026=\\sigma(z)\\cdot(1-\\sigma(z))\\end{align} $$ 10. 推导Softmax的求导公式 softmax公式如下： $$ s(z_i)=\\frac{e^{z_i}}{\\sum_{k=1}^{n}{e^{z_k}}} $$ 求导公式推导如下：\n当$j=i$时： $$ \\begin{align} \\frac{\\partial s_i}{\\partial z_i} \u0026=\\frac{\\partial(\\frac{e^{z_i}}{\\sum_{k=1}^{n}{e^{z_k}}})}{\\partial z_i}\\\\ \u0026=\\frac{e^{z_i}\\cdot\\sum{e^{z_k}}-(e^{z_i})^2}{(\\sum{e^{z_k}})^2}\\\\ \u0026=\\frac{e^{z_i}}{\\sum{e^{z_k}}}\\cdot\\frac{\\sum{e^{z_k}}-e^{z_i}}{\\sum{e^{z_k}}}\\\\ \u0026=\\frac{e^{z_i}}{\\sum{e^{z_k}}}\\cdot(1-\\frac{e^{z_i}}{\\sum{e^{z_k}}})\\\\ \u0026=s_i(1-s_i) \\end{align} $$ 当$j\\neq i$时： $$ \\begin{align} \\frac{\\partial s_j}{\\partial z_i} \u0026=\\frac{\\partial(\\frac{e^{z_j}}{\\sum_{k=1}^{n}{e^{z_k}}})}{\\partial z_i}\\\\ \u0026=e^{z_j}\\cdot-(\\frac{1}{\\sum{e^{z_k}}})^2\\cdot e^{z_i}\\\\ \u0026=-\\frac{e^{z_j}}{\\sum{e^{z_k}}}\\cdot\\frac{e^{z_i}}{\\sum{e^{e_k}}}\\\\ \u0026=-s_j\\cdot s_i \\end{align} $$ p.s.基本初等函数的求导公式与法则 ","permalink":"https://Achilles-10.github.io/posts/tech/activation/","summary":"1. 说一下了解的激活函数和各自的应用场景 sigmoid: $$ \\sigma(x)=\\frac{1}{1+e^{-x}} $$ sigmoid是第一个被广泛应用于神级网络的激活函数，其值域为$[0,1]$，但是它存在输出均值不为0和梯度消失的问题，在深层网络中被其他激活函数替代。在逻辑回归中使用该激活函数用于输出分类。 tanh: $$ tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}=2\\sigma(2x)-1 $$ tanh函数解决了sigmoid函","title":"深度学习面试题：激活函数"},{"content":"[paper] [code]\n1. 引言 Transformer 取代了以往递归神经网络为主导的骨干架构，随着ViT的引入，彻底改变了网络架构设计的格局。但ViT的全局注意力机制对输入大小的复杂度过高，难以处理高分辨率的输入。\n层级Transformer采用混合方法来解决这个问题，例如Swin Transformer采用了“滑动窗口”策略，也说明了卷积仍然非常受欢迎。本文目标是为卷积网络弥补前ViT时代和后ViT时代的差距，并测试纯卷积网络可以达到的极限。\n2. Modernizing a ConvNet: a Roadmap（研究路线图） 以ResNet-50作为baseline，考虑以下几种设计决策：\nmarco design（宏观设计） ResNeXt inverted bottlenect（倒置瓶颈） large kernel size（更大的卷积核） various layer-wise micro designs（多样的分层微设计） 2.1 训练技巧 epoch: 90-\u0026gt;300 optimizer: AdamW data augmentation: Mixup, Cutmix, RandAugment, RandomErasing\u0026hellip; regularization: Stochastic Depth, Label Smoothing 2.2 Marco Design（宏观设计） 改变阶段计算比：Swin-T的阶段计算比为1:1:3:1，更大型的Swin的阶段计算比为1:1:9:1。对此，将ResNet-50中的(3,4,6,3)改为 (3,3,9,3)，使模型准确率从78.8%提升至79.4%。 将stem改为\u0026quot;Patchify\u0026quot;（非重叠的卷积）：标准的ResNet中stem为(k=7,p=3,s=2)的卷积后跟一个(k=3,p=1,s=2)的最大池化，这导致输入图像的4倍下采样。将其更换为 (k=4,s=4)的卷积，模型准确率从79.4%提升至79.5%。 2.3 ResNeXt-ify 采用深度可分离卷积，使得每个操作单独混合空间或通道的信息。使用分组卷积(depthwise conv)能够降低网络的FLOPs，但也会降低准确率(78.3%)。将网络宽度从64扩展到96，准确率提升到80.5%。\n2.4 Inverted Bottlenect（倒置瓶颈） Transformer中的MLP的隐藏维度比输入维度大4倍（384:96），这就是倒置瓶颈。对倒置瓶颈的探索如下图(a)(b)，这使得准确率提升(80.5%-\u0026gt;80.6%)的同时降低了FLOPs(下采样残差1x1卷积的FLOPs减少)。\n2.5 Large Kernel Sizes（大卷积核） VGG推广的黄金标准是堆叠3x3的小卷积核，这在现代化GPU上更高效，但Swin中的窗口大小至少为7x7。\n上移分组卷积层：如上图(b)(c)，使复杂低效的模块(MSA)有更少的通道数，降低FLOPS至4.1G，性能暂时下降到79.9%。 增大卷积核：将卷积核大小从3x3增大到7x7，FLOPs大致保持不变，准确率提升至80.6%。当继续增大卷积核时并没有带来更大准确率增益。 2.6 Micro Design（微观设计） 将ReLU更换为GELU：准确率不变 更少的激活函数：如下图所示，复制Swin的样式，将残差块中的激活函数去掉，去掉两个卷积层中的一个激活函数，准确度提升至81.3%。 更少的归一化层：去掉两个归一化层，在1x1卷积前只留下一个BN层，准确率提升到81.4%，超过Swin。 将BN替换为LN：BN能够加速收敛并减少过拟合，但BN错综复杂，可能对模型的性能产生不利影响。在ResNet中直接将BN替换为LN会导致性能不佳，但随着对网络结构和训练技巧的修改，使用LN将准确率提升至81.5%。 可分离的下采样层：ResNet中的下采样是通过每个阶段开始时的残差块实现的。Swin中添加了一个单独的下采样层。本文用单独的(k=2,s=2)卷积实现下采样，后续实验发现在分辨率变化的地方添加归一化层有助于稳定训练，这时准确率达到82.0%。 3. 在ImageNet上的评估 构建了不同的ConvNeXt变体：\nConvNeXt-T: C =(96, 192, 384, 768), B =(3, 3, 9, 3) ConvNeXt-S: C =(96, 192, 384, 768), B =(3, 3, 27, 3) ConvNeXt-B: C =(128, 256, 512, 1024), B =(3, 3, 27, 3) ConvNeXt-L: C =(192, 384, 768, 1536), B =(3, 3, 27, 3) ConvNeXt-XL: C =(256, 512, 1024, 2048), B =(3, 3, 27, 3) 3.1 结果 ImageNet-1K：\nImageNet-22K 预训练，ImageNet-1K 微调：\n3.2 Isotropic ConvNeXt vs. ViT（同质性比较） 同质架构（Isotropic architecture）：同质架构模型没有下采样层，在所有深度都保持相同的特征图分辨率，只需要用特征大小（即patch embedding的维度）和网络深度（即blocks数量）两个参数定义。\nConvNeXt的性能同ViT相当，说明ConvNeXt块设计在用于非层级模型时具有竞争力。\n4. 在下游任务上的评估 4.1 COCO数据集上的目标检测和分割 4.2 ADE20K上的语义分割 4.3 关于模型效率的评论 5. 总结 ConvNeXt模型本身不是全新的，里面的许多设计都被单独测试过，但没有放在一起测试过。ConvNeXt的实验结果是优秀的，在多个计算机视觉基准测试中与最先进的层级Transformer竞争的同时，还保留着标准卷积网络的简单性和效率。\n","permalink":"https://Achilles-10.github.io/posts/paper/convnext/","summary":"[paper] [code] 1. 引言 Transformer 取代了以往递归神经网络为主导的骨干架构，随着ViT的引入，彻底改变了网络架构设计的格局。但ViT的全局注意力机制对输入大小的复杂度过高，难以处理高分辨率的输入。 层级Transformer采用混合方法来解决这个问题，例如Swin Transformer采用了“滑动窗口”策","title":"A ConvNet for the 2020s"},{"content":"图像入门 读取图像 使用cv2.imread(filename,flags)函数读取图像，参数说明如下：\nfilename - 待读取图像的路径\nflags - 读取图像的方式\ncv2.IMREAD_COLOR - 加载彩色图像，图像的透明度会被忽略，默认标志 cv2.IMREAD_GRAYSCALE - 以灰度模式加载图像 cv2.IMREAD_UNCHANGED - 加载图像，不会忽略透明度 可以分别传递整数1，0，-1\nimport numpy as np import cv2 img = cv2.imread(\u0026#39;face.png\u0026#39;,0) 即使图像路径错误，也不会报错，但print(img)会输出None\n写入图像 使用cv2.imwrite(filename,image)函数保存图像，参数说明如下：\nfilename - 保存的文件名 image - 要保存的图像 cv2.imwrite(\u0026#39;save.png\u0026#39;, img) 使用Matplotlib显示图像 from matplotlib import pyplot as plt plt.imshow(img, cmap = \u0026#39;gray\u0026#39;, interpolation = \u0026#39;bicubic\u0026#39;) plt.xticks([]), plt.yticks([]) # 隐藏 x 轴和 y 轴上的刻度值 plt.show() 图像的基本操作 访问和修改像素值 可以通过行列坐标来访问和修改像素值。对于BGR图像，返回一个[BLUE值 GREEN值 RED值]数组；对于灰度图像，只返回对应的灰度。\n\u0026gt;\u0026gt;\u0026gt; px=img[100,100] \u0026gt;\u0026gt;\u0026gt; print(px) [237 217 186] # 访问BLUE值 \u0026gt;\u0026gt;\u0026gt; blue = img[100,100,0] \u0026gt;\u0026gt;\u0026gt; print(blue) 237 \u0026gt;\u0026gt;\u0026gt; img[100,100]=[255,255,255] \u0026gt;\u0026gt;\u0026gt; print(img[100,100]) [255 255 255] 上述方法用于选择数组的区域。对于单像素访问，Numpy数组方法array.item()和array.itemset()返回标量，相对更好。\n\u0026gt;\u0026gt;\u0026gt; img.item(100,100,2) 255 \u0026gt;\u0026gt;\u0026gt; # 修改RED值 \u0026gt;\u0026gt;\u0026gt; img.itemset((10,10,2),99) \u0026gt;\u0026gt;\u0026gt; img.item(10,10,2) 99 访问图像属性 图像属性包括行列通道数，数据类型和像素数等。\n图像的形状由img.shape访问，返回行列通道数的元组，如果图像是灰度的，返回值仅包括行列数。\n像素总数由img.size访问，图像数据类型由img.dtype访问。\n\u0026gt;\u0026gt;\u0026gt; print(\u0026#39;shape:\u0026#39;,img.shape) shape: (512, 512, 3) \u0026gt;\u0026gt;\u0026gt; print(\u0026#39;size:\u0026#39;,img.size) size: 786432 \u0026gt;\u0026gt;\u0026gt; print(\u0026#39;dtype:\u0026#39;,img.dtype) dtype: uint8 img.dtype在调试时很重要，因为OpenCV代码中的大量错误是由无效的数据类型引起的。\n图像感兴趣区域(Region of Interest, ROI) 用Numpy获取ROI，例如将图像中的人脸复制到图像的另一个区域\n\u0026gt;\u0026gt;\u0026gt; face = img[10:300,210:430] \u0026gt;\u0026gt;\u0026gt; img[0:290,0:220]=face 拆分和合并图像通道 有时候需要分别处理图像的B, G, R通道，或者将单独的通道加入到BGR图像，在这种情况下需要拆分或合并图像通道。\n\u0026gt;\u0026gt;\u0026gt; b,g,r=cv2.split(img) \u0026gt;\u0026gt;\u0026gt; img=cv2.merge((b,g,r)) 或者采用Numpy索引，例如将所有红色值设置为零：\n\u0026gt;\u0026gt;\u0026gt; img[:,:,2]=0 cv2.split()是一个耗时的操作，非必要时使用Numpy索引。\n为图像设置边框（填充） 可以使用copyMakeBorder(src, top, bottom, left, right, borderType[, dst[, value]]) -\u0026gt; dst在图像周围创建边框，该函数在卷积运算，零填充等方面有更多应用。参数说明如下：\nsrc - 输入图像 top, bottom, left, right - 边界宽度 borderType - 边框类型标志，可以是一下类型： cv2.BORDER_CONSTANT - 添加恒定的彩色边框，该值由下一个参数给出 cv2.BORDER_REFLECT - 边框是边框元素的镜像 cv2.BORDER_REFLECT_101或cv2.BORDER_DEFAULT与上述相同，但略有变化 cv2.BORDER_REPLICATE - 最后一个元素被复制 cv2.BORDER_WRAP value - 边框的颜色，如果边框类型为cv2.BORDER_CONSTANT import cv2 import numpy as np from matplotlib import pyplot as plt BLUE = [255,0,0] img1 = cv2.imread(\u0026#39;face.png\u0026#39;) img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB) replicate = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REPLICATE) reflect = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT) reflect101 = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT_101) wrap = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_WRAP) constant= cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_CONSTANT,value=BLUE) plt.subplot(231),plt.imshow(img1,\u0026#39;gray\u0026#39;),plt.title(\u0026#39;ORIGINAL\u0026#39;) plt.subplot(232),plt.imshow(replicate,\u0026#39;gray\u0026#39;),plt.title(\u0026#39;REPLICATE\u0026#39;) plt.subplot(233),plt.imshow(reflect,\u0026#39;gray\u0026#39;),plt.title(\u0026#39;REFLECT\u0026#39;) plt.subplot(234),plt.imshow(reflect101,\u0026#39;gray\u0026#39;),plt.title(\u0026#39;REFLECT_101\u0026#39;) plt.subplot(235),plt.imshow(wrap,\u0026#39;gray\u0026#39;),plt.title(\u0026#39;WRAP\u0026#39;) plt.subplot(236),plt.imshow(constant,\u0026#39;gray\u0026#39;),plt.title(\u0026#39;CONSTANT\u0026#39;) plt.show() 图像上的运算 图像加法 可以通过cv2.add()或Numpy操作res=img1+img2完成图像加法操作。相加的图像应该具有相同的深度和类型，或者第二个图像是一个标量值。\nOpenCV加法是饱和运算，Numpy加法是模运算。\n\u0026gt;\u0026gt;\u0026gt; x=np.uint8([250]) \u0026gt;\u0026gt;\u0026gt; y=np.uint8([10]) \u0026gt;\u0026gt;\u0026gt; print(cv2.add(x,y)) [[255]] \u0026gt;\u0026gt;\u0026gt; print(x+y) [4] 当添加两个图像时，尽量使用OpenCV的功能，能提供更好的结果。\n图像融合 这也是图像加法，但是对相加的图像赋予给定的权重，使其具有融合或透明的感觉。\n$$ G(x)=(1-\\alpha)f_0(x)+\\alpha f_1(x) $$\n将$\\alpha$从$0\\rightarrow1$更改，可以实现图像过渡的效果。cv2.addWeighted()在图像上应用以下公式：\n$$ dst=\\alpha\\cdot img_1+\\beta\\cdot img_2+\\gamma $$\n在这里，$\\gamma$ 被视为零。\nimg1 = cv2.imread(\u0026#39;face1.png\u0026#39;) img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB) img2 = cv2.imread(\u0026#39;face2.png\u0026#39;) img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB) dst = cv2.addWeighted(img1,0.6,img2,0.4,0) plt.figure(figsize=(15, 9)) plt.subplot(131),plt.imshow(img1),plt.title(\u0026#39;IMG1\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(132),plt.imshow(img2),plt.title(\u0026#39;IMG2\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(133),plt.imshow(dst),plt.title(\u0026#39;DST\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.show() 按位运算 按位运算包括AND,OR,NOT,XOR操作。这些操作在提取图像的任意部分、定义和处理非矩形ROI方面非常有用。下面的例子是想把OpenCV的标志放到一个图像上。\n如果我们直接使用图像加法，它会改变颜色，无法达到我们想要的效果；如果使用图像融合，会得到一个透明的效果，也不是我们想要的效果。如果是一个矩形区域，我们可以使用ROI，但OpenCV的标志并不是矩形的，故可以用按位操作来实现：\n# 加载两张图片 img1 = cv2.cvtColor(cv2.imread(\u0026#39;shuyi.png\u0026#39;),cv2.COLOR_BGR2RGB) img2 = cv2.cvtColor(cv2.imread(\u0026#39;logo.jpg\u0026#39;),cv2.COLOR_BGR2RGB) # 我想把logo放在左上角，所以我创建了ROI rows,cols,channels = img2.shape roi = img1[0:rows, 0:cols] # 现在创建logo的掩码，并同时创建其相反掩码 img2gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY) ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY) mask_inv = cv2.bitwise_not(mask) # 现在将ROI中logo的区域涂黑 img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv) # 仅从logo图像中提取logo区域 img2_fg = cv2.bitwise_and(img2,img2,mask = mask) # 将logo放入ROI并修改主图像 dst = cv2.add(img1_bg,img2_fg) img1[0:rows, 0:cols ] = dst plt.figure(figsize=(9, 6)) plt.subplot(121),plt.imshow(mask,\u0026#39;gray\u0026#39;),plt.title(\u0026#39;MASK\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(122),plt.imshow(img1),plt.title(\u0026#39;RESULT\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.show() 在计算mask时用到了cv2.bitwise_not(src,dst=None,mask=None)函数，在计算前景和背景区域时用到了cv2.bitwise_and(src1,src2,dst=None,mask=None)，参数说明如下：\nsrc1 - 参与运算的图像 src2 - 参与运算的图像 dst - 可选运算结果输出数组 mask - 可选操作掩码 threshold(src, thresh, maxval, type[, dst])-\u0026gt;ret,dst函数的作用是将一幅灰度图二值化，参数说明如下：\nsrc - 输入的灰度图\nthresh - 阈值\nmaxval - 最大值\ntype - 阈值类型\n阈值类型 灰度值大于阈值(val\u0026gt;threshold) 其他情况 cv2.THRESH_BINARY maxval 0 cv2.THRESH_BINARY_INV 0 maxval cv2.THRESH_TRUNC thresh 当前灰度值 cv2.THRESH_TOZERO 当前灰度值 0 cv2.THRESH_TOZERO_INV 0 当前灰度值 性能衡量和提升技术 使用OpenCV衡量性能 cv2.getTickCount()函数返回从参考时间到调用此函数时的时钟周期数，可以在函数执行前后调用它获得执行函数的时钟周期数。\ncv2.getTickFrequency()函数返回时钟周期的频率或者每秒的时钟周期数。下列代码可以获得执行函数所用时间（以秒为单位）。\ne1 = cv2.getTickCount() # 你的执行代码 e2 = cv2.getTickCount() time = (e2 - e1)/ cv2.getTickFrequency() 也可以使用两次time.time()函数，取两次的差来获得函数所用时间。\nOpenCV中的默认优化 OpenCV默认运行优化的代码。可以使用cv2.useOptimized()来检查是否启用优化，使用cv2.setUseOptimized(bool)来启用/禁用优化。\ncv2.setUseOptimized(True) print(cv2.useOptimized()) %timeit res = cv2.medianBlur(img1,59) cv2.setUseOptimized(False) print(cv2.useOptimized()) %timeit res = cv2.medianBlur(img1,59) True 35 ms ± 2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) False 36.5 ms ± 2.37 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) 在IPython或者Jupyter中衡量性能 使用%timeit。实例如下：\nx=5 z=np.uint8([5]) %timeit y=x**2 %timeit y=z*z %timeit y=x**x %timeit y=np.square(z) 273 ns ± 13.9 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) 659 ns ± 37.2 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) 334 ns ± 10.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) 646 ns ± 48.1 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) 可以看到，Python的标量操作比Numpy的标量操作快，对于包含一两个元素的运算，Python标量比Numpy数组好，当数组大小稍大时Numpy会占优势。\n下面测试cv2.countNonZero()函数和np.count_nonzero()函数对于同一张图片的性能。\nimg = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY) %timeit z=cv2.countNonZero(img) %timeit z=np.count_nonzero(img) 13.5 µs ± 481 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each) 23.2 µs ± 970 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each) 可以看到OpenCV函数比Numpy函数快。\n性能优化技术 尽量避免在Python中使用循环，特别是双重/三重循环等，因为它们本质上速度较慢。 最大程度地向量化算法/代码，因为Numpy和OpenCV针对向量运算进行了优化。 利用缓存一致性。 尽量不要复制数组，因为数组复制是一项代价昂贵的操作。 参考资源 Python优化技术 Scipy讲义-高级Numpy IPython中的时序和性能分析 ","permalink":"https://Achilles-10.github.io/posts/tech/opencv1/","summary":"图像入门 读取图像 使用cv2.imread(filename,flags)函数读取图像，参数说明如下： filename - 待读取图像的路径 flags - 读取图像的方式 cv2.IMREAD_COLOR - 加载彩色图像，图像的透明度会被忽略，默认标志 cv2.IMREAD_GRAYSCALE - 以灰度模式加载图像 cv2.IMREAD_UNCHANGED - 加载图像，不会忽略透明度 可以分别传递整数1，0，-1 import numpy as np import cv2 img =","title":"OpenCV-Python学习笔记(1)：核心操作"},{"content":"[paper] [code]\n动机与介绍 已有方法对跨域数据集和高压缩高曝光数据的检测能力大幅下降(泛化性差)；\n难以识别的fake样本通常包含更一般伪造痕迹，故要学习更通用和鲁棒的面部伪造表征；\n定义了四种常见的伪影(artifacts)： 主要贡献 提出了source-target generator (STG) and mask generator (MG)来学习更一般鲁棒的人脸伪造表征 通过自换脸而非寻找最接近的landmark换脸，降低了计算成本 在cross-dataset和cross-maniputation测试中都取得了SOTA 方法 学习伪造人脸与背景的不一致分为下列三个模块\nSource-Target Generator(STG):\n对source和target进行数据增强以产生不一致，并且对source进行resize和translate以再现边界混合和landmarks不匹配； 首先对Target和Source之一做图像增强 (color：RGB channels, hue, saturation, value, brightness, and contrast；frequency：downsample or sharpen)； 然后对source进行裁剪：$H_r=u_hH,\\quad W_r=u_wW$,其中$\\ u_h和u_w$是一组均分分布中的随机值，再对裁剪后的图像zero-padded 或者 center-cropped还原回初始大小； 最后对source做变形(translate)：traslate vector$\\ t=[t_h,t_w]$,$\\ t_h=v_hH,t_w=v_wW$，$v_h和v_w$是一组均分分布中的随机值。 Mask Generator: 生成变形的灰度mask图\n计算面部landmarks的convex hull来初始化mask，然后对mask变形(elastic deformation)，在用两个不同参数的高斯滤波器(gaussian filter)对mask进行平滑处理。最后在{0.25, 0.5, 0.75, 1, 1, 1}中选取混合指数(blending ration)； Blending: 用Mask来混合source和target图得到SBI\n$$I_{SB}=I_s\\odot M+I_t\\odot(1-M)$$\nTrain with SBIs: 将target而非原图作为”REAL“，使得模型集中在伪造痕迹上\n实验 实现细节 预处理：Dlib和RetinaFace裁帧，面部区域裁剪：4~20%(训练),12.5%(推理)； Source-Target Augmentation：RGBShift, HueSaturationValue, RandomBrightnessContrast, Downscale, and Sharpen 推理策略：如果在一帧中检测到两个或多个人脸，则将分类器应用于所有人脸，并将最高的虚假置信度用作该帧的预测置信度。 实验设定：各类baseline 跨数据集评估 跨操作评估 定量分析 消融实验 定性分析 局限性 缺乏时序信息、无法解决GAN生成的伪造图像\n","permalink":"https://Achilles-10.github.io/posts/paper/sbi/","summary":"[paper] [code] 动机与介绍 已有方法对跨域数据集和高压缩高曝光数据的检测能力大幅下降(泛化性差)； 难以识别的fake样本通常包含更一般伪造痕迹，故要学习更通用和鲁棒的面部伪造表征； 定义了四种常见的伪影(artifacts)： 主要贡献 提出了source-target generator (STG) and mask generator (MG)来学习更一般","title":"Detecting Deepfakes with Self-Blended Images"},{"content":" 英文名: Achilles Zhang 职业: 学生 爱好: 篮球、健身、Dota2 个性签名: 垒山不止就是幸福 ","permalink":"https://Achilles-10.github.io/about/","summary":"英文名: Achilles Zhang 职业: 学生 爱好: 篮球、健身、Dota2 个性签名: 垒山不止就是幸福","title":"关于"}]